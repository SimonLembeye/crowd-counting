{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch\n",
    "from torch.nn import functional as F2\n",
    "from PIL import Image\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "from glob import glob\n",
    "import torchvision.transforms.functional as F\n",
    "from torchvision import transforms, models\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch import optim\n",
    "from torch.nn import Module\n",
    "import time\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orginal model of the paper\n",
    "\n",
    "A pretrain vvg19 nn with a downsampling of 8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "__all__ = ['vgg19']\n",
    "model_urls = {\n",
    "    'vgg19': 'https://download.pytorch.org/models/vgg19-dcbb9e9d.pth',\n",
    "}\n",
    "\n",
    "class VGG(nn.Module):\n",
    "    def __init__(self, features):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.reg_layer = nn.Sequential(\n",
    "            nn.Conv2d(512, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(128, 1, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = F2.upsample_bilinear(x, scale_factor=2)\n",
    "        x = self.reg_layer(x)\n",
    "        return torch.abs(x)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "cfg = {\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512]\n",
    "}\n",
    "\n",
    "def vgg19():\n",
    "    \"\"\"VGG 19-layer model (configuration \"E\")\n",
    "        model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = VGG(make_layers(cfg['E']))\n",
    "    model.load_state_dict(model_zoo.load_url(model_urls['vgg19']), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CSRNet \n",
    "Downsampling = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSRNet(nn.Module):\n",
    "    def __init__(self, load_weights=False):\n",
    "        super(CSRNet, self).__init__()\n",
    "        self.seen = 0\n",
    "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
    "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
    "        self.frontend = make_layers(self.frontend_feat)\n",
    "        self.backend = make_layers(self.backend_feat,in_channels = 512,dilation = True)\n",
    "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        if not load_weights:\n",
    "            mod = models.vgg16(pretrained = True)\n",
    "            self._initialize_weights()\n",
    "            self.frontend.load_state_dict(mod.features[0:23].state_dict())\n",
    "            \n",
    "    def forward(self,x):\n",
    "        size = x.size()\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = F2.upsample(x, size = size[2:])\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            \n",
    "                \n",
    "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
    "    if dilation:\n",
    "        d_rate = 2\n",
    "    else:\n",
    "        d_rate = 1\n",
    "    layers = []\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_crop(im_h, im_w, crop_h, crop_w):\n",
    "    res_h = im_h - crop_h\n",
    "    res_w = im_w - crop_w\n",
    "    i = random.randint(0, res_h)\n",
    "    j = random.randint(0, res_w)\n",
    "    return i, j, crop_h, crop_w\n",
    "\n",
    "\n",
    "def cal_innner_area(c_left, c_up, c_right, c_down, bbox):\n",
    "    inner_left = np.maximum(c_left, bbox[:, 0])\n",
    "    inner_up = np.maximum(c_up, bbox[:, 1])\n",
    "    inner_right = np.minimum(c_right, bbox[:, 2])\n",
    "    inner_down = np.minimum(c_down, bbox[:, 3])\n",
    "    inner_area = np.maximum(inner_right-inner_left, 0.0) * np.maximum(inner_down-inner_up, 0.0)\n",
    "    return inner_area\n",
    "\n",
    "\n",
    "\n",
    "class Crowd(data.Dataset):\n",
    "    def __init__(self, root_path, crop_size,\n",
    "                 downsample_ratio, is_gray=False,\n",
    "                 method='train'):\n",
    "\n",
    "        self.root_path = root_path\n",
    "        self.im_list = sorted(glob(os.path.join(self.root_path, '*.jpg')))\n",
    "        if method not in ['train', 'val']:\n",
    "            raise Exception(\"not implement\")\n",
    "        self.method = method\n",
    "\n",
    "        self.c_size = crop_size\n",
    "        self.d_ratio = downsample_ratio\n",
    "        assert self.c_size % self.d_ratio == 0\n",
    "        self.dc_size = self.c_size // self.d_ratio\n",
    "\n",
    "        if is_gray:\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "            ])\n",
    "        else:\n",
    "            self.trans = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Pour CSRNet à vérifier si besoin de modif\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.im_list)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img_path = self.im_list[item]\n",
    "        gd_path = img_path.replace('jpg', 'npy')\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "        if self.method == 'train':\n",
    "            keypoints = np.load(gd_path)\n",
    "            return self.train_transform(img, keypoints)\n",
    "        elif self.method == 'val':\n",
    "            keypoints = np.load(gd_path)\n",
    "            img = self.trans(img)\n",
    "            name = os.path.basename(img_path).split('.')[0]\n",
    "            return img, len(keypoints), name\n",
    "\n",
    "    def train_transform(self, img, keypoints):\n",
    "        \"\"\"random crop image patch and find people in it\"\"\"\n",
    "        \n",
    "        \"\"\"\n",
    "        Les keypoints correspondent aux coordonnées des têtes\n",
    "        MAIS une troisième coordonnée a été calculée lors du preprocessing des données,\n",
    "        elle correspont à \"dis\" et semble important pour calculer pas mal de choses\n",
    "        \"\"\"\n",
    "        \n",
    "        wd, ht = img.size\n",
    "        st_size = min(wd, ht)\n",
    "        assert st_size >= self.c_size\n",
    "        assert len(keypoints) > 0\n",
    "        i, j, h, w = random_crop(ht, wd, self.c_size, self.c_size)\n",
    "        img = F.crop(img, i, j, h, w)\n",
    "        \n",
    "        nearest_dis = np.clip(keypoints[:, 2], 4.0, 128.0)\n",
    "       \n",
    "        points_left_up = keypoints[:, :2] - nearest_dis[:, None] / 2.0\n",
    "        points_right_down = keypoints[:, :2] + nearest_dis[:, None] / 2.0\n",
    "        bbox = np.concatenate((points_left_up, points_right_down), axis=1)\n",
    "        inner_area = cal_innner_area(j, i, j+w, i+h, bbox)\n",
    "        origin_area = nearest_dis * nearest_dis\n",
    "        ratio = np.clip(1.0 * inner_area / origin_area, 0.0, 1.0)\n",
    "        mask = (ratio >= 0.3)\n",
    "\n",
    "        target = ratio[mask]\n",
    "        keypoints = keypoints[mask]\n",
    "        keypoints = keypoints[:, :2] - [j, i]  # change coodinate\n",
    "        if len(keypoints) > 0:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "                keypoints[:, 0] = w - keypoints[:, 0]\n",
    "        else:\n",
    "            if random.random() > 0.5:\n",
    "                img = F.hflip(img)\n",
    "        return self.trans(img), torch.from_numpy(keypoints.copy()).float(), \\\n",
    "               torch.from_numpy(target.copy()).float(), st_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation of p(yn|xm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Post_Prob(Module):\n",
    "    def __init__(self, sigma, c_size, stride, background_ratio, use_background, device):\n",
    "        super(Post_Prob, self).__init__()\n",
    "        assert c_size % stride == 0\n",
    "\n",
    "        self.sigma = sigma\n",
    "        self.bg_ratio = background_ratio\n",
    "        self.device = device\n",
    "        # coordinate is same to image space, set to constant since crop size is same\n",
    "        self.cood = torch.arange(0, c_size, step=stride,\n",
    "                                 dtype=torch.float32, device=device) + stride / 2\n",
    "        self.cood.unsqueeze_(0)\n",
    "        self.softmax = torch.nn.Softmax(dim=0)\n",
    "        self.use_bg = use_background\n",
    "\n",
    "    def forward(self, points, st_sizes):\n",
    "        num_points_per_image = [len(points_per_image) for points_per_image in points]\n",
    "        all_points = torch.cat(points, dim=0)\n",
    "\n",
    "        if len(all_points) > 0:\n",
    "            x = all_points[:, 0].unsqueeze_(1)\n",
    "            y = all_points[:, 1].unsqueeze_(1)\n",
    "            x_dis = -2 * torch.matmul(x, self.cood) + x * x + self.cood * self.cood\n",
    "            y_dis = -2 * torch.matmul(y, self.cood) + y * y + self.cood * self.cood\n",
    "            y_dis.unsqueeze_(2)\n",
    "            x_dis.unsqueeze_(1)\n",
    "            dis = y_dis + x_dis\n",
    "            dis = dis.view((dis.size(0), -1))\n",
    "\n",
    "            dis_list = torch.split(dis, num_points_per_image)\n",
    "            prob_list = []\n",
    "            for dis, st_size in zip(dis_list, st_sizes):\n",
    "                if len(dis) > 0:\n",
    "                    if self.use_bg:\n",
    "                        min_dis = torch.clamp(torch.min(dis, dim=0, keepdim=True)[0], min=0.0)\n",
    "                        d = st_size * self.bg_ratio\n",
    "                        bg_dis = (d - torch.sqrt(min_dis))**2\n",
    "                        dis = torch.cat([dis, bg_dis], 0)  # concatenate background distance to the last\n",
    "                    dis = -dis / (2.0 * self.sigma ** 2)\n",
    "                    prob = self.softmax(dis)\n",
    "                else:\n",
    "                    prob = None\n",
    "                prob_list.append(prob)\n",
    "        else:\n",
    "            prob_list = []\n",
    "            for _ in range(len(points)):\n",
    "                prob_list.append(None)\n",
    "        return prob_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian Loss definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bay_Loss(Module):\n",
    "    def __init__(self, use_background, device):\n",
    "        super(Bay_Loss, self).__init__()\n",
    "        self.device = device\n",
    "        self.use_bg = use_background\n",
    "\n",
    "    def forward(self, prob_list, target_list, pre_density):\n",
    "        # print(\"problist\", prob_list[0].size())\n",
    "        # print(\"pre dense\", pre_density.size())\n",
    "        # print(\"target_list\", target_list)\n",
    "        loss = 0\n",
    "        \n",
    "        \"\"\"\n",
    "            - prob list semble être la listes des p(yn|xm) ie la contribution du pixel xm sur la n-ieme tête\n",
    "            (les lignes de cette matrice sont de taille 4096 = 64*64)\n",
    "            - pre density est la prédiction de la densité (sortie du réseau) - de taille 64x64 ici\n",
    "            - target list a pour longueur le nombre de têtes - correspond aux E[cn] \"réel\" (le calcul reste un mystère)\n",
    "            - On obtient les E[cn] estimées grâce à un produit terme à terme de prob_list et pre_density\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        for idx, prob in enumerate(prob_list):  # iterative through each sample\n",
    "            if prob is None:  # image contains no annotation points\n",
    "                pre_count = torch.sum(pre_density[idx])\n",
    "                target = torch.zeros((1,), dtype=torch.float32, device=self.device)\n",
    "            else:\n",
    "                N = len(prob)\n",
    "                if self.use_bg:\n",
    "                    target = torch.zeros((N,), dtype=torch.float32, device=self.device)\n",
    "                    target[:-1] = target_list[idx]\n",
    "                else:\n",
    "                    target = target_list[idx]\n",
    "                pre_count = torch.sum(pre_density[idx].view((1, -1)) * prob, dim=1)  # flatten into vector\n",
    "\n",
    "            loss += torch.sum(torch.abs(target - pre_count))\n",
    "        loss = loss / len(prob_list)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = 1.0 * self.sum / self.count\n",
    "\n",
    "    def get_avg(self):\n",
    "        return self.avg\n",
    "\n",
    "    def get_count(self):\n",
    "        return self.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets and DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: True \n"
     ]
    }
   ],
   "source": [
    "downsample_ratio = 8 # Mettre à 8 pour le réseau du répo (à 1 pour CSRNet puisque on ne modifie pas la dim avec le réseau)\n",
    "data_dir = \"SHHA\"\n",
    "# data_dir = \"/Users/VictoRambaud/dev/crowd_counting2/ProcessedData/SHHA\"\n",
    "crop_size = 256\n",
    "is_gray = False\n",
    "num_workers = 8\n",
    "batch_size = 10\n",
    "\n",
    "def train_collate(batch):\n",
    "    transposed_batch = list(zip(*batch))\n",
    "    # print(transposed_batch)\n",
    "    images = torch.stack(transposed_batch[0], 0)\n",
    "    points = transposed_batch[1]  # the number of points is not fixed, keep it as a list of tensor\n",
    "    targets = transposed_batch[2]\n",
    "    st_sizes = torch.FloatTensor(transposed_batch[3])\n",
    "    return images, points, targets, st_sizes\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())\n",
    "\n",
    "datasets = {x: Crowd(os.path.join(data_dir, x),\n",
    "                          crop_size,\n",
    "                          downsample_ratio,\n",
    "                          is_gray, x) for x in ['train', 'val']}\n",
    "\n",
    "dataloaders = {x: DataLoader(datasets[x],\n",
    "                            collate_fn=(train_collate if x == 'train' else default_collate),\n",
    "                            batch_size=(batch_size if x == 'train' else 1),\n",
    "                            shuffle=(True if x == 'train' else False),\n",
    "                            num_workers=num_workers,\n",
    "                            pin_memory=(True if x == 'train' else False))\n",
    "                            for x in ['train', 'val']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model / Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.0001\n",
    "weight_decay = 0.9\n",
    "sigma = 0.1\n",
    "use_background = False\n",
    "background_ratio = 1\n",
    "\n",
    "model = vgg19()\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "post_prob = Post_Prob(sigma,\n",
    "                           crop_size,\n",
    "                           downsample_ratio,\n",
    "                           background_ratio,\n",
    "                           use_background,\n",
    "                           device)\n",
    "criterion = Bay_Loss(use_background, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2589: UserWarning: nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample_bilinear is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter()\n",
    "\n",
    "image = Image.open('SHHA/train/IMG_1.jpg')\n",
    "trans1 = transforms.ToTensor()\n",
    "img = trans1(image).to(device)\n",
    "img = img.unsqueeze(0)\n",
    "\n",
    "# write to tensorboard\n",
    "\n",
    "writer.add_graph(model, img)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorboard --logdir=runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch = 0\n",
    "max_epoch = 20\n",
    "validation_epoch = 1\n",
    "val_start = 0\n",
    "save_dir = \"\"\n",
    "\n",
    "def train():\n",
    "    for epoch in range(start_epoch, max_epoch):\n",
    "        print('-'*5 + 'Epoch {}/{}'.format(epoch, max_epoch - 1) + '-'*5)\n",
    "        train_epoch(epoch)\n",
    "        if epoch % validation_epoch == 0 and epoch >= val_start:\n",
    "            val_epoch(epoch)\n",
    "        \n",
    "\n",
    "def train_epoch(epoch):\n",
    "    epoch_loss = AverageMeter()\n",
    "    epoch_mae = AverageMeter()\n",
    "    epoch_mse = AverageMeter()\n",
    "    epoch_start = time.time()\n",
    "    model.train()  # Set model to training mode\n",
    "    running_loss = 0.0\n",
    "    # Iterate over data.\n",
    "    for step, (inputs, points, targets, st_sizes) in enumerate(dataloaders['train']):\n",
    "        inputs = inputs.to(device)\n",
    "        st_sizes = st_sizes.to(device)\n",
    "        gd_count = np.array([len(p) for p in points], dtype=np.float32)\n",
    "        points = [p.to(device) for p in points]\n",
    "        targets = [t.to(device) for t in targets]\n",
    "        \n",
    "        # print(inputs.size())\n",
    "        # print(gd_count)\n",
    "        # print(points)\n",
    "        # print(targets)\n",
    "        # print(st_sizes)\n",
    "        \n",
    "        # inputs = image size(m, 3, crop_size, crop_size)\n",
    "        # gd_counts = [nb_of_head_img1, num_of_head_img2, ...]\n",
    "        # point = array of positions\n",
    "        # targets = ?\n",
    "        \n",
    "\n",
    "        with torch.set_grad_enabled(True):\n",
    "            outputs = model(inputs)\n",
    "            prob_list = post_prob(points, st_sizes)\n",
    "            loss = criterion(prob_list, targets, outputs)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "\n",
    "            N = inputs.size(0) # batch size\n",
    "            pre_count = torch.sum(outputs.view(N, -1), dim=1).detach().cpu().numpy()\n",
    "            res = pre_count - gd_count\n",
    "            \n",
    "            print(f'step: {step} | gd_count: {gd_count} | prediction: {pre_count} | loss: {loss}')\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            if step % 2 == 1:    # every 1000 mini-batches...\n",
    "\n",
    "            # ...log the running loss\n",
    "                writer.add_scalar('training loss vgg',\n",
    "                            running_loss / 2,\n",
    "                            epoch * len(dataloaders['train']) + step)\n",
    "                running_loss = 0.0\n",
    "            # epoch_loss.update(loss.item(), N)\n",
    "            # epoch_mse.update(np.mean(res * res), N)\n",
    "            # epoch_mae.update(np.mean(abs(res)), N)\n",
    "\n",
    "    # print('Epoch {} Train, Loss: {:.2f}, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "    #             .format(epoch, epoch_loss.get_avg(), np.sqrt(epoch_mse.get_avg()), epoch_mae.get_avg(),\n",
    "    #                     time.time()-epoch_start))\n",
    "\n",
    "def val_epoch(epoch):\n",
    "    epoch_start = time.time()\n",
    "    model.eval()  # Set model to evaluate mode\n",
    "    epoch_res = []\n",
    "    running_loss = 0.0\n",
    "    best_mse = 100000000000000\n",
    "    best_mae = 100000000000000\n",
    "\n",
    "    # Iterate over data.\n",
    "    for inputs, count, name in dataloaders['val']:\n",
    "        inputs = inputs.to(device)\n",
    "        # inputs are images with different sizes\n",
    "        assert inputs.size(0) == 1, 'the batch size should equal to 1 in validation mode'\n",
    "        with torch.set_grad_enabled(False):\n",
    "            outputs = model(inputs)\n",
    "            res = count[0].item() - torch.sum(outputs).item()\n",
    "            epoch_res.append(res)\n",
    "    \n",
    "            \n",
    "    running_loss = 0.0\n",
    "    epoch_res = np.array(epoch_res)\n",
    "    mse = np.sqrt(np.mean(np.square(epoch_res)))\n",
    "    mae = np.mean(np.abs(epoch_res))\n",
    "    \n",
    "                # ...log the running loss\n",
    "    writer.add_scalar('val MAE vgg',\n",
    "                        mae,\n",
    "                        epoch * len(dataloaders['val']))\n",
    "    writer.add_scalar('val MSE vgg',\n",
    "                    mse,\n",
    "                    epoch * len(dataloaders['val']))\n",
    "    \n",
    "    print('Epoch {} Val, MSE: {:.2f} MAE: {:.2f}, Cost {:.1f} sec'\n",
    "                 .format(epoch, mse, mae, time.time()-epoch_start))\n",
    "\n",
    "    model_state_dic = model.state_dict()\n",
    "    if (2.0 * mse + mae) < (2.0 * best_mse + best_mae):\n",
    "        best_mse = mse\n",
    "        best_mae = mae\n",
    "        print(\"save best mse {:.2f} mae {:.2f} model epoch {}\".format(best_mse,\n",
    "                                                                             best_mae,\n",
    "                                                                             epoch))\n",
    "        torch.save(model_state_dic, os.path.join(save_dir, 'best_model_vgg.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Epoch 0/19-----\n",
      "step: 0 | gd_count: [ 45. 140.   2. 172.  64.  18.  68.  76.  59.  34.] | prediction: [47.201492 54.46009  67.745605 37.82522  42.88755  52.49192  45.365654\n",
      " 57.99845  40.121384 59.44285 ] | loss: 59.54890823364258\n",
      "step: 1 | gd_count: [  8.  42.  46.  36.   9.   6. 138. 137. 105.  53.] | prediction: [36.02681  58.389755 52.527718 15.338438 16.306213 17.222683 41.62084\n",
      " 40.654545 44.01917  20.833183] | loss: 47.82880783081055\n",
      "step: 2 | gd_count: [ 87. 128.  84.  71.  20. 139.  83.  26.  48.  29.] | prediction: [50.686    40.238262 37.817917 45.785328 30.189236 47.218864 55.567574\n",
      " 30.30301  50.79026  36.39255 ] | loss: 39.39012908935547\n",
      "step: 3 | gd_count: [18. 61. 54.  8. 46. 22. 54. 20.  0. 93.] | prediction: [ 58.316944 151.03441  111.57718   28.993057  91.076614  61.371334\n",
      "  31.633179  58.8022    30.29679  153.08449 ] | loss: 49.6040153503418\n",
      "step: 4 | gd_count: [ 18.  47.  30.  36.  42.  30. 180.   9.   9.  23.] | prediction: [19.549196 32.649403 20.8181   24.955404 19.30333  15.533918 58.388474\n",
      " 11.536594 15.843528 18.12475 ] | loss: 23.082494735717773\n",
      "step: 5 | gd_count: [  9.  21. 108.  17.  35.  27.  22.  55.  38. 115.] | prediction: [ 8.967244  10.787337  19.042559   8.7809925 10.040044  14.045185\n",
      " 18.404465  13.17206   16.97714   26.380081 ] | loss: 30.4119930267334\n",
      "step: 6 | gd_count: [25. 87. 55. 12.  7. 27. 69. 42. 83.  5.] | prediction: [20.256355 27.798431 11.543627 16.472567 16.141724 22.554174 21.076332\n",
      " 15.447804 22.719017 23.371136] | loss: 28.935537338256836\n",
      "step: 7 | gd_count: [149.   0.  45.  42. 457.  16.  14.  31. 280. 365.] | prediction: [32.57631  11.324781  9.09074  27.830357 30.170967 12.260965 10.597633\n",
      "  9.444    45.595184 17.946562] | loss: 118.0188217163086\n",
      "step: 8 | gd_count: [201.   0. 118.  54. 233.  94. 257.  31.  26.  24.] | prediction: [77.76504  17.664734 65.1322   55.284332 39.512207 38.2045   94.37389\n",
      " 23.781416 15.160656 19.188782] | loss: 66.57085418701172\n",
      "step: 9 | gd_count: [ 68. 119. 104.  77.  38.  34.  46.  28. 114.  70.] | prediction: [ 86.67139  144.4739   110.19856   55.61058   93.95082   43.638252\n",
      "  75.70807   42.321045 136.23912   86.89041 ] | loss: 37.49913787841797\n",
      "step: 10 | gd_count: [  5. 258.  46.  56.  47.  36. 181.  29.  70.  18.] | prediction: [ 16.014042 142.94708   62.62782   48.551346  34.65674   47.2399\n",
      "  69.35435   52.685867  52.081985  25.074928] | loss: 41.2762565612793\n",
      "step: 11 | gd_count: [  8.  21.  85.  22.  28. 137.  41. 211.  17.  17.] | prediction: [11.051939 31.072016 27.052168 10.135859  9.190262 23.372894 23.805817\n",
      " 23.874372 19.885014 14.598019] | loss: 44.41884231567383\n",
      "step: 12 | gd_count: [ 99. 201. 161.  39.   4. 508. 121.  40. 155. 341.] | prediction: [ 22.59585   72.28449   39.69828   10.309309   7.910107  30.773842\n",
      "  26.809296  16.629383  21.6637   125.11291 ] | loss: 123.51273345947266\n",
      "step: 13 | gd_count: [ 82.  96.   6.  40. 183. 232. 171.  10.  55. 159.] | prediction: [22.979534 25.902401 14.044772 14.264528 77.58325  97.48747  47.022575\n",
      " 13.50827  20.12785  51.914776] | loss: 66.91513061523438\n",
      "step: 14 | gd_count: [164. 195.  43.   0. 127.   7.  31.  54.  89.  90.] | prediction: [69.46176  66.888664 31.314053 15.041925 50.76287  14.393667 26.149025\n",
      " 26.987354 38.479782 30.608154] | loss: 48.87394332885742\n",
      "step: 15 | gd_count: [ 56.  50.  20.  18.  91.  34. 100. 126.   6.  45.] | prediction: [35.508675 31.61718  26.749126 22.536425 70.639824 29.354084 68.49987\n",
      " 66.30379  17.08118  25.509972] | loss: 24.653573989868164\n",
      "step: 16 | gd_count: [ 45.  30.  26.  11.   4.   1. 328.  15.   4.  86.] | prediction: [ 32.185463  43.205296  30.491953  27.755287  57.33357   20.034779\n",
      " 236.69841   30.688585  18.758741 145.84016 ] | loss: 43.47180938720703\n",
      "step: 17 | gd_count: [166.   4.   2. 528.  38.  16.  74.  29.  27.  35.] | prediction: [160.66495    16.447353    7.7093763 207.22003    32.141808   25.60611\n",
      " 134.6        60.58477    51.83968    41.982586 ] | loss: 66.32054901123047\n",
      "step: 18 | gd_count: [157. 163.   7.  10.  29. 365. 206.  10.  27.  41.] | prediction: [147.68784   91.96153   15.483444  10.696457  37.442524 143.95741\n",
      " 148.54822   13.92817   17.023808  34.073853] | loss: 53.08308792114258\n",
      "step: 19 | gd_count: [ 32.  56.  31. 139.  88. 118.  21.  92.  16.  36.] | prediction: [ 16.229221   43.576515    8.940447  125.49553   151.18318    16.66035\n",
      "  10.152483   37.13858     7.6630754  16.514965 ] | loss: 38.103328704833984\n",
      "step: 20 | gd_count: [104.  34.  45. 213.   6. 131.  21. 143. 149. 139.] | prediction: [ 79.295395  25.328362  19.653467 144.26685    9.770058 110.001015\n",
      "  11.016472 158.27484   96.487076  86.85119 ] | loss: 47.78339767456055\n",
      "step: 21 | gd_count: [ 28. 354. 113.  29. 254.  40.  26.  22.   6. 106.] | prediction: [ 17.331171 110.40556   54.018627  16.099785 155.77316   19.922726\n",
      "  16.734602  18.726368  13.416739  32.16407 ] | loss: 54.69533157348633\n",
      "step: 22 | gd_count: [ 34.  32.  26.  21.  72.  44.  78.  23. 222.  11.] | prediction: [30.063673 17.939621 22.347622 18.10919  20.698309 24.379173 11.309363\n",
      " 24.757797 65.190544 23.380507] | loss: 36.0284423828125\n",
      "step: 23 | gd_count: [15. 15. 79.  7. 33. 49. 45. 41. 22.] | prediction: [19.67345  23.661465 46.700832 18.833536 22.0846   33.219383 31.16317\n",
      " 22.810202 27.942764] | loss: 17.924537658691406\n",
      "Epoch 0 Val, MSE: 314.92 MAE: 182.54, Cost 6.4 sec\n",
      "save best mse 314.92 mae 182.54 model epoch 0\n",
      "-----Epoch 1/19-----\n",
      "step: 0 | gd_count: [ 24. 213. 160.  50.  31.  94. 302. 114. 347.  48.] | prediction: [ 24.444786 273.31158   93.21484   20.307156  32.29872   62.554745\n",
      " 320.66595   79.78833  228.85869   23.20539 ] | loss: 56.70193099975586\n",
      "step: 1 | gd_count: [307. 238.  63.  26. 132.  51.  12.  15.  84.  23.] | prediction: [202.73859   63.756935  49.412064  25.926355 129.93546   46.651268\n",
      "  24.980877  28.04235   55.267357  33.57701 ] | loss: 45.24930953979492\n",
      "step: 2 | gd_count: [ 72.  35.  27.  23.   8. 201.  35.  24.  62. 172.] | prediction: [ 60.05783   24.174007  25.65757   26.944225  20.19965  117.44205\n",
      "  54.397568  31.675163  46.818436 135.73352 ] | loss: 26.942611694335938\n",
      "step: 3 | gd_count: [ 59.  20. 206.  39.  39.   3.  52.  20.  88.  28.] | prediction: [ 50.321743  24.368456 140.2588    46.244755  33.672543  14.750777\n",
      "  45.683563  31.692015  82.738785  37.363224] | loss: 22.13477897644043\n",
      "step: 4 | gd_count: [105. 208.  85.  50.  36.  22.  64.  85.  59.  29.] | prediction: [ 80.61367  117.21274   53.522263  30.052427  39.81881   29.686472\n",
      "  29.051758  82.7391    45.617874  48.681343] | loss: 30.940351486206055\n",
      "step: 5 | gd_count: [ 61.  41.  67.  16.  53. 385. 275.  29. 109.  72.] | prediction: [ 67.63387   59.48215   41.141487  13.104073  48.614372 192.2294\n",
      " 116.50253   57.140335  55.996475  60.394028] | loss: 57.96140670776367\n",
      "step: 6 | gd_count: [  6. 152. 149.  58. 219.   2.  55.  31.  38.  38.] | prediction: [  9.930433  176.27368   180.00104    62.641724  233.34317     5.7833867\n",
      "  44.15381    41.610546   39.795574   30.086792 ] | loss: 29.168289184570312\n",
      "step: 7 | gd_count: [ 11.  30. 157.   0. 258.   6.  56. 157.   0.  61.] | prediction: [ 16.598967  16.154724 106.645195  25.886196  99.97057   10.943075\n",
      "  33.760117 103.52463   21.016613  37.49923 ] | loss: 42.95562744140625\n",
      "step: 8 | gd_count: [222.  23.  59.  95.  14.  28. 110.  91.  46. 112.] | prediction: [108.92798   13.667295  41.697517 137.72205   16.512772  12.648662\n",
      "  66.9532    45.69609   23.307827  83.44998 ] | loss: 38.709861755371094\n",
      "step: 9 | gd_count: [ 11. 193. 245.  31. 115. 154.  29.  79. 327.  56.] | prediction: [  8.680103  86.18849  145.32422   14.919304  77.476234  92.26669\n",
      "  11.725535  45.517067 143.66936   21.200428] | loss: 60.33669662475586\n",
      "step: 10 | gd_count: [ 0.  1. 25. 32. 10. 12. 11. 78. 52. 17.] | prediction: [11.2830305  8.285023  26.98871   27.779686  15.733166  14.220558\n",
      " 14.332714  47.80424   49.269337  23.171852 ] | loss: 10.88408088684082\n",
      "step: 11 | gd_count: [ 15.   0. 277.  11.  43.  30.  14.  37.  44.   5.] | prediction: [ 17.01905     6.1371145 189.16177    11.361076   29.229023   11.83456\n",
      "  16.928293   46.124523   59.08486     6.470726 ] | loss: 23.83427619934082\n",
      "step: 12 | gd_count: [  0.   5.  68.  27. 122.   7.  21.   8.  46. 217.] | prediction: [  8.3587265   7.1095643  79.0114     11.191827  335.09235     5.166828\n",
      "  13.08756     6.1896105  35.46427   361.92264  ] | loss: 47.50386428833008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 13 | gd_count: [61.  7. 44. 55. 24. 56. 38. 74. 36. 27.] | prediction: [33.009186  6.487939 40.257225 38.1781    9.606043 40.20549  33.01216\n",
      " 39.49661  10.817812 18.578459] | loss: 16.268089294433594\n",
      "step: 14 | gd_count: [ 58. 103.  91.   2.  97. 204.  92.  73.   7.  95.] | prediction: [16.815567 54.43081  40.157677  9.700008 27.852978 66.29373  51.783287\n",
      " 43.658287  6.274604 93.303215] | loss: 43.2924919128418\n",
      "step: 15 | gd_count: [94. 36. 85. 40. 18. 24. 57. 11. 81. 36.] | prediction: [36.990303 14.196057 38.62406  22.134258 12.328886 14.97151  22.483286\n",
      " 13.805094 55.95852  24.395   ] | loss: 20.482662200927734\n",
      "step: 16 | gd_count: [  5. 510.  38. 190.  26.  57.   7.  54.   9.  81.] | prediction: [  9.335019 163.68451   21.53992   87.369675  19.848696  39.747425\n",
      "  15.057012  31.372494  15.44116   43.661995] | loss: 54.908912658691406\n",
      "step: 17 | gd_count: [ 44. 224.  83.   0.  47. 251.  42.  34.  18. 133.] | prediction: [ 52.758636 166.86923   52.24382   16.681894  32.238388 113.47652\n",
      "  39.571182  35.02576   25.025368 100.00572 ] | loss: 40.36103439331055\n",
      "step: 18 | gd_count: [ 77.  51. 277.  88.  28. 272.  68.  44.  69. 125.] | prediction: [ 87.57633   43.300655  68.081604  57.058037  29.782478 157.84167\n",
      "  77.98232   70.98421  100.00352  138.0815  ] | loss: 55.130950927734375\n",
      "step: 19 | gd_count: [ 55. 165.  54. 168.  31. 124.  37.  23.  47.  32.] | prediction: [ 68.128296 166.75586   81.98     119.775536  89.264496 105.98474\n",
      "  16.144707  49.97181   68.160255  21.012629] | loss: 43.782249450683594\n",
      "step: 20 | gd_count: [ 26.   0.   0. 318.  68.   3.  82.  45.  40. 114.] | prediction: [ 30.184185  12.408518  11.303222 157.359     58.36708   11.612406\n",
      "  65.24262   67.09393   41.003967  96.462524] | loss: 34.65615463256836\n",
      "step: 21 | gd_count: [23. 31. 17. 68. 55.  0. 10. 13. 39. 58.] | prediction: [21.83134  47.51904  23.174635 45.319313 50.783    13.032282 16.948507\n",
      " 24.987206 31.705692 39.320366] | loss: 14.550125122070312\n",
      "step: 22 | gd_count: [176. 120.  74.  43.  40.  25.  29.  89.  15.  34.] | prediction: [129.0828    66.970406  37.929443  41.019592  37.551746  31.51151\n",
      "  35.423786  56.09181   20.299473  32.092655] | loss: 26.321218490600586\n",
      "step: 23 | gd_count: [ 41.  19.   6. 112.  15. 307. 101. 131.   4.] | prediction: [ 36.38535    14.501764    6.6468506 182.7706     10.219385  178.82793\n",
      "  59.56927    77.93651    16.444986 ] | loss: 41.98434829711914\n",
      "Epoch 1 Val, MSE: 275.11 MAE: 165.48, Cost 6.4 sec\n",
      "save best mse 275.11 mae 165.48 model epoch 1\n",
      "-----Epoch 2/19-----\n",
      "step: 0 | gd_count: [165.  47.  12.   3.  24.  16.  30.  49.  24.  90.] | prediction: [112.84524   38.156094  14.948759   7.461751  19.372013  11.054544\n",
      "  19.626095  24.167397  29.806389  63.13346 ] | loss: 19.25508689880371\n",
      "step: 1 | gd_count: [16. 76. 32. 22. 51. 53. 31. 15. 22. 82.] | prediction: [16.134502 78.2856   23.612698 15.510259 39.35303  32.825504 22.607285\n",
      " 19.643635 17.218182 57.84351 ] | loss: 15.348698616027832\n",
      "step: 2 | gd_count: [ 40.  48.  58.  56.  54.  99.  88.  18.  57. 123.] | prediction: [ 18.62662   28.426506  40.377167  42.608276  20.442528  56.64324\n",
      "  63.530716  10.400551  12.198415 113.94164 ] | loss: 25.5098819732666\n",
      "step: 3 | gd_count: [ 42. 177.  45.   7.  39.  52.  54.   1.  43. 165.] | prediction: [ 21.659256  211.01624    37.99901     8.435562   18.474981   28.78915\n",
      "  37.69703     6.5523033  42.757458  129.9104   ] | loss: 24.650747299194336\n",
      "step: 4 | gd_count: [252.  36.   0.   8.  55.  18.  40.  51. 461.  45.] | prediction: [245.89133    32.055256    6.4852824   8.005142   30.92144    15.544491\n",
      "  30.520912   47.02877   319.07965    47.085625 ] | loss: 41.13370895385742\n",
      "step: 5 | gd_count: [ 39.   5. 408.  53.  15.  26. 130. 233.  31.   7.] | prediction: [ 45.428947  14.682943 226.31102   46.198986  18.365833  19.884438\n",
      "  99.14426  214.30519   25.177753  16.008873] | loss: 43.33114242553711\n",
      "step: 6 | gd_count: [ 44. 279.  27.  73.  68. 146.  40. 197.  14.   6.] | prediction: [ 28.830547 212.71292   30.85007   82.217255  61.906517 114.06906\n",
      "  73.035614 136.00275   21.85189   15.945637] | loss: 35.435176849365234\n",
      "step: 7 | gd_count: [ 34. 137.   0.  56.   4.   7.  15.  23. 639.  76.] | prediction: [ 26.92403    89.239334    4.7708907  46.194855   15.374923   17.746868\n",
      "  23.180923   22.141184  402.31085    51.706207 ] | loss: 41.84157943725586\n",
      "step: 8 | gd_count: [  5. 126.  27.  97.  36.  17. 139. 320.   0.   8.] | prediction: [  9.21101  109.297005  24.756313  72.04975   24.346008  18.336422\n",
      "  94.30317  150.15636   11.2405     8.599217] | loss: 34.70518112182617\n",
      "step: 9 | gd_count: [ 68. 221. 101.  77.  36.  28.  59. 207.  43.  21.] | prediction: [ 66.40115  154.48131   86.56521   68.4919    67.37525   32.005653\n",
      "  47.045258 222.87683   33.64215   19.788212] | loss: 37.04533386230469\n",
      "step: 10 | gd_count: [ 34.  17.  20. 148. 249.  32.  26. 120.  65.  78.] | prediction: [ 42.616844  11.143996  11.227042  67.41554  201.71616   20.110912\n",
      "  21.784094 100.85598   43.99995   51.922607] | loss: 32.05115509033203\n",
      "step: 11 | gd_count: [  0.  12. 119. 183.  59. 198.  23. 136.  58.  19.] | prediction: [  4.876606   5.793517  48.54571  136.45024   43.617043 151.44977\n",
      "  16.050186 168.14996   46.511063  13.442038] | loss: 31.85345458984375\n",
      "step: 12 | gd_count: [218.  43. 265.  20. 320. 125. 113.  38. 101.  30.] | prediction: [100.82211   30.177652  86.75536   13.679474 221.38858  134.82507\n",
      " 100.41402   24.09057   59.906578   9.780259] | loss: 59.42212677001953\n",
      "step: 13 | gd_count: [ 67. 239.  56. 237.  71.  15. 129.  31. 238.  60.] | prediction: [ 62.35972  240.8725    54.271366 169.53821   28.539814  14.354807\n",
      " 106.56722   18.702923 165.44446   79.61096 ] | loss: 41.54512023925781\n",
      "step: 14 | gd_count: [ 54.  17.  41.  99.  35.  79.  31.   3. 125.  11.] | prediction: [ 50.057743  19.199448  55.06618  102.03894   41.469566  82.177376\n",
      "  37.278755   9.378687 130.1799    19.921656] | loss: 19.987030029296875\n",
      "step: 15 | gd_count: [ 20.  43.   1.  36.  26.   4. 326. 159.  83.  46.] | prediction: [ 23.78871   45.769115   9.938457  20.450626  13.433155  13.824688\n",
      " 276.06433  129.71573   72.65178   45.934982] | loss: 28.17022705078125\n",
      "step: 16 | gd_count: [119.  46. 110.  42. 180.   9.  61.  12.  27.  96.] | prediction: [82.10026  30.494457 61.166245 34.695213 72.41812  10.127335 50.732513\n",
      " 11.017861 30.955173 63.4937  ] | loss: 29.330175399780273\n",
      "step: 17 | gd_count: [ 78. 579.   0.  19. 174. 341. 145. 118.  35. 138.] | prediction: [ 45.78708  167.20291    9.853531  14.576431  99.64461  226.62991\n",
      "  92.07115   70.546234  25.470848  80.5669  ] | loss: 84.13123321533203\n",
      "step: 18 | gd_count: [47.  6. 13. 58. 74. 19. 49. 20.  0.  0.] | prediction: [84.58926    8.712086  20.651344  55.05342   53.11717   18.56058\n",
      " 49.97667   26.8245    79.342865   3.9588823] | loss: 21.986433029174805\n",
      "step: 19 | gd_count: [ 76. 399.  80.  94.  18.  48.  10. 101.  30. 107.] | prediction: [ 99.02959  188.01077   92.42763   84.20822   15.674286  28.013508\n",
      "  12.222986  88.44872   32.615135 153.71762 ] | loss: 48.29608154296875\n",
      "step: 20 | gd_count: [165.  19. 107.  29.   1.  78.  22.  46.  50.  35.] | prediction: [174.77472    10.019728  109.369644   18.171759    5.4335155  61.490696\n",
      "   9.991116   54.28564    49.127014   19.616255 ] | loss: 19.321758270263672\n",
      "step: 21 | gd_count: [  0.  64.  10. 174.   6.  30.   0.   6.  33.  44.] | prediction: [  7.3308825  32.006622    5.1726127 126.01576     6.0549955  10.8305645\n",
      "   6.288397    7.243037   24.61373    16.818623 ] | loss: 14.690994262695312\n",
      "step: 22 | gd_count: [ 34.  67.  14. 292.  42.  14.  36.  82.  58.  32.] | prediction: [ 12.49611   44.409584  13.075699 120.85936   22.757786   9.644173\n",
      "  18.154442  44.275505  35.74421   21.736685] | loss: 30.8289794921875\n",
      "step: 23 | gd_count: [208.  61.  74.   0. 116.   4.  30.  40. 142.] | prediction: [126.70496   51.876648  41.43399    7.503648  62.588608   6.869074\n",
      "  39.272198  28.210289  69.29898 ] | loss: 33.88250732421875\n",
      "Epoch 2 Val, MSE: 296.54 MAE: 168.90, Cost 6.5 sec\n",
      "save best mse 296.54 mae 168.90 model epoch 2\n",
      "-----Epoch 3/19-----\n",
      "step: 0 | gd_count: [ 60.  49.  38.   0. 122. 199.   0.  48.   3.  12.] | prediction: [53.239494  38.696068  41.212      6.306056  88.37326   97.655205\n",
      "  3.4001932 56.680534   4.5270863 13.113208 ] | loss: 24.0017147064209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1 | gd_count: [19. 40. 61. 36. 39. 40. 24. 39. 94.  8.] | prediction: [28.121485 32.279324 58.447105 28.42448  49.990265 33.14125  18.04244\n",
      " 37.643303 59.46068  15.292013] | loss: 15.075759887695312\n",
      "step: 2 | gd_count: [292.  48.  62.  93.   4.  58. 182.  72.  47. 110.] | prediction: [109.838455  67.60857   55.318504  97.55666    6.628502  56.78998\n",
      " 155.84763   83.52777   62.18483   90.005196] | loss: 46.4315185546875\n",
      "step: 3 | gd_count: [ 45.  59. 100.   9.  27.  12.  22. 228.  35.  75.] | prediction: [ 45.131958  59.610878 111.45326    7.696452  25.519997  15.561861\n",
      "  17.600603 158.45549   21.251532  61.638813] | loss: 20.58091163635254\n",
      "step: 4 | gd_count: [ 26. 139.  22. 114.  99. 234. 206.  23.  57.  61.] | prediction: [ 20.48516  125.00051   16.538055  84.88945   63.382477 223.05624\n",
      " 217.89523   11.945097  35.21827   60.32328 ] | loss: 31.648767471313477\n",
      "step: 5 | gd_count: [ 13.  12. 122.  52.  28. 366.  13.  22.  25.   0.] | prediction: [ 11.074343   16.810843  143.15811    21.227516   24.170832  151.23523\n",
      "  12.783478   18.197205   20.206282    7.4970956] | loss: 37.3960075378418\n",
      "step: 6 | gd_count: [ 27.  10.  21.  60.  10.  13.   6.  39. 113.  39.] | prediction: [22.441761   9.610649  14.990988  28.186546   8.386314  11.199155\n",
      "  6.2118287 25.011677  69.37096   24.688461 ] | loss: 11.255943298339844\n",
      "step: 7 | gd_count: [112.  51.   0.  17.  22. 123. 114.  74.  48.  22.] | prediction: [ 62.288803   32.776764    7.745322   11.015522    5.7887225 107.937485\n",
      "  74.21118    50.807045   44.240402   18.448664 ] | loss: 23.454511642456055\n",
      "step: 8 | gd_count: [ 11.  78. 140.  42. 131.  39. 121.  11.  41.  62.] | prediction: [ 9.401825 64.219955  4.415522 26.558672 80.52775  49.24492  86.9335\n",
      " 10.519178 25.753468 47.427567] | loss: 31.620168685913086\n",
      "step: 9 | gd_count: [ 44.  79.  30.  12.  90. 258.   0.  49.  35. 203.] | prediction: [ 23.755293  47.540154  24.885035  13.831359  96.2605   115.5954\n",
      "   8.788406  58.924553  35.029877 172.32361 ] | loss: 31.042062759399414\n",
      "step: 10 | gd_count: [122.  82.  46.   4. 184.  83.  22.  80.  13.  17.] | prediction: [131.78511   55.17221   70.5154    11.374552 145.10356   78.4995\n",
      "  22.23575   86.72721   21.828522  21.859888] | loss: 31.63321304321289\n",
      "step: 11 | gd_count: [ 75.  73. 319. 136.  43.   1.  49.  72.  56.   8.] | prediction: [ 80.06377    80.8955    249.11375   138.10892    43.160355    6.3105016\n",
      "  76.00987    85.255875   48.656204    8.202642 ] | loss: 34.176353454589844\n",
      "step: 12 | gd_count: [ 48.  35.  59.  13.  25.  34. 263.   7.  29.  51.] | prediction: [ 40.297012   27.31406    28.162506    7.1166315  14.273127   23.602886\n",
      " 117.2527      7.016472   18.77724    40.32747  ] | loss: 24.08669090270996\n",
      "step: 13 | gd_count: [ 96.  35. 123.  44.  20.  33.  12.  21.  30.   1.] | prediction: [70.50889   21.00464   59.25702   36.922592  10.866522  23.170738\n",
      "  8.763848  11.8054085 25.312468   5.7535477] | loss: 15.887231826782227\n",
      "step: 14 | gd_count: [  0.   9.  37. 155.  85.  19.  91. 305.  73. 166.] | prediction: [ 11.956359  13.137982  18.542719  98.12056   42.47978   13.317717\n",
      "  37.539032 146.73843   34.75441   69.56433 ] | loss: 47.31959533691406\n",
      "step: 15 | gd_count: [ 34. 196.  77.  57.  41. 180.   2.  87.  28. 157.] | prediction: [ 20.43742  111.334564  56.549072  45.859375  27.390388 137.7804\n",
      "   6.323119  60.42266   21.579868  72.71217 ] | loss: 35.25304412841797\n",
      "step: 16 | gd_count: [ 67.  95. 154.   3.   2.   3.  25.  27.  32.  32.] | prediction: [ 74.76784   116.32509   152.48965     6.1276093   8.794594   10.967105\n",
      "  24.734974   24.704294   44.736526   36.572517 ] | loss: 18.80616569519043\n",
      "step: 17 | gd_count: [ 29. 542. 133. 198.  32.   2.   6.  25. 130.  18.] | prediction: [ 27.18739  874.94507  144.68004  309.83215   26.472828   4.189645\n",
      "   8.790848  25.658695 264.36093   15.990149] | loss: 80.75175476074219\n",
      "step: 18 | gd_count: [  4. 264. 257.   0.  61.  29.   8.   3.  15.  49.] | prediction: [ 10.2978325 127.09663   119.773865    4.583378   36.506527   22.975788\n",
      "  10.245516    6.7124405   7.4008665  41.738716 ] | loss: 32.76340866088867\n",
      "step: 19 | gd_count: [ 44.  79.  23. 236.  28.  10.  76. 136.  38.  64.] | prediction: [ 44.079735  37.729828  14.139508 104.35186   11.262239   6.60365\n",
      "  55.615654  52.80186   28.470139  38.438763] | loss: 32.45572280883789\n",
      "step: 20 | gd_count: [240.  49.  20.  23.  23.  62.  38. 422.  73.  49.] | prediction: [94.60611  32.104717 12.348255 19.10856  10.133528 50.687584 20.877914\n",
      " 60.48477  80.866    24.629528] | loss: 59.50046920776367\n",
      "step: 21 | gd_count: [ 73.   1. 207.  72. 115.  59. 117.   5.  54.  39.] | prediction: [46.04425    5.4743967 46.640167  36.846046  90.34671   57.838585\n",
      " 69.93315    7.5384483 61.790398  42.9234   ] | loss: 35.342430114746094\n",
      "step: 22 | gd_count: [343.   0.  29. 129.  41. 104.  45.  49. 631.   2.] | prediction: [ 54.5213     4.880047  34.86705   50.516087  79.71307   96.4841\n",
      "  53.897087  46.80062  100.21491    4.030224] | loss: 100.08656311035156\n",
      "step: 23 | gd_count: [ 15.  45.  36.  59. 140.  35. 128.  37.  15.] | prediction: [ 20.26348   64.73941   39.33864   47.34192  106.40095   43.973984\n",
      "  93.046364  60.738117  16.260765] | loss: 23.263690948486328\n",
      "Epoch 3 Val, MSE: 332.66 MAE: 187.68, Cost 6.5 sec\n",
      "save best mse 332.66 mae 187.68 model epoch 3\n",
      "-----Epoch 4/19-----\n",
      "step: 0 | gd_count: [ 80.  42. 249. 122.   9.  35.  33.  79.  61.   4.] | prediction: [ 62.6141    60.800507 135.17912   82.30351    9.877829  31.226929\n",
      "  66.85659   66.974594  53.034004  11.422405] | loss: 33.00861740112305\n",
      "step: 1 | gd_count: [  2.  21.  18.  40.  49.  67. 209. 104. 170.  37.] | prediction: [ 5.24473   9.042776 12.785818 32.91499  37.82045  20.755787 88.833176\n",
      " 89.86034  66.49953  26.248854] | loss: 34.626338958740234\n",
      "step: 2 | gd_count: [ 17. 198.  72.  49. 128.   3.  44. 478. 118. 189.] | prediction: [ 11.632229  112.08231    51.064262   22.325087   74.05976     6.0676193\n",
      "  33.357956   82.093056   62.050163  107.36943  ] | loss: 73.41048431396484\n",
      "step: 3 | gd_count: [ 96.  37.  60. 177.  44.  56.  61.   7.  13.  64.] | prediction: [ 76.29635   27.77535   77.99799  128.43362   56.493305  48.88573\n",
      "  81.225945   4.617678  17.505854  56.935856] | loss: 25.196758270263672\n",
      "step: 4 | gd_count: [141. 139.  74.  50.  72.  45.   8.  86.  13. 133.] | prediction: [115.85847   97.970245 114.13965   56.54006   78.9825    41.800407\n",
      "  11.092106  20.514814   8.528116 144.36102 ] | loss: 34.71136474609375\n",
      "step: 5 | gd_count: [ 26.  56.  66.  61. 414. 104.   9.  27.  12. 293.] | prediction: [ 20.775013   67.107544   36.164604   23.574738  108.69948    58.806057\n",
      "   6.6460342  11.389151   11.928459  120.374    ] | loss: 62.628273010253906\n",
      "step: 6 | gd_count: [ 73.  38.   8.   6.  21. 405.  16. 127. 113. 154.] | prediction: [22.781029  17.744709   8.623007   4.9200416 18.985245  98.92383\n",
      " 10.677031  67.90046   54.089485  65.10238  ] | loss: 57.79368209838867\n",
      "step: 7 | gd_count: [ 64.  51.  23.  72. 168.  30.  37.  17.   2.  31.] | prediction: [ 57.657513  33.875572  22.918201  63.56778  113.44556   29.673502\n",
      "  25.380266  16.962158   5.026593  30.481651] | loss: 15.372298240661621\n",
      "step: 8 | gd_count: [ 35.   3.  13.  34.  74.  14. 249.   4.  14.  86.] | prediction: [ 25.208548    5.569916   15.146687   24.095646  125.21856    12.2142105\n",
      " 315.45486     7.8244276  23.497612   78.91944  ] | loss: 26.189279556274414\n",
      "step: 9 | gd_count: [ 55.  13.  43.   1. 200. 113.  67.  82.   6.  49.] | prediction: [ 32.41959     9.874744   44.025627    4.6472025 207.65628   109.4158\n",
      " 133.91129    54.100906    7.3862896  32.70867  ] | loss: 28.572711944580078\n",
      "step: 10 | gd_count: [ 39.  30.   0.  11.   7. 112. 152.  67.  15. 185.] | prediction: [31.927635  14.461487   4.3899097  4.7918215  2.5954938 42.83305\n",
      " 45.217587  33.53428    6.6562967 57.66731  ] | loss: 35.05045700073242\n",
      "step: 11 | gd_count: [13. 57. 15. 21. 51.  6. 17.  7. 77. 36.] | prediction: [13.602221  33.903755   5.261347  18.236681  36.383324   3.8931026\n",
      "  9.759534   5.423896  28.679932  21.19701  ] | loss: 10.880887985229492\n",
      "step: 12 | gd_count: [322.  25. 166.  95. 108.  29. 133. 152. 157.  84.] | prediction: [49.726105 22.944973 58.45238  27.564632 60.709587 33.521378 43.136497\n",
      " 62.384014 54.089996 46.253452] | loss: 78.76195526123047\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 13 | gd_count: [ 40.  97. 134.  18. 427.  12. 107.  20. 174.  12.] | prediction: [50.516125 65.76688  50.02817  45.63752  76.47659  20.806725 29.181297\n",
      " 37.8542   78.3365   26.00324 ] | loss: 75.46580505371094\n",
      "step: 14 | gd_count: [ 26.  52.  27.  30. 283. 118.  36. 109. 103.   5.] | prediction: [42.095978  65.0597    61.156105  19.591694  52.280228  17.917995\n",
      " 47.2745    41.363743  84.34032    4.4949703] | loss: 53.8752326965332\n",
      "step: 15 | gd_count: [ 42.  47. 100.  76.  29.  96.  22.  52.  27.  19.] | prediction: [33.859    23.24554  33.500145 28.698656 13.271954 70.58922  16.760408\n",
      " 57.615307 13.511316 10.262478] | loss: 21.234189987182617\n",
      "step: 16 | gd_count: [ 63.  84. 191.  65. 143.   9.  51.  65.  89.  49.] | prediction: [ 48.317635  43.936577  75.162544  70.07887  109.82922    5.310277\n",
      "  38.77464   56.29883   11.8911    25.199785] | loss: 41.47551345825195\n",
      "step: 17 | gd_count: [ 33.  21.  53.  93. 112.  64.  49.  45.  32.   5.] | prediction: [ 33.582703  35.45185   75.44533   57.07278  108.06088   64.253586\n",
      "  70.685234  35.075005  33.548187  13.854274] | loss: 24.449623107910156\n",
      "step: 18 | gd_count: [ 15. 157.  30.  52.  41.  93.  44.  17.  19.  77.] | prediction: [ 7.2298036 92.08628   18.270596  39.399868  18.392756  52.471367\n",
      " 17.15632    9.682167  10.171719  35.574516 ] | loss: 23.078203201293945\n",
      "step: 19 | gd_count: [ 63.  24.  14.  10.  91. 104.   5.  40. 132. 193.] | prediction: [14.177143   7.6739597  8.352765   7.560231  45.321983  69.71449\n",
      "  5.5290127 22.811241  28.323744  51.36979  ] | loss: 37.41744613647461\n",
      "step: 20 | gd_count: [ 75. 119.   0.  53. 336.  18. 142. 155.  53.  28.] | prediction: [36.091736  68.36813    3.6622806 31.69585   59.31421   16.317415\n",
      " 64.898705  36.968845  39.068314  28.729782 ] | loss: 59.3319206237793\n",
      "step: 21 | gd_count: [ 41.  10. 148. 228.  74. 122.  42.  41. 121.   7.] | prediction: [ 53.845596  25.305084  86.68932  134.2232    79.72821  200.7248\n",
      "  57.782272  52.155987 130.88121   27.518593] | loss: 48.36384201049805\n",
      "step: 22 | gd_count: [ 54.  18.  23.   9. 101.  34. 163.  36. 316. 353.] | prediction: [ 75.5972    30.155502  41.451088  18.84583   66.43873   58.91387\n",
      "  74.67384   67.12753  165.90057  185.50034 ] | loss: 72.46003723144531\n",
      "step: 23 | gd_count: [233.   3.  33.  28. 536.  13.  79.  41. 111.] | prediction: [ 64.65788     5.6183424  37.25171    32.732048  176.94708    19.874329\n",
      "  56.337288   42.84278    91.59976  ] | loss: 70.94772338867188\n",
      "Epoch 4 Val, MSE: 317.19 MAE: 176.30, Cost 6.6 sec\n",
      "save best mse 317.19 mae 176.30 model epoch 4\n",
      "-----Epoch 5/19-----\n",
      "step: 0 | gd_count: [ 39.   0.  56.  43. 191. 107.  45.  25.  12.   7.] | prediction: [28.969875   3.8114893 34.47584   31.184284  55.497425  46.528103\n",
      " 28.214394  26.770826   8.910945  12.706527 ] | loss: 27.677167892456055\n",
      "step: 1 | gd_count: [52. 19. 24. 65.  5. 14.  0. 55. 67. 84.] | prediction: [31.904781  15.8548765 22.654825  31.78598    7.2477655  8.184505\n",
      " 12.339428  20.235294  17.814938  48.55199  ] | loss: 17.892166137695312\n",
      "step: 2 | gd_count: [ 29.   5. 165.  33.  28.  37.   6.  33.  20.   7.] | prediction: [24.440735  8.258047 58.01201  31.760054 17.47889  22.084927  6.851038\n",
      " 14.615498 19.764988  9.949148] | loss: 19.55586051940918\n",
      "step: 3 | gd_count: [200.  70.  10.  49. 120.  96.   9.  40. 167. 447.] | prediction: [126.657776  128.77534    12.892669   45.207756   49.67794   107.546135\n",
      "   6.8786583  33.120804  130.29007   238.01695  ] | loss: 63.58740234375\n",
      "step: 4 | gd_count: [ 10.  78.  42.  68. 266.  55. 269.  26. 130.   0.] | prediction: [ 10.743092  60.148125  28.04893   64.266624 179.84026   43.721363\n",
      " 277.25946   34.770264  78.21811    5.970648] | loss: 42.359920501708984\n",
      "step: 5 | gd_count: [ 48.  42.  88.  64.  40. 170.  63.  34.  36. 244.] | prediction: [ 29.527515  34.31054   81.923874  39.693     43.333828  65.08256\n",
      "  39.12758   24.641912  12.049188 240.98753 ] | loss: 33.29585647583008\n",
      "step: 6 | gd_count: [ 10. 188.  28.  14. 100.  51. 108.   9.  20.  33.] | prediction: [ 9.31131  69.074684 22.93615  18.283493 60.66269  25.957    83.79709\n",
      " 12.856059 10.273552 20.350113] | loss: 26.115158081054688\n",
      "step: 7 | gd_count: [ 32.  93. 114.  68.  54.  73.  49.  41.  86. 187.] | prediction: [ 28.927204  34.50813   59.065125  43.62655   29.445961  35.222218\n",
      "  39.47336   22.475647  41.57499  113.91925 ] | loss: 34.44702911376953\n",
      "step: 8 | gd_count: [170.  59.  33.   3.   9.  12.   0. 295.  61. 213.] | prediction: [101.4518    35.713852  36.424515  11.990238  23.063473  26.333168\n",
      "  12.346202 110.82547   44.75178   98.768036] | loss: 48.10105514526367\n",
      "step: 9 | gd_count: [ 44.   8.  39.  94. 121.  27.   6.  29.  33. 281.] | prediction: [ 86.326385  16.678532  59.59375  227.54758   70.15888   53.136208\n",
      "  21.443666  42.624218  36.63633  177.89874 ] | loss: 55.02307891845703\n",
      "step: 10 | gd_count: [ 87. 135.  20.  70. 196.  23.  61. 245.  96.   9.] | prediction: [ 85.340454 189.91544   26.594387  87.61467  246.23187   28.218765\n",
      "  72.90361  257.5424   135.92184   11.990424] | loss: 54.5479850769043\n",
      "step: 11 | gd_count: [ 90.  21.  13.   2.   0.  47.   8.   9. 111.  49.] | prediction: [60.378742  11.20709    5.865376   4.601713   2.684967  29.777126\n",
      "  4.7864723  6.435114  62.7294    21.972939 ] | loss: 14.958098411560059\n",
      "step: 12 | gd_count: [  8.   4.   3. 411.  55.  30. 188. 130.  24. 115.] | prediction: [ 7.4642363 11.445502  10.064665  33.17341   12.592153   6.0156364\n",
      " 36.963528  42.102016   6.1769724 35.528965 ] | loss: 75.29742431640625\n",
      "step: 13 | gd_count: [ 28.  37.  12.  16.   3.  10. 275.  13.  20. 152.] | prediction: [15.13803   12.6882105  9.876614   7.7620144  4.9390025  8.523264\n",
      " 77.29703    9.583714   5.7822433 21.441162 ] | loss: 38.230873107910156\n",
      "step: 14 | gd_count: [ 44. 308.  16. 118.  58.  46.  12.  35. 182.  20.] | prediction: [ 9.83078   75.290146   7.8735375 38.1864    17.489044  21.681435\n",
      "  5.007385   8.755407  45.966354   5.498155 ] | loss: 55.85511016845703\n",
      "step: 15 | gd_count: [  9. 149.  16. 129. 137.   0. 105.  31.  17.  39.] | prediction: [ 5.0156965 65.600525   6.1522527 41.75164   65.91427    2.808227\n",
      " 55.722366  16.571205   7.2151136  6.82081  ] | loss: 33.327999114990234\n",
      "step: 16 | gd_count: [ 35. 228.  10.  34.  21. 105.  41.  35.  12.  60.] | prediction: [32.75134   72.57041    7.5011024 20.694191  19.348467  41.566574\n",
      " 33.694656  40.154804  13.5710125 52.800636 ] | loss: 27.662145614624023\n",
      "step: 17 | gd_count: [  1.  60.  35. 287.  54.  46.  20.  42. 122.  33.] | prediction: [ 3.2482429 43.981964  46.206673  93.74303   60.572998  35.675232\n",
      " 23.106369  48.79531   71.92821   49.43844  ] | loss: 39.38679122924805\n",
      "step: 18 | gd_count: [ 64.  64.  24.  15. 256.  57. 111.  44.  58.   2.] | prediction: [ 59.565727   64.69079    37.99077    39.234955  122.343506   55.083664\n",
      "  97.54596    61.116436   56.16749     3.6679928] | loss: 32.975032806396484\n",
      "step: 19 | gd_count: [ 59. 425.  96.   7.   0.  14.  68.  62.  64.  98.] | prediction: [ 87.939316  93.672745  71.37294   16.35179    6.089297  19.95158\n",
      "  72.87526   38.52717   63.990997 110.79671 ] | loss: 54.87825393676758\n",
      "step: 20 | gd_count: [158.  22.  10.  36. 144.  75.  27. 120.  53.  39.] | prediction: [102.573074  40.89602   10.933154  54.64561   47.928963  59.456703\n",
      "  42.039124  97.203064  54.358627  50.17001 ] | loss: 33.07777786254883\n",
      "step: 21 | gd_count: [  8. 133.   2. 141.  65.  19. 132.  55.  62.  35.] | prediction: [11.336468 96.20746   9.483742 93.446045 41.897316 17.165428 63.79653\n",
      " 54.79995  56.235573 65.58819 ] | loss: 27.501728057861328\n",
      "step: 22 | gd_count: [ 32.  86.  69.  60.  19.  11.  14. 196.  48.  23.] | prediction: [13.690533 64.70388  55.126244 66.77321  20.32315  10.377236 13.236127\n",
      " 99.224014 43.512955 35.12081 ] | loss: 24.633209228515625\n",
      "step: 23 | gd_count: [ 57. 166.  13.  75. 128.  57.  15.  19.  85.] | prediction: [ 42.819687 102.69092   13.754761  67.02304   83.88109   43.992863\n",
      "   9.578123  11.123942  57.535625] | loss: 23.7601261138916\n",
      "Epoch 5 Val, MSE: 307.02 MAE: 175.30, Cost 6.7 sec\n",
      "save best mse 307.02 mae 175.30 model epoch 5\n",
      "-----Epoch 6/19-----\n",
      "step: 0 | gd_count: [42. 44.  3. 70. 30.  5. 29. 28. 76.  1.] | prediction: [35.23282   32.6728     3.7239437 38.00387   19.23164    5.749406\n",
      "  8.231465  20.058546  42.693504   2.6575537] | loss: 12.36965560913086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 1 | gd_count: [ 53.   7. 151.  74. 248. 146.  26.  24.  41.  74.] | prediction: [ 51.819008    7.9714704  90.158615   63.874187  157.06012   142.57199\n",
      "  21.812302   23.899836   26.877457   73.23111  ] | loss: 29.04669189453125\n",
      "step: 2 | gd_count: [ 70.  55.  32.  58.   5. 329.   6.   3.  66. 213.] | prediction: [ 66.446655  60.67163   40.61698   87.06238   12.158604 223.58356\n",
      "  11.30558   17.920301  70.4306   128.99815 ] | loss: 35.39836502075195\n",
      "step: 3 | gd_count: [ 68.  98.  29. 186.  45.  47.  68.  77.  33.  25.] | prediction: [ 86.24136   73.96974   16.427973 145.31711   38.181625  45.938206\n",
      " 106.08855   62.14646   39.923637  25.034433] | loss: 28.346662521362305\n",
      "step: 4 | gd_count: [  0.   0.  23. 199. 216.  24. 161. 172.  15.  46.] | prediction: [  6.189595    6.23643    23.036364  132.11678   173.0786     25.670797\n",
      " 154.02805   181.08131    15.5499115  72.4321   ] | loss: 32.192108154296875\n",
      "step: 5 | gd_count: [ 52.  31. 325.  34.  26. 204.   1. 118.  60.   7.] | prediction: [ 37.446304   22.792805  192.51674    20.977034   24.476894  150.28708\n",
      "   2.5797455  93.76886    74.99362     8.808556 ] | loss: 32.8830451965332\n",
      "step: 6 | gd_count: [ 41. 350. 143.  32.   7.  85.  25.  25.   0.  17.] | prediction: [ 24.22464   165.203     101.059906   16.275595    4.0333233  37.507782\n",
      "  13.438777   18.425476    7.5599775  13.33462  ] | loss: 34.027915954589844\n",
      "step: 7 | gd_count: [ 83.  52.  42.  31.   2.  56.  21. 139.  45.  19.] | prediction: [55.78289   28.140945  23.390728  19.525677   5.9789715 23.29071\n",
      " 10.084797  97.848816  26.789991  10.3676815] | loss: 17.782255172729492\n",
      "step: 8 | gd_count: [ 44.   2.  52.   0.  79. 105.   5.  31.  18.   4.] | prediction: [21.221012   3.7775187 36.662148   7.371429  45.765087  78.92031\n",
      "  4.614581  26.06567   12.425377   5.1699724] | loss: 12.632471084594727\n",
      "step: 9 | gd_count: [152.   1.  92.  12.  23.  29.  43.  53.  52.   4.] | prediction: [155.76736     5.3246613 106.579834   10.328123   22.360378   25.567371\n",
      "  36.137474   42.835922   42.91043     8.497949 ] | loss: 16.219449996948242\n",
      "step: 10 | gd_count: [ 12.  61.  22.  49.  21.  36.  15.  26. 146.  31.] | prediction: [14.461197 39.52404  37.82823  29.345825 26.999329 31.084671 34.0466\n",
      " 33.925846 83.10741  30.199553] | loss: 20.826101303100586\n",
      "step: 11 | gd_count: [ 46.  84.  45.  88.  11.  42.  68. 104.  55.  82.] | prediction: [39.80554  83.8905   58.615303 90.2042   17.846607 34.16582  62.41794\n",
      " 59.354263 46.96117  62.464893] | loss: 23.234024047851562\n",
      "step: 12 | gd_count: [407.   7.   5. 114.   7.   4.  36.  65. 301.  63.] | prediction: [164.07083   15.763002   8.94301  121.86065    9.057882  12.964537\n",
      "  29.627178  64.951126 169.55702   60.083008] | loss: 54.353614807128906\n",
      "step: 13 | gd_count: [ 17.   3.  11.  46. 247.  85.  29.  17.  23.  41.] | prediction: [  8.9921875   6.9468365   7.2877593  32.106285  143.64001    64.99108\n",
      "  22.994835    6.1167035  25.769897   41.354805 ] | loss: 19.820859909057617\n",
      "step: 14 | gd_count: [160.  37.  30.  96. 235.  78.  13. 150.  74.  81.] | prediction: [132.74559   29.066015  12.513172  91.30405  142.5434    78.173065\n",
      "   7.588374  72.82824   39.818035  66.84036 ] | loss: 40.14535140991211\n",
      "step: 15 | gd_count: [ 72. 110.  32.  76.  20.  24. 125.   8.  37.  28.] | prediction: [ 58.39747   66.62842   42.14156   53.588158  22.179588  17.055084\n",
      " 106.61342    8.262651  28.562168  21.78255 ] | loss: 16.6040096282959\n",
      "step: 16 | gd_count: [ 41.  32. 101.  83.  52.   2.   0.  40. 210.  98.] | prediction: [ 43.91091    18.778143   55.320156   50.001724   39.886574    8.198474\n",
      "   5.4076533  40.31932   201.68529    54.4771   ] | loss: 25.574140548706055\n",
      "step: 17 | gd_count: [  6.   4.  10.  37. 386.   8. 143.  11.  43.  29.] | prediction: [  6.8968077   8.170729    7.1974287  29.72456   209.5177      5.9846582\n",
      " 116.313385   18.824503   42.572346   36.473797 ] | loss: 29.811115264892578\n",
      "step: 18 | gd_count: [ 76.  16.   7.  43.  55. 222.  10.  60. 129.  30.] | prediction: [ 71.11075    16.538303    6.276813   48.260788   48.29444   171.99678\n",
      "   7.2236643  37.747276  115.71358    28.348862 ] | loss: 21.909067153930664\n",
      "step: 19 | gd_count: [ 97.  16.  99. 175. 104.  35.  11.  61.  31. 445.] | prediction: [ 84.970634  28.202806  87.41765  119.52131  102.570206  37.839104\n",
      "  17.624662  82.48364   30.260042 410.08334 ] | loss: 49.946533203125\n",
      "step: 20 | gd_count: [  4.  73.  24. 105.  12.  87.  47. 292.   8.  56.] | prediction: [  3.5406132  49.89621    20.098396   55.190964   10.882072   57.982407\n",
      "  32.335884  224.24913     6.540944   33.888756 ] | loss: 24.91935157775879\n",
      "step: 21 | gd_count: [ 16.  70.  81.  50.  40.  10. 101.   0.  95. 230.] | prediction: [ 10.279087  36.61761   39.980618  34.05617   23.603313   8.603792\n",
      "  35.07885    5.947784  66.86232  109.69095 ] | loss: 31.17014503479004\n",
      "step: 22 | gd_count: [ 42.  53.  78.  25.  15.  48.  59.   2.  31. 130.] | prediction: [61.307865 27.01197  63.39698  11.266755 13.867061 38.02085  40.592056\n",
      "  5.565797 19.952187 75.58193 ] | loss: 21.630325317382812\n",
      "step: 23 | gd_count: [113.  29. 301.  27. 358.  46.  61.   8.   6.] | prediction: [ 80.34438   58.864513 170.63988   27.355669  87.56012   65.46873\n",
      "  68.3407     7.059458   7.858966] | loss: 59.99423599243164\n",
      "Epoch 6 Val, MSE: 248.86 MAE: 143.62, Cost 6.7 sec\n",
      "save best mse 248.86 mae 143.62 model epoch 6\n",
      "-----Epoch 7/19-----\n",
      "step: 0 | gd_count: [25. 38. 28. 50. 78. 18. 35. 20. 11. 63.] | prediction: [12.472556  26.085316  29.347504  46.99398   74.87071   18.073341\n",
      " 36.944397  13.600481   6.3755417 17.521858 ] | loss: 14.573687553405762\n",
      "step: 1 | gd_count: [ 17.  57.   9.  32.  48. 212.  46.  36.   0.  13.] | prediction: [ 20.495678   69.26503     6.5481415  15.273508   55.54898   222.47913\n",
      "  76.15656    20.278297    3.0636716  12.075365 ] | loss: 20.16530990600586\n",
      "step: 2 | gd_count: [ 19. 127.  92.  67.  19.  28.  68.  53.  26.  21.] | prediction: [ 10.517496 128.48383   67.22634   56.046368   5.825994  36.23609\n",
      "  52.931694  66.01663   32.550285  14.446462] | loss: 20.285167694091797\n",
      "step: 3 | gd_count: [ 82.  11. 125. 214.  38.  26.  35. 101.  88. 194.] | prediction: [ 62.088203   8.67811  133.02252  244.6539    15.736752  12.215389\n",
      "  20.252056  81.61981   65.85814  111.37029 ] | loss: 34.33590316772461\n",
      "step: 4 | gd_count: [ 21.  91.  63. 195. 211.  33.   1. 261.  74.  73.] | prediction: [ 14.599819   74.41208    54.54679   172.17938   127.02153    15.330839\n",
      "   4.1568747 120.27966    36.20898    13.56265  ] | loss: 42.417762756347656\n",
      "step: 5 | gd_count: [141.  33.  21.  24.  45.  58. 132.  37.  17.  74.] | prediction: [ 75.58265   28.830053  19.671434  16.163757  24.803165  24.752182\n",
      " 104.89731   22.725372  20.917606  49.146244] | loss: 22.961082458496094\n",
      "step: 6 | gd_count: [ 23.  83.   0.  55.  88. 159.  67.  49.  84.  64.] | prediction: [ 11.564156  55.891365   4.638912  34.294037  44.118187 119.52356\n",
      "  49.240547  37.972034 122.51911   44.210102] | loss: 26.655710220336914\n",
      "step: 7 | gd_count: [ 10. 252. 324.  38.  28.   5.  41.   4.  85.  14.] | prediction: [ 15.558519  98.686775 174.28806   34.383842  25.854443   8.826042\n",
      "  59.852463  11.892086  76.12914   29.126316] | loss: 43.15009689331055\n",
      "step: 8 | gd_count: [ 13.   4. 199.   8.  33.  49.   6.  26.  23.   3.] | prediction: [ 23.26226    14.252167  193.20105    17.834133   50.719757   43.110207\n",
      "   3.7244122  38.52735    32.993023    7.035941 ] | loss: 18.118322372436523\n",
      "step: 9 | gd_count: [ 49.  62.  66.   9. 103.  88. 162.  14. 108. 121.] | prediction: [ 44.683586  94.40399  101.89847   17.267345  99.55339  109.99771\n",
      " 136.7681    10.95092  119.09626  123.507355] | loss: 30.363346099853516\n",
      "step: 10 | gd_count: [  2.  25.  18. 286.  31. 179.  77.   9.   8.  88.] | prediction: [  8.769777   23.704441   21.887545  200.9476     28.002567  102.39761\n",
      "  59.147484   11.768953    8.3306675  56.780262 ] | loss: 25.044729232788086\n",
      "step: 11 | gd_count: [ 20.  51. 130.  14.  19.  11.  31.  13.  10. 111.] | prediction: [13.182594  28.80545   64.58394   11.987762  20.208181   7.75733\n",
      " 14.058736   7.5669756  8.177835  88.034966 ] | loss: 16.129898071289062\n",
      "step: 12 | gd_count: [ 28.  19.  36.  36.  32. 183.  80.  37.  35.  70.] | prediction: [11.918008 14.833206 22.013565 27.844507 12.26304  74.841354 53.301117\n",
      " 15.632805 41.85842  44.819687] | loss: 23.742080688476562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 13 | gd_count: [  2.  47. 225.   2.  31.  21.   8. 170.  34.  21.] | prediction: [  8.902566   28.496017  120.755905    7.2877636  21.226913   12.218559\n",
      "   5.844732  129.2135     23.95853    10.938029 ] | loss: 25.30819320678711\n",
      "step: 14 | gd_count: [180.  46. 159.  34. 118.  21.  10.   7.  33. 427.] | prediction: [112.958305  36.348434 118.64054   28.60606   93.83893   28.14061\n",
      "  13.041901   8.259262  39.55452  371.21252 ] | loss: 36.37187194824219\n",
      "step: 15 | gd_count: [107. 185.  10.  33.  29. 400.  21. 197.  47.  44.] | prediction: [110.66394  242.6755    19.159088  38.448025  25.798828 214.0795\n",
      "  31.523922 269.58896   78.61172   29.06593 ] | loss: 52.15924835205078\n",
      "step: 16 | gd_count: [  1.   0.   5. 216. 611.   9. 202.   8.  26.  13.] | prediction: [  7.430705    7.9542394   8.608562   58.70166   254.54956    12.458876\n",
      " 140.67807     8.556742   23.80022    19.414808 ] | loss: 66.04561614990234\n",
      "step: 17 | gd_count: [ 98.   0.  16.  60.  20.  25. 125.  25. 117.  49.] | prediction: [105.48638     3.9487731  15.086455   39.475708   21.1725     28.71685\n",
      "  88.812515   16.114117   98.72046    48.926083 ] | loss: 18.141464233398438\n",
      "step: 18 | gd_count: [ 64. 117.  73. 236.  69.  91.  94.  82.  10.  69.] | prediction: [ 48.611     83.235504  36.189217 123.850914  52.826912  66.7173\n",
      "  67.867455  29.465754   5.623147  53.079723] | loss: 35.03947067260742\n",
      "step: 19 | gd_count: [ 33.  20.  10.  52.   4. 142. 264.  89.   0.  68.] | prediction: [ 22.473612  12.19911    8.970093  32.465294   7.644839 108.80886\n",
      " 159.20116   73.37518    9.985149  72.49486 ] | loss: 28.947269439697266\n",
      "step: 20 | gd_count: [215. 199.  10. 150.  96.  48.  29. 383. 124. 491.] | prediction: [235.5711   218.06085   14.639678 134.50166   58.137836  58.10305\n",
      "  22.389221 352.41837  103.96921  439.93915 ] | loss: 65.1356430053711\n",
      "step: 21 | gd_count: [117.  40.   9.  68.  76.   2.  73.  33.  26. 194.] | prediction: [ 93.63188   28.100758   5.334228  67.56999   91.05954    5.592802\n",
      "  88.16139   33.800983  18.20738  138.73074 ] | loss: 23.811782836914062\n",
      "step: 22 | gd_count: [ 24.   2.  28.  63.  24.  20.  53. 158. 173.  24.] | prediction: [ 19.928213    2.0127342  30.734465   55.54229    18.449272   11.330802\n",
      "  44.077187   52.433273  104.59471    21.77135  ] | loss: 23.979291915893555\n",
      "step: 23 | gd_count: [ 29.  22.   5.   8.   6. 133.  78. 217.  46.] | prediction: [ 14.660009   19.545324    6.7922764   5.808253    6.5271454  60.97511\n",
      "  52.174976  102.492676   27.233677 ] | loss: 26.1516056060791\n",
      "Epoch 7 Val, MSE: 315.01 MAE: 177.95, Cost 6.8 sec\n",
      "save best mse 315.01 mae 177.95 model epoch 7\n",
      "-----Epoch 8/19-----\n",
      "step: 0 | gd_count: [45. 63.  5. 74.  2.  0. 48.  0. 44.  0.] | prediction: [42.95893   54.303368  10.122974  47.96529    7.3470078  4.295101\n",
      " 28.250797   5.5638366 28.347054   6.1336637] | loss: 11.035481452941895\n",
      "step: 1 | gd_count: [  7.  12.  84.  30. 142. 127.   7. 157.  21.   9.] | prediction: [ 6.7490177 12.325649  61.85939   27.66653   94.55794   88.51857\n",
      "  9.132329  65.57656   21.851833   9.901387 ] | loss: 23.308340072631836\n",
      "step: 2 | gd_count: [270. 109.  53.  56.  82.  69.  10.   9.  93. 270.] | prediction: [ 41.89834   86.75581   81.128426  81.00084   71.03377   64.93431\n",
      "  15.252187  10.878617  69.857574 156.60876 ] | loss: 53.0050048828125\n",
      "step: 3 | gd_count: [  0. 254. 137.  37.  74.  13.  34.  31.  32.  20.] | prediction: [  2.2556462 168.32965    80.6967     14.64349    53.7755     13.534485\n",
      "  34.04737    30.437334   32.09204    19.930895 ] | loss: 25.131067276000977\n",
      "step: 4 | gd_count: [ 80.  16.  38. 210.  27. 274.  90.  20.  25.  16.] | prediction: [ 78.474724  12.856621  40.002953 144.49      25.420143 224.11664\n",
      "  62.680855  11.614971  26.023926   7.110632] | loss: 29.768783569335938\n",
      "step: 5 | gd_count: [ 62. 229.  41.   0. 350.   5.  29.  49.  10.  37.] | prediction: [ 82.39064   128.4813     34.272102    6.7159977 282.16626     8.49301\n",
      "  17.1036     73.776115   13.205618   44.70055  ] | loss: 37.14321517944336\n",
      "step: 6 | gd_count: [ 90.  19.  10.  28.   2. 113. 118.  16. 101.   1.] | prediction: [ 40.505302   12.875177    8.69858    27.859238    6.4035625 207.21185\n",
      " 101.25905    15.749277  111.91188     7.3289657] | loss: 29.057758331298828\n",
      "step: 7 | gd_count: [ 31. 118. 415. 147.  77.  13.  22.  66.  17. 163.] | prediction: [ 11.072285   87.96426   285.54608   129.46165    36.93709     6.407936\n",
      "   9.735093   31.777       7.0022726 144.69576  ] | loss: 38.157588958740234\n",
      "step: 8 | gd_count: [ 41. 184.  36. 100.  82. 726.  92.  84. 131.  24.] | prediction: [ 18.00631   76.40312   18.12739   86.58714   40.939503 225.055\n",
      "  37.469414  55.91691   74.98277   10.370019] | loss: 83.79478454589844\n",
      "step: 9 | gd_count: [ 51.  18.  33.  44.  75.  46. 341.  47.  42.  25.] | prediction: [ 54.627728  18.689842  30.354912  45.389313  54.37802   44.675667\n",
      " 298.9235    51.10856   43.3834    34.516846] | loss: 26.096057891845703\n",
      "step: 10 | gd_count: [ 27.  28. 124.  51.  29. 106.  16.   5.   5.  81.] | prediction: [ 20.209991  28.421703 101.33512   58.409897  42.840343 125.6334\n",
      "  59.82256    9.978528  10.62091  111.60614 ] | loss: 27.060413360595703\n",
      "step: 11 | gd_count: [ 21.  55.  18.  54.  26.  38.  24. 108.  23.  84.] | prediction: [ 19.851751  47.085876   5.785595  64.03158   32.624733  38.897804\n",
      "  27.66041  102.663826  30.378468  91.92641 ] | loss: 16.572311401367188\n",
      "step: 12 | gd_count: [ 95.  17. 111.  78.  39.  98.  17.  42.  85.  10.] | prediction: [64.466576 16.078217 72.686646 57.405685 36.199806 86.196884 23.197063\n",
      " 29.553083 84.93566  18.093538] | loss: 20.956096649169922\n",
      "step: 13 | gd_count: [134.   3.  26. 107.  93. 101. 346.   6.  88. 161.] | prediction: [ 52.60383     4.2177763  21.580757   74.84485    59.117107   53.393616\n",
      " 249.98395     5.460409   54.1818    126.16528  ] | loss: 42.63352584838867\n",
      "step: 14 | gd_count: [ 22.  97.   0.  20.  78. 185. 280.   2.  29.   0.] | prediction: [ 16.222069   59.884216    3.8372228  11.692052   26.609575   75.045654\n",
      " 115.600464    3.6728919  26.657883    4.05499  ] | loss: 36.73154830932617\n",
      "step: 15 | gd_count: [ 16.  24.  23.  36. 134.  60.   0.  67.  25.  24.] | prediction: [15.70616   24.976006  20.917984  29.179483  59.61767   29.168945\n",
      "  4.0841503 44.858044  23.808167  33.26825  ] | loss: 16.72004508972168\n",
      "step: 16 | gd_count: [201. 131.  20.  14. 319. 166.  12.  12.  27.  31.] | prediction: [250.08603   108.37461    14.592249   15.992801  315.95413   147.08746\n",
      "  12.1456585  12.496504   31.595045   26.769049 ] | loss: 34.72757339477539\n",
      "step: 17 | gd_count: [ 19. 224.  34.  28.  36.  25.  50.   8.  81.  14.] | prediction: [ 21.415522  116.71906    24.067402   19.887466   37.55024    22.01373\n",
      "  58.43419     6.3312116  57.841667   12.58939  ] | loss: 20.887971878051758\n",
      "step: 18 | gd_count: [ 20.   9. 173.  42. 122.  29.  33. 156.  67.  32.] | prediction: [  5.991293    5.8821487 145.02255    26.705654   94.994095   25.67893\n",
      "  16.742779   61.875023   50.86551    29.176258 ] | loss: 25.542814254760742\n",
      "step: 19 | gd_count: [ 84.  15. 195.  11.  27. 165.  57.  37.   8.  25.] | prediction: [ 56.69152    14.77809   120.1065      5.0306187  19.688986  106.11844\n",
      "  61.96161    52.11695     5.772286   26.419113 ] | loss: 27.113208770751953\n",
      "step: 20 | gd_count: [119. 138.  39. 494.   0.  19. 226.   7.  14.  38.] | prediction: [ 53.058174  111.768974   27.095957  145.46658     2.0507326   9.970064\n",
      " 124.43244     8.880912    5.079711   24.670353 ] | loss: 60.121978759765625\n",
      "step: 21 | gd_count: [ 47.  74.  76.   4.  24.  36.  12. 294. 102.  40.] | prediction: [ 51.451645   72.7917     48.56174     1.9194723  10.192343   28.033655\n",
      "   8.993608  229.3078     91.42248    42.157623 ] | loss: 26.14182472229004\n",
      "step: 22 | gd_count: [  0.  35.  48. 135.  21.  34.  14. 135.  52.  66.] | prediction: [  1.4705936  11.629454   62.24923    84.84767    19.326307    7.5110435\n",
      "   4.4507446 134.427      63.71314    73.42504  ] | loss: 20.76845359802246\n",
      "step: 23 | gd_count: [ 32.  36. 206. 118. 136.  43.   5.  15.  72.] | prediction: [ 20.031689   17.0656    195.45282   114.13962    99.6608     29.202442\n",
      "   3.4415183  12.845144   45.54183  ] | loss: 25.51487159729004\n",
      "Epoch 8 Val, MSE: 224.91 MAE: 120.26, Cost 6.8 sec\n",
      "save best mse 224.91 mae 120.26 model epoch 8\n",
      "-----Epoch 9/19-----\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0 | gd_count: [ 20.  52.  62.  22.  73.  39.  31. 183.  89.  95.] | prediction: [ 13.287672  37.531734  66.59219   40.49359   61.886826  35.63365\n",
      "  18.046556 133.1696    83.37764   93.75605 ] | loss: 28.249969482421875\n",
      "step: 1 | gd_count: [ 56. 137.  12.  18.  50.  56. 120.  35.  79.  47.] | prediction: [ 36.721104  93.50284    9.995395   9.876303  27.925991  57.997013\n",
      " 100.39496   24.11414   59.576553  29.816013] | loss: 21.155250549316406\n",
      "step: 2 | gd_count: [ 77.  93.  78.  13. 267.  48. 101.  64. 122.  95.] | prediction: [ 66.257996  71.33459   81.49814   12.818108 196.92102   24.896334\n",
      "  82.69731   34.734383  84.868195  91.48835 ] | loss: 34.26808547973633\n",
      "step: 3 | gd_count: [30. 66. 45. 61. 12. 16. 10. 11. 15. 76.] | prediction: [25.33094   47.178787  27.834312  39.24079   10.511856  14.478902\n",
      " 14.5378475 12.725435  19.014503  52.22619  ] | loss: 10.541139602661133\n",
      "step: 4 | gd_count: [ 70.   0. 201.  89.  24.   2.  74.  60. 261.  98.] | prediction: [ 55.16854    2.531448 115.96052   73.47197   28.175987   4.135699\n",
      "  49.734043  41.486794 115.06005   93.34375 ] | loss: 36.85765075683594\n",
      "step: 5 | gd_count: [ 50.  39.   0. 175.  14.  59.  80.  13.  40. 403.] | prediction: [ 58.621674   8.463354   1.904476 158.41153   16.694988  69.664505\n",
      "  76.96677   18.161793  31.988445 160.75845 ] | loss: 43.42429733276367\n",
      "step: 6 | gd_count: [ 33.  22.  28. 333.  35.  24.  75. 380.  13.  11.] | prediction: [ 32.854027  22.523266  35.3402   244.55629   27.33799   30.860176\n",
      "  82.85007  253.45949   17.243332  23.627096] | loss: 37.50697708129883\n",
      "step: 7 | gd_count: [  0.  62.  17. 147.  14.  53. 142.  70.  78. 153.] | prediction: [  3.9416468  53.373817   24.754696  136.98807    13.124108   50.08818\n",
      " 157.99931    64.20411    72.07302   100.38794  ] | loss: 28.609472274780273\n",
      "step: 8 | gd_count: [  8.  57.  71. 139.   8. 101.  16.  11.  47.  53.] | prediction: [  9.422923   40.07809    44.466377  133.20596     6.4559383  61.729206\n",
      "  13.726956    7.8914623  11.668798   34.140923 ] | loss: 19.076828002929688\n",
      "step: 9 | gd_count: [ 39. 126.  44.  11.   7.   4.  21.  63.  51.  19.] | prediction: [ 23.878391  111.66992    28.924337    7.2079434   7.053048    4.1055384\n",
      "  17.117481   51.98329    45.63955    15.887017 ] | loss: 10.282244682312012\n",
      "step: 10 | gd_count: [ 78.   8.   7. 165.  53.  25.  33.  38.   9. 136.] | prediction: [ 69.90019     8.152679    8.1422    108.10306    47.723213   14.783488\n",
      "  16.32153    24.816372    3.9170194 139.83925  ] | loss: 18.5910587310791\n",
      "step: 11 | gd_count: [ 33.   7. 198.  30.  31.  58. 323.  15.  43.   9.] | prediction: [ 18.748459   4.037735  27.506996  12.455902  19.22219   38.541584\n",
      " 332.63333    6.386286  33.928673   6.736675] | loss: 37.150856018066406\n",
      "step: 12 | gd_count: [200. 178. 299.   7.   0.  32.   9.  55. 143.  24.] | prediction: [140.56177   139.79361   193.79227     4.2429714   1.8401582  32.287125\n",
      "  11.386573   41.11635   190.48987    16.159348 ] | loss: 37.09151840209961\n",
      "step: 13 | gd_count: [ 56.   0.  61.  15. 123. 135.   4.   0. 254.  43.] | prediction: [ 51.704388    2.5769017  47.951103    9.406719   82.25597   136.0007\n",
      "   3.0093849   1.6434417 176.7625     27.404793 ] | loss: 26.123855590820312\n",
      "step: 14 | gd_count: [ 45.  52.   8.  40.   7.  99.  79. 152.  69.  41.] | prediction: [ 54.626137  48.62464    2.142099  52.308506   8.032285  98.43523\n",
      "  50.968582 105.99481   88.0432    26.081287] | loss: 22.67753028869629\n",
      "step: 15 | gd_count: [ 73. 111.  13.  93.   9.  12. 103. 126.  69.   2.] | prediction: [114.58641    88.31807    17.584446   65.46117     2.8176794  22.37559\n",
      "  92.33812   103.66685    89.81822     2.9778705] | loss: 22.775022506713867\n",
      "step: 16 | gd_count: [  4. 190. 108.   0. 130.  21.  27.   3.  17.  25.] | prediction: [  3.2148852 124.75731    59.35488     2.4086263 105.44302    24.110523\n",
      "  23.224403    1.9752064   9.091139   18.595457 ] | loss: 17.75846290588379\n",
      "step: 17 | gd_count: [36. 39. 53. 36. 17. 26. 32. 84. 34. 43.] | prediction: [19.939087 30.283485 29.630478 34.54402  19.84185  20.740461 33.24588\n",
      " 48.229507 10.244032 31.091888] | loss: 15.0064058303833\n",
      "step: 18 | gd_count: [ 9.  0.  1. 64. 86. 15.  0. 50. 29. 30.] | prediction: [ 8.578491   2.9748237  2.4284706 33.471653  59.357735  13.179882\n",
      "  1.9096678 23.061554  32.809486  24.816414 ] | loss: 10.634318351745605\n",
      "step: 19 | gd_count: [ 48. 102.  40. 271.   0. 109.  27. 418.  92.  47.] | prediction: [ 40.157753   54.83895    43.59272   104.71033     1.9429313  74.8338\n",
      "  22.899797   52.63175    44.715008   24.685232 ] | loss: 69.0431137084961\n",
      "step: 20 | gd_count: [ 76.  21.  26. 142. 396.  64.  44.  95.  50.  51.] | prediction: [ 58.976334  15.129606  19.337233 103.35452  270.5817    32.07482\n",
      "  30.488487  68.29708   36.992958  36.269806] | loss: 32.23017501831055\n",
      "step: 21 | gd_count: [ 18.  38.  10.  33.  26.  35. 680.  75.   9.   0.] | prediction: [ 23.083038  44.896538  12.214228  37.50839   40.344757  52.774044\n",
      " 521.2231    78.0486     9.280724  17.493465] | loss: 37.9720573425293\n",
      "step: 22 | gd_count: [  8.  46. 105. 261. 146.  49.  46.  95.  21.   0.] | prediction: [ 14.028897   81.05304   131.13118   181.34146   180.62888    73.51356\n",
      "  62.053123  165.10547    21.914555    3.6534028] | loss: 48.547157287597656\n",
      "step: 23 | gd_count: [ 83.  31.  65.  16.  37.  62.  16. 145.  65.] | prediction: [ 51.53131   35.266594  58.45052    6.372093  19.188534  41.345585\n",
      "  10.454308 112.06386   44.745045] | loss: 18.592575073242188\n",
      "Epoch 9 Val, MSE: 291.30 MAE: 179.97, Cost 6.7 sec\n",
      "save best mse 291.30 mae 179.97 model epoch 9\n",
      "-----Epoch 10/19-----\n",
      "step: 0 | gd_count: [ 21.  41. 138. 178.  10. 203.  54.  48.  51.  76.] | prediction: [ 11.681333  18.49884   78.90485  139.96628    5.348258 153.82764\n",
      "  36.853928  25.818638  39.91265   47.516083] | loss: 27.25977897644043\n",
      "step: 1 | gd_count: [ 36.  26.  25. 113.  56.  52.  60.  33. 223. 154.] | prediction: [ 19.495167  15.094091  16.459435  85.549     17.137936  34.59305\n",
      "  60.467052  18.603134 161.82352   95.10168 ] | loss: 27.406967163085938\n",
      "step: 2 | gd_count: [  0. 144.  93.   0.  32.  41.   1.  20.  17.  24.] | prediction: [ 1.8503408 86.625824  69.933914   1.8579271 27.515316  42.34751\n",
      "  1.7605755 15.417946  22.624939  27.1192   ] | loss: 13.743776321411133\n",
      "step: 3 | gd_count: [ 94.  30.  37.  46. 223.  16.  16.   2.  36. 116.] | prediction: [ 70.75626   36.010788  39.573547  60.634666 130.88853   21.918621\n",
      "  27.327562   1.7274    40.10755   88.32063 ] | loss: 26.802114486694336\n",
      "step: 4 | gd_count: [181. 130.  61. 128.  29. 266.  52.  30.  36.  80.] | prediction: [114.79159  128.66634   47.751335 135.14111   30.469421 204.78325\n",
      "  48.74872   53.60959   33.532444  77.103035] | loss: 34.739749908447266\n",
      "step: 5 | gd_count: [47. 34.  6.  0. 56. 27.  0. 16. 17. 40.] | prediction: [28.878735   29.891926    8.855968    0.85098624 75.31557    26.800991\n",
      "  2.2361875  17.645      18.766972   34.09482   ] | loss: 8.975783348083496\n",
      "step: 6 | gd_count: [ 77. 271. 307.  14. 111.  38.  36.   4. 100.  85.] | prediction: [ 84.34048   177.47018   171.67862     6.665986   70.09636    16.234325\n",
      "  20.95521     5.8403597  79.695755   60.651016 ] | loss: 42.22844314575195\n",
      "step: 7 | gd_count: [246.  95.   9.   7.   0.  42.  32.  91. 208.  10.] | prediction: [148.24956    79.52516     7.706315    3.8960495   2.1340475  34.388702\n",
      "  17.830957   78.14977   133.12961     6.1507835] | loss: 27.30207633972168\n",
      "step: 8 | gd_count: [27. 13. 18. 23. 75. 26.  9. 65. 26. 38.] | prediction: [20.552135  10.554596  19.077288  13.499136  34.039482  12.168549\n",
      "  3.6604576 36.92862   12.87637   17.630142 ] | loss: 12.589844703674316\n",
      "step: 9 | gd_count: [ 24.  93.  88.  38.  50. 237.  87.  20.  53.  43.] | prediction: [  8.075964  89.83484   82.883545  22.160456  24.539295 206.94589\n",
      "  97.94911   15.041145  40.641968  25.584782] | loss: 26.22051429748535\n",
      "step: 10 | gd_count: [  1. 102.  24.  48.  11.   3.  15.  35. 114.  69.] | prediction: [  1.8826348 117.15271    19.256721   39.3623     43.084923    5.857805\n",
      "  12.260552   37.465694  137.36578    37.851326 ] | loss: 21.00691795349121\n",
      "step: 11 | gd_count: [  9.  38.  28.   6.  64.   6.  57. 166.  28. 102.] | prediction: [ 13.198928   41.167274   23.921158   11.7429695  61.05828    14.92588\n",
      "  41.366585  186.9544     26.2304     99.62808  ] | loss: 20.48011016845703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 12 | gd_count: [  1.  34. 179.  20.  31.  22. 224.   0.  12.  48.] | prediction: [  7.9494386  32.419823  164.28806    20.454857   26.804855   16.931755\n",
      " 173.15302     5.3135643  11.672817   34.02236  ] | loss: 21.061140060424805\n",
      "step: 13 | gd_count: [ 41.  49.  85.  13.   6.  46.  55. 506.   8.  23.] | prediction: [ 32.83494   27.3564    57.691223  11.833095   8.207916  47.77899\n",
      "  21.778233 133.71387    9.057314   5.941553] | loss: 50.529876708984375\n",
      "step: 14 | gd_count: [324.  22.  33.  45.  57. 157.  17.  18.  23.  71.] | prediction: [142.68626    8.446676  16.703352  41.93684   33.19476   79.920715\n",
      "   8.823079  12.138469  12.429544  40.042908] | loss: 34.39866256713867\n",
      "step: 15 | gd_count: [  9.  60.  42. 147.  97.  73.  67.  73.  28. 106.] | prediction: [  9.723118  33.913834  30.748268  80.53469   50.062153  44.105324\n",
      "  34.259712  30.874565  15.748342 100.96893 ] | loss: 29.051410675048828\n",
      "step: 16 | gd_count: [ 14.   0. 140. 198. 291.  61.  66.  47.  87.  91.] | prediction: [ 14.412274  11.140132  83.64091  108.99913   91.99914   25.99894\n",
      "  52.190502  39.439724  54.932953  77.688416] | loss: 49.042877197265625\n",
      "step: 17 | gd_count: [ 27.  93.  35. 227.   1.  12.  17.  17.  82.  42.] | prediction: [ 45.337273   89.680374   45.59996   203.17082     6.8571057  19.18328\n",
      "  33.441257   28.11708    64.21292    64.56015  ] | loss: 23.650592803955078\n",
      "step: 18 | gd_count: [ 52.  78. 104. 218.  45.   0. 152.  11.  31.  19.] | prediction: [103.89199   134.86928   142.31235   215.20132    68.72612     5.6240273\n",
      " 167.39111    32.882053   52.852913   23.214436 ] | loss: 46.28853988647461\n",
      "step: 19 | gd_count: [ 35. 247.   4. 434.  30.  33.  23.  58.   4.  47.] | prediction: [ 16.177927  174.05923     4.2080965 142.3637     36.12815    43.780033\n",
      "  24.27869    84.75426     7.5593333  54.741486 ] | loss: 49.821224212646484\n",
      "step: 20 | gd_count: [  7. 285.  20.  23.  62.  79.  62. 188.  72.  44.] | prediction: [  2.3334148  62.038883    7.573062   13.155781   33.443554   50.882393\n",
      "  28.660358  147.7183     61.64418    31.246174 ] | loss: 40.64384460449219\n",
      "step: 21 | gd_count: [ 29.  85. 118.  14.  75.   0.  52.  19. 266.  46.] | prediction: [ 10.46792    56.40865   100.769936    4.5420356  74.18517     1.3880084\n",
      "  32.005985   11.38663   163.63217    22.80621  ] | loss: 25.07295799255371\n",
      "step: 22 | gd_count: [  4.   6. 207.  77.  65.  58.  57.  14.  26.  15.] | prediction: [  5.59472     1.4595711 127.890564   40.893887   31.520552   31.76934\n",
      "  46.145695   11.5368185  13.63739    13.516396 ] | loss: 22.974597930908203\n",
      "step: 23 | gd_count: [34. 32. 88. 30. 34. 50. 39.  0. 76.] | prediction: [31.83887   25.951042  76.05045   20.922642  21.93528   45.0399\n",
      " 45.4813     1.5353571 79.63439  ] | loss: 11.670933723449707\n",
      "Epoch 10 Val, MSE: 230.67 MAE: 121.71, Cost 6.8 sec\n",
      "save best mse 230.67 mae 121.71 model epoch 10\n",
      "-----Epoch 11/19-----\n",
      "step: 0 | gd_count: [66. 70.  8. 23. 31.  5. 25.  2. 81. 35.] | prediction: [90.57269   88.47516    4.392361  26.9584    39.97926    6.224616\n",
      " 28.554342   2.6698625 60.849247  45.776756 ] | loss: 15.246962547302246\n",
      "step: 1 | gd_count: [ 48.  93. 135.  18. 211. 262.  19.  67. 143. 308.] | prediction: [ 34.52972   85.74972   91.947105  14.060797 232.86766  155.47565\n",
      "  25.120968  73.45144  116.15556  229.96106 ] | loss: 50.9671516418457\n",
      "step: 2 | gd_count: [103.  19. 243.  20.  17. 114.  77. 104.  30.   6.] | prediction: [112.23974   17.715866 194.76183   12.002525  16.716908  59.3657\n",
      "  61.680363  71.5137    22.40123   10.13551 ] | loss: 25.95072364807129\n",
      "step: 3 | gd_count: [ 23.  27.  68.  16.  71. 108.  25.  75.   6.  50.] | prediction: [25.924988 22.13756  46.309326 13.280424 51.688663 92.02145  23.532333\n",
      " 46.813126 15.302012 41.484276] | loss: 15.054837226867676\n",
      "step: 4 | gd_count: [ 70.  21. 150.  79.  32.  16. 116.  12. 116.  42.] | prediction: [34.249687 18.221426 24.22987  71.75778  15.472547 12.993897 72.3033\n",
      " 10.184453 80.21065  25.588856] | loss: 31.092761993408203\n",
      "step: 5 | gd_count: [  6.  46.   1. 176.  56.  27.   9.  61.  41.  42.] | prediction: [ 6.513289  23.629072   5.871005  91.98614   44.162735  14.843029\n",
      "  6.9581013 35.79142   34.526787  26.33407  ] | loss: 18.633085250854492\n",
      "step: 6 | gd_count: [ 67.  41.  69. 150.  45.  32.  17. 126.  12.  10.] | prediction: [ 63.938347  34.918957  54.711197 124.11836   53.218933  17.027884\n",
      "  19.67036   91.08007    8.268409   8.876209] | loss: 18.790616989135742\n",
      "step: 7 | gd_count: [  1.  47.   0.  99.   4.  11.  29.  57.  60. 100.] | prediction: [ 2.130875  47.965515   2.7402973 86.40529    8.069727  10.458578\n",
      " 28.090145  63.120605  43.80252   83.23904  ] | loss: 11.839922904968262\n",
      "step: 8 | gd_count: [ 16. 264.  37. 122.  20.  29.   6.   7.  86.  50.] | prediction: [ 12.417143  132.50803    41.86122   110.29284    18.329302   22.47111\n",
      "   4.691165    6.8104076  60.163704   50.86809  ] | loss: 24.10079002380371\n",
      "step: 9 | gd_count: [86. 23.  0.  3. 46. 82. 59. 73. 33. 89.] | prediction: [112.0305     17.384706    2.9650528   4.5160418  41.528248   71.162834\n",
      "  37.530037   53.876644   30.204966   75.30487  ] | loss: 16.009191513061523\n",
      "step: 10 | gd_count: [  3.  23.  32.  16.  27.  39.  39.  36.  13. 115.] | prediction: [  6.2620544  18.91781    22.403128   11.069817   29.612913   32.91696\n",
      "  28.25424    44.541172   11.9573555 110.199326 ] | loss: 9.976374626159668\n",
      "step: 11 | gd_count: [111.  46. 509.  64. 187. 128.  32.  58.  16.  22.] | prediction: [ 79.04123   40.535225 189.53702   49.934128 130.4258   109.69328\n",
      "  31.15437   49.18917   19.20639   26.664375] | loss: 57.506507873535156\n",
      "step: 12 | gd_count: [ 56.  18.  54.  15.   2. 226. 104.   3. 240.  26.] | prediction: [ 36.24132   15.494373  39.60409   13.55147    3.760437 220.20425\n",
      " 152.8473     5.430953 128.08588   18.95393 ] | loss: 33.855770111083984\n",
      "step: 13 | gd_count: [ 9. 93. 43. 29. 96. 43. 66.  8. 17. 91.] | prediction: [ 7.834416  68.78908   43.56311   15.726564  76.779274  28.112797\n",
      " 58.044514   4.170228   7.1518846 57.231186 ] | loss: 15.519360542297363\n",
      "step: 14 | gd_count: [128.  12. 167.   8.  28.  84.  48. 276. 128.   5.] | prediction: [ 88.703735   7.668228 116.79175    6.588229  13.865223  82.29228\n",
      "  40.274097 149.03854   76.4395     8.320686] | loss: 32.166683197021484\n",
      "step: 15 | gd_count: [ 29.  74.  14.  80.  81. 106.  34. 112.  23. 197.] | prediction: [ 19.901684  75.850815  14.830961  77.652466  58.428642  91.0383\n",
      "  20.758572  83.375244  12.445339 196.0651  ] | loss: 26.942365646362305\n",
      "step: 16 | gd_count: [ 46. 161.  68.  96. 156. 244.   0.  34. 118.  22.] | prediction: [ 45.128708  145.3866     96.41194    59.80707    88.028564  232.1368\n",
      "   1.8618302  39.650646   96.20172    14.7777815] | loss: 35.33412170410156\n",
      "step: 17 | gd_count: [  4. 100. 107.   7.   0.  42.  28. 175.  82. 121.] | prediction: [  2.9251976  99.51859    97.31097     2.1722848   3.279483   39.278862\n",
      "  46.146893  104.06258    69.858185  110.47963  ] | loss: 25.293506622314453\n",
      "step: 18 | gd_count: [ 97.  46.  28.  30.  25.  26.  25.  95.  57. 246.] | prediction: [84.216    42.046562 21.576393 20.687223 24.661247 20.55302  10.659811\n",
      " 91.30676  87.5148   75.20837 ] | loss: 30.466583251953125\n",
      "step: 19 | gd_count: [ 71.   0.  45.  13. 105.  26. 167. 208. 293. 192.] | prediction: [ 49.424747    2.4118662  41.81401    19.329762   85.43599    25.829523\n",
      " 107.4749    160.27405   195.99898    87.42872  ] | loss: 44.38146209716797\n",
      "step: 20 | gd_count: [  0.  96. 167. 215. 122. 287.  32.  30.  18. 503.] | prediction: [  2.360805  63.47637  140.85928  153.65617  114.3775   226.49081\n",
      "  25.528072  22.69953   23.949013 377.4796  ] | loss: 51.55338668823242\n",
      "step: 21 | gd_count: [150.  12. 139.  25. 107.  29. 116. 168.  96.  40.] | prediction: [155.88638    8.630177 109.84928   11.928919  73.18848   24.25288\n",
      " 102.88434  159.22498  109.91527   48.483994] | loss: 30.620359420776367\n",
      "step: 22 | gd_count: [126.  54.  30. 150.   5.   6.  38.  43.   6. 158.] | prediction: [ 70.88326    50.907722   29.539629  145.22124     3.9095526   3.7166214\n",
      "  30.147274   33.540146    5.1331644 126.02463  ] | loss: 19.475522994995117\n",
      "step: 23 | gd_count: [ 23. 135.   5. 160.   9.  36.  23.  13. 376.] | prediction: [ 19.180716  124.60535     1.971378  163.13586     7.5168543  24.352287\n",
      "  20.991766    6.6759553 365.5268   ] | loss: 28.57396125793457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 Val, MSE: 290.85 MAE: 177.43, Cost 6.9 sec\n",
      "save best mse 290.85 mae 177.43 model epoch 11\n",
      "-----Epoch 12/19-----\n",
      "step: 0 | gd_count: [ 21.  95.  82. 191.  96.  50.  24.  64.  13.  68.] | prediction: [ 10.52479   39.088905  58.141365 118.20265   70.93851   34.05697\n",
      "  15.633745  41.707947  11.070569  40.884148] | loss: 23.83976173400879\n",
      "step: 1 | gd_count: [ 72.   9.  89.  24.  31.  46. 154.  69.  41.  58.] | prediction: [  6.359899   9.641428  61.92128   25.614893  40.78042   39.075104\n",
      " 109.42955   82.90869   22.021206  30.969795] | loss: 26.7614688873291\n",
      "step: 2 | gd_count: [  6.  13.  42.  11. 166.  35.   0.  88. 337.  45.] | prediction: [  8.104713  17.908148  38.85602   15.700008  63.13117   31.378149\n",
      "   4.787344  65.73532  190.51714   34.320408] | loss: 33.33262252807617\n",
      "step: 3 | gd_count: [139.  51.  65.  25.  25.   2.   7.   0. 137.  53.] | prediction: [96.430664  38.33623   63.91687   28.692324  29.05981    3.2036734\n",
      " 11.107243   3.3925662 79.24926   68.16599  ] | loss: 19.61286163330078\n",
      "step: 4 | gd_count: [133. 389.  17. 284. 670. 148.  35.  27. 112. 144.] | prediction: [ 95.28313  155.57372   15.013018 170.84003  314.6637    84.69633\n",
      "  27.668137  33.57613   53.942757 133.34235 ] | loss: 92.67269134521484\n",
      "step: 5 | gd_count: [ 20.  38.  26.  17.  60.   0. 113.   9.   5.  18.] | prediction: [29.512829 58.624207 14.184614 28.184645 75.49507   5.56514  85.33107\n",
      "  9.968408  9.168648 13.687271] | loss: 16.647382736206055\n",
      "step: 6 | gd_count: [ 57.  60. 105.   9.  76.   1.  39.  55.  51.  61.] | prediction: [130.34665   120.20965   180.95073     6.8870544 108.41801     4.1105275\n",
      "  80.92763   110.19794   141.28891    89.87343  ] | loss: 54.3939208984375\n",
      "step: 7 | gd_count: [ 34.  69.  29.  30.   2.  15.  54.  59. 357.  30.] | prediction: [ 16.366953   27.702284   16.380405   24.751673    4.6010504   5.767612\n",
      "  23.364216   47.898964  321.1222     13.890673 ] | loss: 27.275278091430664\n",
      "step: 8 | gd_count: [ 16.  42.   0.   1.  25.  24. 223. 261. 336.   0.] | prediction: [  5.194014    3.7948666   1.6270654   1.3332746   9.85161     7.231423\n",
      "  90.3678    154.22882   115.7178      1.9380544] | loss: 52.90578079223633\n",
      "step: 9 | gd_count: [ 10. 177.  26.  69.  19.  61.  43.  62. 125.  35.] | prediction: [ 3.7260134 74.92182    5.138541  23.538017   6.0808787 23.286554\n",
      "  8.736863  24.263296  19.437153  11.374329 ] | loss: 40.1636962890625\n",
      "step: 10 | gd_count: [412.  46.  25.  53.  56.  17. 139.  15.  33.   8.] | prediction: [100.428444   19.405977   11.081202   21.438396   20.595928   11.592445\n",
      "  52.734398    9.976013   12.429716    5.0127845] | loss: 50.59984588623047\n",
      "step: 11 | gd_count: [ 72.   7.  23.  86.  11. 211.   4.  70.  15. 108.] | prediction: [ 46.491474  15.018231  30.418026  56.933033  17.970167 143.7261\n",
      "  12.139978  52.04886   15.785097 119.16191 ] | loss: 23.890464782714844\n",
      "step: 12 | gd_count: [ 40.  16.  67.   4. 115.  58.  87.  31.  53. 274.] | prediction: [ 42.215027  28.660248  52.35749   17.83332   78.109314  53.47225\n",
      "  56.337475  37.28724   47.984543 178.7289  ] | loss: 28.88709831237793\n",
      "step: 13 | gd_count: [ 75.  43.   0.  79.  55.  51.  58.  50.  44. 194.] | prediction: [ 91.80841   48.41263   17.068672  74.16162   62.811256  54.655994\n",
      "  57.629402  47.73436   52.5304   206.09967 ] | loss: 27.74262046813965\n",
      "step: 14 | gd_count: [  0.   8.  11.  26. 110.   0.   7.  96.  69.  14.] | prediction: [ 24.245684  32.171593  28.775925  41.800438 108.62967   19.220943\n",
      "  19.42065   89.15354   83.26186   32.982185] | loss: 24.731693267822266\n",
      "step: 15 | gd_count: [  1.  88. 201. 247.   0.  63.  52.  26.  80.  94.] | prediction: [ 25.522743  80.2384   183.64114  322.27142   17.007978  71.89128\n",
      "  56.540714  36.86021   66.501495  93.45343 ] | loss: 36.757415771484375\n",
      "step: 16 | gd_count: [413. 159. 181.  51.  64.  41.  57.  20.  66. 199.] | prediction: [220.14848   95.18277  126.9668    43.67856   68.6909    41.027256\n",
      "  49.832756  32.346287  68.6488   140.02798 ] | loss: 49.851783752441406\n",
      "step: 17 | gd_count: [ 25.  28.  23.  53.   3.  28.  30. 264.  40. 191.] | prediction: [ 29.299816  33.89992   26.99778   47.91244   16.973299  33.84798\n",
      "  33.59637  103.68903   35.195744 124.95587 ] | loss: 32.482967376708984\n",
      "step: 18 | gd_count: [ 19. 261.  65.  70.   6.  94.   2.  52.  20.   9.] | prediction: [ 18.352264 116.52409   53.128933  53.433968  18.160313  65.99693\n",
      "  15.719625  37.668213  27.369776  17.120903] | loss: 30.393585205078125\n",
      "step: 19 | gd_count: [103.  70.  14.  16.  42.   7.  19.  21.  44.  31.] | prediction: [65.68269  50.192482 17.273998 14.098392 26.172775 13.248239 12.809843\n",
      " 19.363228 28.611383 26.096046] | loss: 13.83733081817627\n",
      "step: 20 | gd_count: [ 35.  71.  11.  20. 131.  54.  34.  46.  32.   0.] | prediction: [25.492096 31.527271 10.2561   14.555149 71.185486 42.281963 26.075523\n",
      " 37.286453 21.757198  8.287659] | loss: 17.49268913269043\n",
      "step: 21 | gd_count: [101.  28.  22.  43. 291. 125. 281.  30. 213.  60.] | prediction: [ 64.16794   18.10518   28.576084  42.72888  165.25496  104.96966\n",
      " 177.34851   13.845558 158.09833   62.985283] | loss: 43.05520248413086\n",
      "step: 22 | gd_count: [ 43. 103.  70.  16. 228.   1.  83.  71.   7.  84.] | prediction: [ 37.295357  119.74106    39.153282    6.772032   91.193985    2.4121404\n",
      "  78.551155   64.23685     8.209515   78.907906 ] | loss: 30.214441299438477\n",
      "step: 23 | gd_count: [ 44.  44.   5.  68. 227.   6.  26.  72.  23.] | prediction: [ 75.97363    26.028854    6.5935287  96.66837   222.63184     5.432738\n",
      "  26.028961   86.73248    23.651615 ] | loss: 25.6132755279541\n",
      "Epoch 12 Val, MSE: 306.44 MAE: 176.98, Cost 6.9 sec\n",
      "save best mse 306.44 mae 176.98 model epoch 12\n",
      "-----Epoch 13/19-----\n",
      "step: 0 | gd_count: [  8.  44.  23. 235.   6.  66.  87.  28.   0.  42.] | prediction: [  6.372472  51.89182   20.86724  273.1734     6.53874   34.829315\n",
      "  89.33699   21.928143  10.249414  21.849089] | loss: 24.125530242919922\n",
      "step: 1 | gd_count: [246.   6. 111. 193.  28.  15.   7.  25.  37.  43.] | prediction: [222.78894     7.9628587  83.46055   154.30176    26.95697    12.473331\n",
      "   7.6299944  21.413816   30.64526    14.349098 ] | loss: 29.293182373046875\n",
      "step: 2 | gd_count: [ 91.  16.  88.  10.  44.  56.  19.  44.  11. 155.] | prediction: [39.13272    5.8373046 62.62379    4.804779  33.155357  37.73094\n",
      " 17.330841  31.713415   8.944099  59.30008  ] | loss: 22.543603897094727\n",
      "step: 3 | gd_count: [  0.  31.  41. 193.  54.  87.   9.  45.  19.  44.] | prediction: [  1.4204961  18.257538   25.081917  148.57864    56.76779    54.283024\n",
      "   3.704619   42.000526    9.232237   28.309145 ] | loss: 15.696850776672363\n",
      "step: 4 | gd_count: [ 36. 251.   5. 138.  65.  35.   6.  34. 106.  23.] | prediction: [ 27.794113  129.91818    10.542422   70.507355   75.94013    30.162605\n",
      "   6.1753435  33.33483    77.77786    23.522278 ] | loss: 28.629697799682617\n",
      "step: 5 | gd_count: [ 49.  54.  53.  41.  80. 121.   8. 724.  75.   8.] | prediction: [ 41.514183  39.24732   40.51632   46.59705   72.60916   92.57352\n",
      "   7.011485 189.22655   63.520393  25.371336] | loss: 67.56259155273438\n",
      "step: 6 | gd_count: [ 67.  51.  43.  25.  36. 101.  54. 124.  93.  20.] | prediction: [73.98389  51.890984 41.1353   31.923523 29.138432 81.10234  71.76608\n",
      " 83.35721  72.324554 24.83765 ] | loss: 22.511960983276367\n",
      "step: 7 | gd_count: [ 95.  18.  25.  37.   6.  72.  20.  65. 145.  46.] | prediction: [87.29605  29.640896 31.924925 24.617483  8.115482 45.28234  26.074764\n",
      " 58.214127 85.741486 52.817657] | loss: 19.440757751464844\n",
      "step: 8 | gd_count: [ 33.  52.  36. 264.  16.  19. 129.  62. 222.  66.] | prediction: [ 30.61718   49.35888   43.1298   173.9556    10.813513  19.802689\n",
      "  90.38492   59.032143 165.44675   46.948013] | loss: 29.561111450195312\n",
      "step: 9 | gd_count: [224.  14. 348.   1.   0. 104.  24.   9.  43.  77.] | prediction: [210.4302    15.37487  111.678024   3.002666   2.886467  77.39958\n",
      "  18.298157  12.796894  34.811375  48.78739 ] | loss: 37.93866729736328\n",
      "step: 10 | gd_count: [ 34.  74.  52.   7.  17.  54.  26. 210.  12.  22.] | prediction: [ 20.883049   62.121536   32.700794    5.6801815  14.16647    67.5499\n",
      "  24.141262  230.02878    11.02431    16.923344 ] | loss: 19.46780776977539\n",
      "step: 11 | gd_count: [157.  28.  10. 180.   0.  44.  53.  30. 133.  33.] | prediction: [179.96397    12.092514    4.4576693 163.17073     1.2639246  61.25642\n",
      "  80.984764   21.408035  114.35803    17.077805 ] | loss: 30.6863956451416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 12 | gd_count: [117.  33. 101.   8.  30.  20.  70.  52.  25. 201.] | prediction: [ 85.66089   13.726579  95.126274   6.5905     9.282248  15.723199\n",
      "  34.473595  30.888756  22.962059 199.47963 ] | loss: 25.6405086517334\n",
      "step: 13 | gd_count: [106.  33.  17.   6.   0.  60. 134.  22. 264.  52.] | prediction: [ 56.065327   22.794872    9.858514    4.1125      1.4920177  25.827635\n",
      "  73.763145   13.781689  173.74484    32.43454  ] | loss: 26.742237091064453\n",
      "step: 14 | gd_count: [  0.   0.   0.  27.  58. 187.  63.   2.  39. 226.] | prediction: [  1.7255912   1.2090404   1.1959488  16.35579    33.93337   188.92978\n",
      "  40.292732    2.3915424  21.541458  224.794    ] | loss: 25.676198959350586\n",
      "step: 15 | gd_count: [ 59.  19.  18. 354.  71.  71.   0.  47. 121.  23.] | prediction: [ 53.04491    20.07711    14.916749  278.1274     46.626278   46.690895\n",
      "   1.5529189  55.311928  106.889435   20.139091 ] | loss: 24.798574447631836\n",
      "step: 16 | gd_count: [ 56.   0.  43. 122. 101.  66.  20.  21.   6.  77.] | prediction: [ 50.257072    0.9222747  32.03169   151.19821    78.387665   58.22931\n",
      "  22.708214   30.194027   13.657848   53.80121  ] | loss: 17.698930740356445\n",
      "step: 17 | gd_count: [11. 54.  0. 22. 15. 50. 18. 35. 10.  3.] | prediction: [ 9.457882  49.99108    1.2520578 27.228262  21.366798  44.567448\n",
      " 25.90929   36.9467    14.261564   6.4811964] | loss: 9.322732925415039\n",
      "step: 18 | gd_count: [172.  57.  52. 178. 125. 481.  15.  14.  30.  52.] | prediction: [154.88646   47.28534   64.16491  129.72073   49.82122  183.42973\n",
      "  25.082834  14.326094  24.681261  49.109413] | loss: 53.536354064941406\n",
      "step: 19 | gd_count: [ 60.  29.   8. 244.   5.  30. 225.  40. 122.  27.] | prediction: [ 44.02687   40.063797   9.589468 148.12083    8.192697  28.518673\n",
      " 163.42126   37.45308   78.734726  24.088148] | loss: 30.005674362182617\n",
      "step: 20 | gd_count: [ 17.  94.  10. 345. 409.   6. 272.  21.  52.  69.] | prediction: [ 21.743645  81.31386   18.145294 239.60841  130.73262    8.836847\n",
      " 140.15784   15.535522  54.837055  78.644135] | loss: 62.05156326293945\n",
      "step: 21 | gd_count: [ 22. 132.  37. 327.   2.  37.  84.   7.  47.   8.] | prediction: [ 18.87639   147.41238    20.414745   69.97258     9.116844   41.72979\n",
      "  97.12671     6.7806783  26.811787    7.624687 ] | loss: 39.639705657958984\n",
      "step: 22 | gd_count: [ 15.  47.   7.  35.  31.  83.  11.   0. 142. 109.] | prediction: [  7.7393827  29.931112    6.7862725  26.18923    21.017397   81.85349\n",
      "   7.007137    7.553894  189.99504    85.33161  ] | loss: 18.617233276367188\n",
      "step: 23 | gd_count: [ 21. 201. 121. 235.  88.  69.  73. 166.  79.] | prediction: [ 10.988333 126.18739   70.84198  217.8932    63.261642  45.722076\n",
      "  48.59498   54.281067  52.04518 ] | loss: 51.04929733276367\n",
      "Epoch 13 Val, MSE: 255.94 MAE: 138.38, Cost 6.8 sec\n",
      "save best mse 255.94 mae 138.38 model epoch 13\n",
      "-----Epoch 14/19-----\n",
      "step: 0 | gd_count: [ 58. 167. 500.   0.   4. 101.  44. 210.   6.  20.] | prediction: [ 52.700363  127.12144   360.60266     2.9614024   3.0579565  98.84764\n",
      "  28.626389  149.69035     6.8762264   6.784988 ] | loss: 42.55295181274414\n",
      "step: 1 | gd_count: [ 77.  25.  26.  65. 151.  87.  16.  68.  27.   1.] | prediction: [ 67.08157    15.167312   30.822544   70.62649   102.87801   112.22371\n",
      "   9.822237   49.306618   23.081463    2.7006226] | loss: 18.300304412841797\n",
      "step: 2 | gd_count: [215.  44.  39.   0.   2. 174.  16. 149.  50. 134.] | prediction: [203.01768   48.95804   22.183401   4.845998  12.102869 135.82089\n",
      "  17.860432 113.15783   44.1425   145.31488 ] | loss: 27.841461181640625\n",
      "step: 3 | gd_count: [ 17.  45. 106.  12. 103. 171.  21.  65.  46. 427.] | prediction: [ 17.922867  42.908768  71.14407    9.129303  73.856094 132.73392\n",
      "  18.52995   30.874928  37.142555 324.9199  ] | loss: 32.4156494140625\n",
      "step: 4 | gd_count: [ 48.  13.  24.  98. 198. 182.  35.  29.  45. 136.] | prediction: [ 36.955505  22.60893   21.78178   86.79172  197.11116  169.17487\n",
      "  19.127058  26.281162  32.80412  105.19024 ] | loss: 26.65687370300293\n",
      "step: 5 | gd_count: [107.  18.  16. 187.   0. 168.  36.  17.  20.   9.] | prediction: [ 75.15912   13.994731  17.372997 115.97772   10.302438 125.14264\n",
      "  24.411095  16.37899   16.178402  11.082546] | loss: 21.4265193939209\n",
      "step: 6 | gd_count: [123.   7.  45.  97.  16.  36.  49.  64.  22.  34.] | prediction: [90.37677   8.962982 36.13089  77.141815 16.972977 31.929352 36.501984\n",
      " 56.870995 17.3441   26.028608] | loss: 14.466867446899414\n",
      "step: 7 | gd_count: [ 37. 109.  55.  51. 191.  32.  31.  87. 236. 420.] | prediction: [ 37.627575  87.20323   48.02426   53.342003 142.5314    27.496178\n",
      "  23.033089  82.80238  122.10103  328.03143 ] | loss: 49.65895080566406\n",
      "step: 8 | gd_count: [ 28.   4.  43.  72.   0.  72. 174. 533.   4.  17.] | prediction: [ 25.361053    6.177554   44.43778    40.681137    1.8725417  69.7272\n",
      " 162.8453    425.44543     6.7229033  18.595264 ] | loss: 43.05866622924805\n",
      "step: 9 | gd_count: [  0.  10. 142.  87.  18.   9.  28.  35.  38.  37.] | prediction: [  2.858849   12.520887  127.492065   76.633835   15.556379    7.4184737\n",
      "  13.906829   36.278458   21.155596   37.98754  ] | loss: 13.661654472351074\n",
      "step: 10 | gd_count: [121.   5. 111. 463.  21.  27.  40.  33.  88.  15.] | prediction: [102.73729    4.902339  89.25745  273.1876    11.650339  13.895506\n",
      "  40.85223   19.881264  58.211006  17.406624] | loss: 36.25821304321289\n",
      "step: 11 | gd_count: [ 53. 183. 110.  34.   7. 126.  14. 211.  11.  55.] | prediction: [ 37.8862    151.8259     70.76367    22.802454    6.1069055 103.54272\n",
      "   9.419134  151.96666     7.2627163  40.93284  ] | loss: 25.66463279724121\n",
      "step: 12 | gd_count: [ 28.  96. 214.  17.  97. 199.  38.  29.   1.  16.] | prediction: [ 19.455383  111.365456  143.75597    11.059181  100.6732    162.16785\n",
      "  25.639217   20.05278     5.4797263   9.383089 ] | loss: 26.913969039916992\n",
      "step: 13 | gd_count: [ 57.  69.   5.  90.   4.  26.  21.  48.  49. 108.] | prediction: [ 48.71714   52.277428   8.427258  89.629684   5.00905   28.760384\n",
      "  18.448338  54.61367   40.002163 101.56675 ] | loss: 14.738616943359375\n",
      "step: 14 | gd_count: [ 22. 200.   0.  24. 172.  28. 119.  34.  20.  11.] | prediction: [ 16.660332  190.43887     2.1447647  18.27898   128.5871     30.401115\n",
      " 109.396576   39.533974   21.24332     9.064876 ] | loss: 20.190431594848633\n",
      "step: 15 | gd_count: [ 92.  50.  38.  14. 127.  59.  65.  23.  94.  23.] | prediction: [59.94526  43.14218  37.05898  12.505182 66.11487  56.372414 84.72994\n",
      " 21.67042  68.7383   10.549915] | loss: 20.148069381713867\n",
      "step: 16 | gd_count: [  5. 181.   4. 196.  32.  46.   2. 263.  54. 124.] | prediction: [  3.6643097 191.93655     4.5217876 158.64711    13.882378   29.635704\n",
      "   4.126165  165.64493    35.168526   92.33286  ] | loss: 38.361419677734375\n",
      "step: 17 | gd_count: [ 39.  81.  43.  99. 121.   7. 141.  60.  17.  16.] | prediction: [ 34.81343   52.51834   36.49093  120.022896 107.43182    3.877573\n",
      " 102.105804  58.67288   13.343166  28.740213] | loss: 22.382457733154297\n",
      "step: 18 | gd_count: [ 92.  91. 358.   0.  93.  31.  47.  34. 132.  22.] | prediction: [ 58.059483   42.582443  172.70676     3.3329759  57.288055   29.450937\n",
      "  29.91124    29.578026   85.159164   17.236643 ] | loss: 38.13287353515625\n",
      "step: 19 | gd_count: [ 71.  99.  17.  27.  27.  32. 148. 155. 120.  22.] | prediction: [80.48133  64.80252  17.652027 31.668032 22.796356 37.82563  98.25378\n",
      " 94.78332  83.92645  28.513832] | loss: 26.50282859802246\n",
      "step: 20 | gd_count: [ 11. 137.  33.  24.  52.   2. 161.  25. 213. 402.] | prediction: [ 11.669883 120.283966  26.245066  33.936214  32.75659    4.32695\n",
      "  98.25908   23.939152  51.71086  138.7445  ] | loss: 56.41560745239258\n",
      "step: 21 | gd_count: [42. 16. 15.  7. 27. 48. 25. 72. 31. 28.] | prediction: [ 37.742714  18.142134  15.851322   5.344531  44.381355  54.25352\n",
      "  33.22641  112.62677   33.27217   42.294228] | loss: 14.164420127868652\n",
      "step: 22 | gd_count: [199.  64.  82.  47.  65.  10.   2.  25.  31.  92.] | prediction: [217.04388    80.94148    67.784775   32.207138   54.9632      5.6145067\n",
      "   1.0706093  29.107868   48.734917  101.818954 ] | loss: 23.938825607299805\n",
      "step: 23 | gd_count: [156.  42. 130. 117.  46.  39. 391.   8.  58.] | prediction: [134.47917    19.229538  112.32843    85.97031    14.407124   18.882935\n",
      " 309.88538     1.7491107  65.013275 ] | loss: 43.676265716552734\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 Val, MSE: 302.49 MAE: 228.56, Cost 6.8 sec\n",
      "save best mse 302.49 mae 228.56 model epoch 14\n",
      "-----Epoch 15/19-----\n",
      "step: 0 | gd_count: [337.  39.  96.  52. 201.  99.  44.  48.  76. 114.] | prediction: [178.62871    33.601295    2.7218914  11.688694  225.6294     36.021202\n",
      "  22.43301    16.265213   31.404041   60.799397 ] | loss: 59.55498123168945\n",
      "step: 1 | gd_count: [  7.   1. 208.  51.  49. 222.  19. 173. 331.  15.] | prediction: [  1.9388442   2.0561917 154.84831    33.43376    16.851067  145.87437\n",
      "  11.351614  104.47233   264.8855      6.582435 ] | loss: 43.51158142089844\n",
      "step: 2 | gd_count: [  6.  44. 494.  17. 115. 458. 118.  43. 140.  34.] | prediction: [  5.420043  37.592445 375.2571    15.82601   83.03565  212.58769\n",
      "  87.10195   21.273106 111.29173   31.872477] | loss: 68.86016845703125\n",
      "step: 3 | gd_count: [21. 94. 51. 19. 27. 26.  8. 38. 20. 62.] | prediction: [20.646107 93.735916 71.6266   19.404594 27.718548 34.19413   9.542484\n",
      " 21.94976  21.324669 62.72224 ] | loss: 15.924371719360352\n",
      "step: 4 | gd_count: [ 38.  25.  49. 234. 210. 103.  95.  22.   3.   0.] | prediction: [ 40.527737  28.073118  46.146732 193.02545  206.69023  144.62296\n",
      " 155.8165    23.942135  12.193761  12.031018] | loss: 39.83893585205078\n",
      "step: 5 | gd_count: [ 26.  37. 150.  14.   3.  14.   0.  59.  33.  47.] | prediction: [ 25.982485  36.843002 131.95038   16.457684   9.539337  20.470968\n",
      "   9.916666  79.42128   38.770584  55.80567 ] | loss: 14.953913688659668\n",
      "step: 6 | gd_count: [161. 133.  56.  84. 119.   3.  24.  23.  30. 100.] | prediction: [104.32126   71.278305  49.596924  49.63908   87.45468   10.381512\n",
      "  32.58461   28.648033  28.413431  94.8234  ] | loss: 30.882511138916016\n",
      "step: 7 | gd_count: [ 21. 120.   8. 221.  59. 194.   0. 196.  30.  21.] | prediction: [ 11.913387   66.95        6.552121  135.01006    30.064783   77.23646\n",
      "   2.0989423  78.03353    15.791581   11.442793 ] | loss: 41.563758850097656\n",
      "step: 8 | gd_count: [21. 99.  0. 40. 43. 50. 11. 50. 33.  6.] | prediction: [18.214611  38.98462    2.4417264 21.897     26.356266  19.667763\n",
      "  7.7989187 28.020332  21.117283   4.3104334] | loss: 15.214823722839355\n",
      "step: 9 | gd_count: [108.  25. 340. 111.  20.  21.   7.   6.  35.   0.] | prediction: [ 63.599182   15.186923  128.93684    69.225555   10.690247   15.024488\n",
      "   3.0655437   3.4848118  19.907461    6.876174 ] | loss: 32.69291305541992\n",
      "step: 10 | gd_count: [189.  35.  89.  44.  29.  62. 159.  12.  87.  33.] | prediction: [149.1917    20.624157  76.57578   27.464136  23.965542  57.84886\n",
      " 143.2803    11.640764  66.79149   22.229383] | loss: 20.96954917907715\n",
      "step: 11 | gd_count: [85. 46. 33. 35. 14.  0. 51. 19. 14. 89.] | prediction: [102.60428   35.293327  32.805126  60.52172   12.467079   2.606498\n",
      "  51.448635  15.78826   23.561024 111.05821 ] | loss: 17.37725830078125\n",
      "step: 12 | gd_count: [ 37.  71.  21.  11. 133. 209.  43.  81.  50.  15.] | prediction: [ 21.146008  76.89493    8.08303   15.426503 153.05707  151.58728\n",
      "  61.163143  52.7715    43.581688  12.999514] | loss: 29.226181030273438\n",
      "step: 13 | gd_count: [142. 183.   0.  14. 141.  44.   5.   9.  39.  44.] | prediction: [138.68842   150.65659     1.8549677  15.59655    90.24892    32.171284\n",
      "   7.274399    8.174322   28.61872    43.14932  ] | loss: 20.814794540405273\n",
      "step: 14 | gd_count: [ 62. 218.  46.  54.  84.  41. 175.   0.  23.  37.] | prediction: [ 41.96374   148.08893    37.962543   34.697735   52.266792   25.781567\n",
      " 106.36829     1.2901573  23.204628   31.703575 ] | loss: 23.889312744140625\n",
      "step: 15 | gd_count: [111.  46.  91.  33. 166.   2.   3.  32. 119. 386.] | prediction: [ 75.708466   19.962627   52.23755    22.414669  129.43558     6.9739513\n",
      "   8.005184   28.444326   51.690376  112.6064   ] | loss: 51.7861442565918\n",
      "step: 16 | gd_count: [  1.  75. 696. 264.  12.  65.  28.  16.  25.  55.] | prediction: [  2.6631951  39.15982   264.89862   213.80498     8.723872   64.682816\n",
      "  15.747408    7.047221   23.0284     37.88253  ] | loss: 62.909645080566406\n",
      "step: 17 | gd_count: [  9. 282.  33.  89.  47.  57.  27.  22.  41. 167.] | prediction: [  7.140518  214.03511    38.711075  104.29704    25.995975   90.27228\n",
      "   7.5523996  23.058681   40.34127   199.41125  ] | loss: 33.503379821777344\n",
      "step: 18 | gd_count: [198.  17.  61.   3.  34.  17.  54.  21. 113.   6.] | prediction: [138.9313    12.273553  74.25466   13.386822  25.442537  32.0121\n",
      "  92.22897   23.233475 141.08746    9.290583] | loss: 24.69542694091797\n",
      "step: 19 | gd_count: [182. 107.  62.   8.   6.  36. 115.  69. 403. 110.] | prediction: [247.40097    69.61797    77.03004     6.4262495   5.245819   29.106804\n",
      "  86.95734    35.863976  357.92062   120.291695 ] | loss: 44.7885856628418\n",
      "step: 20 | gd_count: [ 36.  41.  81.  54.  23.  44.  23. 304.  54. 190.] | prediction: [ 25.356302  19.555988  36.149117  30.194723  16.441315  22.003616\n",
      "  17.17575   82.664116  30.724663 113.46257 ] | loss: 44.419960021972656\n",
      "step: 21 | gd_count: [ 95.   9.  87.   0. 137.  99. 146.  22.  24. 129.] | prediction: [30.901974   8.646437  44.405533   5.2306213 75.61701   56.12489\n",
      " 35.191887  23.567858  21.621426  64.181915 ] | loss: 38.74454879760742\n",
      "step: 22 | gd_count: [ 24. 347.  86.  56.  10.  19. 108.   5.  27.  43.] | prediction: [ 25.23666   148.14828    42.34691    26.657837   12.932056   25.99369\n",
      "  49.7186      7.7320065  26.965149   35.16839  ] | loss: 34.955047607421875\n",
      "step: 23 | gd_count: [  0.  33. 135.  69.  21.  42.   8.  76. 104.] | prediction: [ 6.6209745 28.218164  58.609684  38.10913   22.519897  36.976677\n",
      " 13.9044285 47.186996  47.023087 ] | loss: 26.192686080932617\n",
      "Epoch 15 Val, MSE: 309.98 MAE: 184.07, Cost 6.9 sec\n",
      "save best mse 309.98 mae 184.07 model epoch 15\n",
      "-----Epoch 16/19-----\n",
      "step: 0 | gd_count: [ 67.  33.   0.  80.  19.  20. 324. 142.  39.  22.] | prediction: [ 55.25399    34.110634    3.2001767  61.867367   29.19145    19.86424\n",
      " 133.84856    65.20332    39.65138    33.00005  ] | loss: 35.278465270996094\n",
      "step: 1 | gd_count: [ 20.  24. 192.   5.  46.   0.  56.   6.  17.  11.] | prediction: [ 21.95112    34.380066  123.211426    4.860276   43.64611     2.2219768\n",
      "  62.556686    6.1054897  24.56678    22.022135 ] | loss: 18.19571876525879\n",
      "step: 2 | gd_count: [100.  47.  48.  91.  18. 117.  70. 278.   8.  10.] | prediction: [ 87.82599   43.36299   50.866302  92.22128   14.171372  84.59112\n",
      "  87.95163  232.10394    8.183415  11.361095] | loss: 26.02349281311035\n",
      "step: 3 | gd_count: [173.  17.  41. 117.  19.  85.  73. 374.   0. 352.] | prediction: [150.28886    11.4854355  42.815334  147.45949    11.460548   70.34334\n",
      "  44.106827  229.82838     8.335948  222.94766  ] | loss: 61.3916130065918\n",
      "step: 4 | gd_count: [176.  19.  56.  20.  17.  38.   1.   2.  27. 184.] | prediction: [128.57143   19.13515   58.297863  10.92104   13.067819  32.195934\n",
      "   9.753127   8.002631  21.019701 236.1677  ] | loss: 24.235097885131836\n",
      "step: 5 | gd_count: [  5.   0.   1.  54.  29.  21. 136.  53.  29.  96.] | prediction: [  7.6817694   5.945918    5.9143553  12.493763    7.1912403  18.519539\n",
      " 104.91455    33.873486    7.1292214  69.27382  ] | loss: 18.881980895996094\n",
      "step: 6 | gd_count: [ 52.  12.  14.  67. 294.  89.  27.  25.  12. 125.] | prediction: [ 12.141016   4.813818   4.962077  41.88311  215.23108   43.47837\n",
      "   9.761204  12.271017   6.402302 100.83504 ] | loss: 30.235340118408203\n",
      "step: 7 | gd_count: [ 25.  55.   8. 209.  15.  96.  26.  90. 104.   8.] | prediction: [ 24.569832   41.181767    3.5206575 151.2871      4.8888507  79.94607\n",
      "  14.418814  120.90583    85.23362     4.664141 ] | loss: 25.683008193969727\n",
      "step: 8 | gd_count: [56. 84. 48. 93. 42.  5. 95. 14. 29. 88.] | prediction: [50.266563  62.709946  68.08456   90.66334   32.695667   2.6815476\n",
      " 90.42355   10.31152   16.442303  67.43568  ] | loss: 18.027265548706055\n",
      "step: 9 | gd_count: [ 33.   1.  25. 203.   6.  76.  93.  19.  58. 171.] | prediction: [ 37.40771     2.1490068  30.57301   195.07199     3.7021074  89.01625\n",
      "  55.43099    19.09563    42.61057    86.020355 ] | loss: 30.121082305908203\n",
      "step: 10 | gd_count: [ 12. 120.  52.   8.   3. 142. 205.  59. 315.   4.] | prediction: [ 11.782056   95.0995     52.842598   13.061497    2.6195602  57.30686\n",
      " 128.6446     65.91372   167.84253     2.699223 ] | loss: 40.88863754272461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 11 | gd_count: [ 39.  73. 131.   8.  72. 278.  53. 106.   9.  68.] | prediction: [ 48.86666    67.33464   107.28959     3.9984488  80.673546  173.77776\n",
      "  61.098587   88.480545    6.576332   69.32762  ] | loss: 30.785322189331055\n",
      "step: 12 | gd_count: [ 16.  35.  98.  44.  13.   8. 170.   3.  17.   8.] | prediction: [ 27.048931   39.57807    92.58626    43.06646    18.455822    7.0463753\n",
      " 132.37984     4.813898   18.281775   11.264877 ] | loss: 14.210138320922852\n",
      "step: 13 | gd_count: [ 21.  57.  16. 101.  28. 101.  12.  21.  27.  30.] | prediction: [ 24.397282  53.652657  18.35064  151.95142   22.985     73.19591\n",
      "   8.108151  22.414562  48.625378  40.44884 ] | loss: 19.301599502563477\n",
      "step: 14 | gd_count: [448.  17.  80.   0. 143.  12.  38. 296.  84.  67.] | prediction: [321.50613    11.4677515  62.117893    2.4708002  94.43657    11.446819\n",
      "  31.058823  148.06308    64.01347    50.724503 ] | loss: 42.863521575927734\n",
      "step: 15 | gd_count: [ 50. 132.  35.  75.  35.  36.  21. 481. 149.  35.] | prediction: [ 20.622982  73.04667   20.76936   43.81167   10.401012  15.827326\n",
      "  12.395725 126.05978   84.20392   13.367414] | loss: 59.500762939453125\n",
      "step: 16 | gd_count: [ 99.   0.  32.  24.  19. 220. 112.   2.  84.   0.] | prediction: [ 73.499825    2.131141   22.422726   20.71733    11.6261015 162.1369\n",
      "  84.94957     2.9114501  91.0305      4.7240205] | loss: 21.135305404663086\n",
      "step: 17 | gd_count: [ 37.  30.  67.  19.  10. 219.   6. 320.  23. 102.] | prediction: [ 36.432068  22.912323  99.285     20.890028  10.477968 258.31592\n",
      "   9.178342 153.19829   25.09331  149.77664 ] | loss: 42.03298568725586\n",
      "step: 18 | gd_count: [ 36.  96. 169.  35. 110. 165. 161.   9. 405. 226.] | prediction: [ 26.464764  41.359894 163.3764    16.467182 135.78653   87.69441\n",
      " 191.65543    5.027874 353.18033  239.5563  ] | loss: 56.56341552734375\n",
      "step: 19 | gd_count: [ 12.  29.  33.  13. 128.  10. 108.  33. 153.  21.] | prediction: [ 12.931715  22.141167  26.72439   11.185499 106.71344   11.099173\n",
      "  69.83978   18.510815  91.76915   19.847145] | loss: 17.35727882385254\n",
      "step: 20 | gd_count: [179.   6.  44.  69.  46.  82. 190.  13.  49.  93.] | prediction: [ 58.386963   5.944152  23.857801  39.79669   31.536167  24.995691\n",
      " 104.72732   12.203332  30.775917  59.491684] | loss: 36.31914520263672\n",
      "step: 21 | gd_count: [153. 185.  95. 193.  11. 110.  46. 259.  15.  19.] | prediction: [ 72.00065   78.97647   54.669357 113.55003   15.460337  25.665678\n",
      "  22.338572  75.335236  11.671617  14.160199] | loss: 59.70798873901367\n",
      "step: 22 | gd_count: [ 75.  41.  26.  89. 405.  23. 110.   4. 295.  29.] | prediction: [ 51.159348  40.08828   26.295025  73.622314 170.79582   26.262766\n",
      "  83.3932     8.288443 133.46536   27.228836] | loss: 48.616172790527344\n",
      "step: 23 | gd_count: [ 51.  17.   9.  79.  80.  16.  31. 315. 134.] | prediction: [ 51.00036   26.12592   18.23656   80.100624  91.85234   16.063656\n",
      "  37.462593 163.39368  118.94931 ] | loss: 31.29427719116211\n",
      "Epoch 16 Val, MSE: 304.19 MAE: 193.52, Cost 6.8 sec\n",
      "save best mse 304.19 mae 193.52 model epoch 16\n",
      "-----Epoch 17/19-----\n",
      "step: 0 | gd_count: [503.  44.  18.  68.  12.  35. 124.  26.  30. 236.] | prediction: [408.27243   54.19376   28.744709  74.68911   18.810741  48.799088\n",
      " 140.64209   42.5562    32.150444 161.70886 ] | loss: 45.99818801879883\n",
      "step: 1 | gd_count: [302.  15.   0.  50.  86.   3.   0.  46.  33.  15.] | prediction: [136.86612    17.90609     5.3305507  47.677246   90.6962      8.704077\n",
      "   5.1161823  59.88285    47.32267    23.146057 ] | loss: 30.832983016967773\n",
      "step: 2 | gd_count: [ 65.   8.  57.  11.  88.  28.   0.  14. 188.  64.] | prediction: [ 58.74721    6.70161   50.396503   9.522622 143.02625   11.780701\n",
      "   7.954122  11.286384 197.10863   42.389366] | loss: 22.833885192871094\n",
      "step: 3 | gd_count: [260.  80.  30.  68.  68.  57.   8.  57.  72.  71.] | prediction: [301.55096   45.392204  16.797146  70.371704  48.669724  19.621223\n",
      "   4.226507  57.902195  18.84161   52.276344] | loss: 35.226802825927734\n",
      "step: 4 | gd_count: [ 29.  80.  85.  43. 201.  11.  22. 219.  68.  15.] | prediction: [  5.964745   30.014704   35.170757    9.324919  129.40582     5.934172\n",
      "   8.835732  133.32562    22.445347    6.0083437] | loss: 36.926727294921875\n",
      "step: 5 | gd_count: [ 13. 110.  35. 109.  39.  20.  19.   3.  26. 182.] | prediction: [ 7.6263084 58.178932  14.953799  55.476364  12.83344    7.344519\n",
      " 10.96205    5.1633205 10.549238  93.37043  ] | loss: 25.6575870513916\n",
      "step: 6 | gd_count: [222.  25.  67. 160.  81.  58.   0.  20.  69.   0.] | prediction: [203.177      13.392092   49.42369    88.31197    48.10891    62.959732\n",
      "   6.8038607  10.562924   46.830284    6.877365 ] | loss: 27.900293350219727\n",
      "step: 7 | gd_count: [154.  27. 161. 126.  36. 105. 112. 120.  50.  23.] | prediction: [155.59253   34.560074 130.49556  112.75781   24.062708 131.0932\n",
      "  78.455414  97.89868   57.7728    21.542286] | loss: 34.060081481933594\n",
      "step: 8 | gd_count: [ 40.  14.  24. 165.  19.  40. 165.  36.  63. 235.] | prediction: [ 51.793003  28.234512  30.077534 182.60785   28.77316   47.575554\n",
      " 186.85435   39.695038  41.354836 157.8838  ] | loss: 34.8170280456543\n",
      "step: 9 | gd_count: [ 33. 167. 263.  16.  30. 216. 252.   0.  51. 241.] | prediction: [ 36.327065  88.868866 171.9616    22.642864  35.34655  117.961044\n",
      " 160.25925    5.687156  50.95655  182.45096 ] | loss: 58.07059860229492\n",
      "step: 10 | gd_count: [ 34.  73.  18.  22.  48.   1.  94. 121.  32.  19.] | prediction: [40.247303 48.524742 17.474813 35.404118 52.969196  8.944748 84.261314\n",
      " 68.98348  33.396423 23.577929] | loss: 21.329580307006836\n",
      "step: 11 | gd_count: [ 38. 129.  85. 120.  34.  15.   0.  28.  51. 229.] | prediction: [ 34.720657   82.19232    63.490673   77.92184    36.02739    22.646717\n",
      "   6.7692986  23.011913   19.948776  160.46504  ] | loss: 27.76251220703125\n",
      "step: 12 | gd_count: [ 10. 185. 103.   5.  43.  30. 122.  79.  15. 267.] | prediction: [ 16.245058 131.33165   63.77867    9.00789   30.354713  28.462317\n",
      "  58.449448  58.673073  23.48587   88.040535] | loss: 38.631587982177734\n",
      "step: 13 | gd_count: [202.  11.  91.  82.  37.   4.  13. 180. 179.   9.] | prediction: [149.99945    12.463242   81.59837   102.41135    31.71131     8.655041\n",
      "   5.097232  146.04263    85.04828     7.3383904] | loss: 30.35016441345215\n",
      "step: 14 | gd_count: [130.  87.   9. 136.  47.  93.  66. 156.  36.  30.] | prediction: [ 89.69823    98.40419     7.1992517  99.26553    23.109951   79.613464\n",
      "  80.51154   157.4052     21.37466    20.340927 ] | loss: 27.071033477783203\n",
      "step: 15 | gd_count: [  0.  27.  44.  31.  72.  13.  45. 381.   9. 217.] | prediction: [  2.6351109  20.238718   32.646374   19.086803   58.488556   11.748914\n",
      "  24.308784  209.75351     6.9458866 103.190384 ] | loss: 38.37646484375\n",
      "step: 16 | gd_count: [ 27.  34. 185. 144.  16.  14.  71.  39.   4. 149.] | prediction: [ 23.612534   34.74529    54.60282   213.96829     9.440363   11.249369\n",
      "  79.98671    29.86627     4.8143787 237.36557  ] | loss: 41.0813102722168\n",
      "step: 17 | gd_count: [ 64.  11.   9. 204.  38. 103.  37.  17.  12. 306.] | prediction: [ 51.874084    6.673027    3.4455614 196.18854    36.575386   78.23448\n",
      "  17.465519   10.584139   11.221801  224.75922  ] | loss: 28.658292770385742\n",
      "step: 18 | gd_count: [310.  35.  11.  37. 105.  41. 206.   3.  19.  67.] | prediction: [224.97374    21.072626    5.3606167  40.01032    95.39279    23.000124\n",
      " 213.45772     2.107169   13.261818   52.61938  ] | loss: 28.424945831298828\n",
      "step: 19 | gd_count: [136.  82.   0. 155.  36. 136.  14. 182.  50.  53.] | prediction: [107.03965    62.005737    2.1716533 119.56262    29.526913   84.400604\n",
      "  18.116474  120.5598     31.150856   20.644855 ] | loss: 30.90865135192871\n",
      "step: 20 | gd_count: [ 11.  42. 110.  38.  10.  98.  76.   6.  17.   0.] | prediction: [10.066875  30.067986  89.30065   33.53276    9.464971  86.37106\n",
      " 55.187374   8.253274  13.488911   2.6816118] | loss: 11.826105117797852\n",
      "step: 21 | gd_count: [ 52.  60.  41.  67. 267.  46.   3.  11.   7. 209.] | prediction: [ 36.10205    45.640205   37.61773    50.152992  136.98016    43.244205\n",
      "   3.3303928  14.38855     9.614294  139.86005  ] | loss: 28.368789672851562\n",
      "step: 22 | gd_count: [ 28. 140.   7.  85.  46.  60.  12.  12.  39.  32.] | prediction: [25.581451  79.405205   4.0977955 69.95862   37.43222   50.19242\n",
      " 16.21448   18.938683  32.395668  30.787916 ] | loss: 14.605981826782227\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 23 | gd_count: [ 97.  52.  39. 252. 281.   0.  90.   5.   8.] | prediction: [ 86.11427   43.25642   31.49714  131.58063  165.37344    8.110395\n",
      "  60.149166   5.376668  11.40314 ] | loss: 38.21353530883789\n",
      "Epoch 17 Val, MSE: 284.92 MAE: 144.43, Cost 6.8 sec\n",
      "save best mse 284.92 mae 144.43 model epoch 17\n",
      "-----Epoch 18/19-----\n",
      "step: 0 | gd_count: [  0. 180. 108.   8.  66.  14.  51.  70.  40.  41.] | prediction: [  2.1678019 194.78769   121.73546     9.872475   52.792213   13.009092\n",
      "  37.016907   48.031906   38.708565   38.445824 ] | loss: 21.11506462097168\n",
      "step: 1 | gd_count: [157.   1. 236.  88.   8.   2.   9.  41. 406.  19.] | prediction: [ 88.21001     3.4300704 184.28644    94.02672     4.20651     3.8528092\n",
      "   8.037836   34.3765    231.26187    18.561722 ] | loss: 36.59150695800781\n",
      "step: 2 | gd_count: [ 89.  45.  45.  25. 458. 301.  23.  55.  85.  10.] | prediction: [106.17685   36.370094  66.51525   18.97865  223.2131   333.96283\n",
      "  27.47361   57.007225  82.65147    9.932459] | loss: 51.92962646484375\n",
      "step: 3 | gd_count: [180. 137. 119.  65. 357.  22.   1.  12. 447.   1.] | prediction: [243.3992    135.97298   137.24435    67.05237   230.5662     21.609486\n",
      "   3.543741    8.359233  506.22543     3.5649061] | loss: 61.270076751708984\n",
      "step: 4 | gd_count: [ 65.  21.  25.  75. 275. 124.  95. 114. 237.  13.] | prediction: [ 41.403793  16.668274  15.573873  59.063347 152.78528   85.76573\n",
      "  29.15412   58.5627   129.9068     9.595428] | loss: 42.3747444152832\n",
      "step: 5 | gd_count: [104.  17. 238. 169.  46.  35.  24.   0.  35. 185.] | prediction: [ 53.911186    6.806267   55.93197   105.24024    30.382355   19.259926\n",
      "  12.234865    3.7578142  24.17202    92.1685   ] | loss: 43.93976974487305\n",
      "step: 6 | gd_count: [  7.  13. 278.  24. 807.   4. 122.  47. 135.  25.] | prediction: [  2.5194721   3.7247565 119.554146   17.446114  193.19807     3.6742334\n",
      "  67.51419    28.502846   46.88564     8.223818 ] | loss: 93.81946563720703\n",
      "step: 7 | gd_count: [265.  34.  72. 125. 300. 122.  48. 243.  15. 163.] | prediction: [137.4904    22.455196  47.004086  71.9382   153.83821   68.124374\n",
      "  46.764946  94.14349   12.717516  96.01102 ] | loss: 64.22151947021484\n",
      "step: 8 | gd_count: [ 18.   2. 361.  92.  26.  84.  50. 117.  85.  37.] | prediction: [ 16.310184   6.480842 251.60861   87.77391   28.481434  84.86478\n",
      "  46.09652   95.7301    67.29884   50.116524] | loss: 31.557621002197266\n",
      "step: 9 | gd_count: [ 22.  14.   5.  10. 156.  99.  52.  62.  28.  63.] | prediction: [ 35.30178   16.707298   4.770758  24.723541 138.94302  117.92879\n",
      "  71.80812   72.599     40.4479    71.88505 ] | loss: 25.998483657836914\n",
      "step: 10 | gd_count: [115.  87.  53.  86.  64.   4.  35. 436. 112.  66.] | prediction: [168.09009   105.955086   60.871803  109.30615   112.34042     3.6149774\n",
      "  50.484386  354.06802   112.26496    82.76739  ] | loss: 48.003143310546875\n",
      "step: 11 | gd_count: [  2.  58.  10. 137. 186.  33. 226.  18.  28. 128.] | prediction: [  9.536619  60.94173    4.844078 103.94523  176.06497   26.653572\n",
      " 262.89328   10.102237  19.597504 110.01478 ] | loss: 31.105539321899414\n",
      "step: 12 | gd_count: [151.   1.  16.  74.  11.   9.  78.  16.  66.  94.] | prediction: [112.36522     3.492516   10.610632   31.06118     8.214117    4.7115836\n",
      "  28.740185    9.801443   36.958267   76.78956  ] | loss: 20.903547286987305\n",
      "step: 13 | gd_count: [ 31.  19.  48.  66.   5.  15.  92.  25. 110. 261.] | prediction: [ 15.229726   11.218989   23.043663   26.845104    5.162459    5.4542727\n",
      "  51.960945   10.554329   33.631363  127.44729  ] | loss: 33.702735900878906\n",
      "step: 14 | gd_count: [156. 167.   0.  60.  45.  27.  23.  23.  31. 264.] | prediction: [72.0363    60.445114   2.1222677 18.5046    14.395484  15.143399\n",
      "  8.830977   8.289985  13.67492   56.377205 ] | loss: 49.45855712890625\n",
      "step: 15 | gd_count: [ 38.  36.  86.  33.  44. 269.  36. 250.  32.  50.] | prediction: [ 17.135677   18.237885   41.089836   17.205574   11.517471  118.03471\n",
      "  15.331823  150.04361     7.3941317  25.653275 ] | loss: 42.34382247924805\n",
      "step: 16 | gd_count: [ 17.  47. 132.  50.  16.  80. 163. 110.   7.  45.] | prediction: [ 13.476814   31.176937  100.24959    44.45346    11.917484   52.474907\n",
      " 114.67794    73.85214     6.8745317  27.014519 ] | loss: 22.492631912231445\n",
      "step: 17 | gd_count: [ 18.  77.  76. 100.  36.  99.   5. 121.   0.  36.] | prediction: [ 29.414543 113.33484   62.32531  132.37294   36.748604 128.80522\n",
      "  15.062403 122.42822    4.248494  43.870102] | loss: 27.596729278564453\n",
      "step: 18 | gd_count: [147.   0.  67.  13.  77.  59.  27.  26.  23.  15.] | prediction: [134.55711    8.080539  59.362198  43.114105  77.01312   84.05051\n",
      "  43.927223  43.56843   43.089485  28.248228] | loss: 27.571664810180664\n",
      "step: 19 | gd_count: [138.  23.  88.  38.  65.  15. 119.  33.  30.  31.] | prediction: [103.44401   48.28096   93.08429   50.978775  76.28459   28.997177\n",
      "  88.69661   54.575897  37.526016  42.680283] | loss: 31.027469635009766\n",
      "step: 20 | gd_count: [179. 183.  85.  26. 123.  12.  41.  41.  39.  80.] | prediction: [168.16055  111.153275  88.32287   32.392025 106.3174    32.070045\n",
      "  38.22741   39.114044  38.501877  97.841446] | loss: 32.79764938354492\n",
      "step: 21 | gd_count: [ 34.  39.  59. 257.  78.  87.  45.  11. 331.  60.] | prediction: [ 27.960537  22.04775   53.87226  192.90253   51.54976   44.25554\n",
      "  32.41749   18.598236 144.72543   46.260166] | loss: 43.54740524291992\n",
      "step: 22 | gd_count: [ 45. 150.  26.   4. 113.  84.   9.  22.  26.  54.] | prediction: [32.536106  70.0056    18.966267   7.1005163 67.744064  52.34146\n",
      " 13.819454  22.986288  19.113117  35.326828 ] | loss: 19.95370101928711\n",
      "step: 23 | gd_count: [ 36. 408.   2.  19. 132.  21. 100. 196.  20.] | prediction: [ 25.570827  192.54376     5.7117205  13.790634   78.00676    19.165796\n",
      "  53.192276  118.63973    14.658777 ] | loss: 44.61205291748047\n",
      "Epoch 18 Val, MSE: 298.78 MAE: 196.14, Cost 6.8 sec\n",
      "save best mse 298.78 mae 196.14 model epoch 18\n",
      "-----Epoch 19/19-----\n",
      "step: 0 | gd_count: [ 22. 200.  20.  23.   7.  72.  85. 215.   1. 115.] | prediction: [ 14.1733    154.89084     5.9173956  21.3811      8.069836   42.453506\n",
      "  33.580498  112.71098     6.688943   78.953674 ] | loss: 31.756072998046875\n",
      "step: 1 | gd_count: [ 32. 151.  22.  74.   5.  35.  37.  44.  26. 176.] | prediction: [ 12.010539  113.853096    9.030851   64.60063     6.6890287  11.092545\n",
      "  25.378971   20.045517   22.016829  154.86371  ] | loss: 21.38571548461914\n",
      "step: 2 | gd_count: [ 76.  54.   0. 101.  16.  15.  21.  75.  74.  43.] | prediction: [84.60066   45.070305   6.5076704 92.40638    7.9211435  7.667695\n",
      " 12.306942  72.94403   79.11243   11.525427 ] | loss: 18.384958267211914\n",
      "step: 3 | gd_count: [434. 448.  33.  20.  23.  23.  94. 203.  96.  25.] | prediction: [348.8476   231.17245   41.923347  17.609888  16.531593  24.823605\n",
      " 120.490906 187.08098   94.157196  13.636726] | loss: 75.78971099853516\n",
      "step: 4 | gd_count: [ 34.  17.   5.   6. 228.  65.   0. 219.   8.  73.] | prediction: [ 34.69888    15.918601    3.1021771   4.3247495 145.27179    58.22524\n",
      "   2.938267  277.03125     7.165907   86.95547  ] | loss: 33.23190689086914\n",
      "step: 5 | gd_count: [314. 140. 450. 177. 110.  12.  57.   4.  47.   9.] | prediction: [160.04143   179.63527   306.63095   143.18533   148.77985    15.092972\n",
      "  71.710075    2.3638911  51.643475   11.380165 ] | loss: 57.63838577270508\n",
      "step: 6 | gd_count: [127. 185.  77.  16. 125.  65.  42.  70.  46.   5.] | prediction: [100.1207    114.994934   69.365295   12.306397  163.33614    59.106205\n",
      "  48.272003   63.263897   44.111282    7.4847946] | loss: 29.657438278198242\n",
      "step: 7 | gd_count: [ 86.  11.  27.  55.   0.  52. 116.  44. 124. 179.] | prediction: [ 57.893692  13.868724  32.688175  43.9073     5.020693  47.85432\n",
      "  49.76956   45.110786  78.98299  116.37515 ] | loss: 26.626239776611328\n",
      "step: 8 | gd_count: [ 78.  22.  16.  35.  46.  28.  78. 137.  80.  59.] | prediction: [ 46.227097  11.577638  13.147132  24.757736  39.35951   24.555967\n",
      "  60.41083  112.24647   71.679146  30.115768] | loss: 18.162248611450195\n",
      "step: 9 | gd_count: [  6. 141. 284. 152. 165.   0. 237.   4.  45. 100.] | prediction: [ 10.570252   52.134567  117.48767    94.93387    67.977066    6.2394958\n",
      " 104.6071     10.898691   33.298256   63.700832 ] | loss: 58.14985275268555\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 10 | gd_count: [ 45.   2. 156.  19.  22. 121.   0.  26.   0.  42.] | prediction: [30.528698  6.414038 83.72128  11.198234 22.54165  44.968803  5.532557\n",
      " 21.901278  6.199065 36.744453] | loss: 19.115867614746094\n",
      "step: 11 | gd_count: [262.   8.  65.   3. 138.  20.  68. 240.   5. 373.] | prediction: [ 84.99544     4.8218956  45.206276    5.5766935  76.30916    20.333542\n",
      "  80.8613    114.34697     5.086893  103.60603  ] | loss: 66.67695617675781\n",
      "step: 12 | gd_count: [36. 21. 15. 17. 41. 35. 21. 67. 30. 26.] | prediction: [30.81688  15.772711 21.77002  17.168987 42.218018 41.202793 18.788397\n",
      " 69.37594  24.027208 27.378807] | loss: 9.23518180847168\n",
      "step: 13 | gd_count: [77. 86. 64. 21. 41. 15. 27. 56. 59. 42.] | prediction: [81.435776 71.4193   53.015083 20.353054 12.260988 13.929901 13.99749\n",
      " 71.704735 73.991974 51.46001 ] | loss: 17.992023468017578\n",
      "step: 14 | gd_count: [ 81.  50. 147.  13.  70.  46. 125.  21.  93.  33.] | prediction: [ 84.77553   39.47283  121.91572    8.36242   70.584076  15.351799\n",
      " 102.849174  19.132895  80.878136  36.84486 ] | loss: 21.701200485229492\n",
      "step: 15 | gd_count: [ 33.  29.  96.  10.  80.  55.  61.  89. 180.  40.] | prediction: [28.981138 40.431557 76.79317   9.73334  69.01488  65.766136 38.365814\n",
      " 71.71403  94.688896 34.377327] | loss: 26.816436767578125\n",
      "step: 16 | gd_count: [  2.  38. 283.  36.  52.  30. 132.  68. 116.  83.] | prediction: [  5.026444  17.123917 185.21637   15.679646  19.494087  15.291531\n",
      "  89.610016  41.240982  79.23807   66.76213 ] | loss: 36.87150955200195\n",
      "step: 17 | gd_count: [ 50.  28.  35. 114.   6. 107.  37.  58. 131. 131.] | prediction: [20.905352 12.508844 26.566769 57.096672 13.720401 71.862274 30.689556\n",
      " 52.885506 90.59447  97.0043  ] | loss: 25.702850341796875\n",
      "step: 18 | gd_count: [  7.  44.  19.   9.  72.  39. 333.  18. 219.  30.] | prediction: [  6.893976   23.351362   12.303406    2.9159036  50.83378    21.37045\n",
      " 211.75334     6.495237  113.06346    10.389788 ] | loss: 32.58059310913086\n",
      "step: 19 | gd_count: [ 34.  36.  18.  41.  43.   9.   8. 359. 144. 124.] | prediction: [ 16.983013  22.89252   17.660547  37.51117   26.918497   8.423621\n",
      "   5.532029 237.4917    74.0224   116.17131 ] | loss: 37.932945251464844\n",
      "step: 20 | gd_count: [ 82.  31.  14.  23.  15.  36. 188.  15.  42. 162.] | prediction: [ 68.57382   32.684578  14.068822  30.484343  27.35535   30.174238\n",
      "  91.34719   22.195778  54.97303  248.81778 ] | loss: 34.31032180786133\n",
      "step: 21 | gd_count: [ 20.  18. 169.  87. 103. 192.  51.  13.  31.  56.] | prediction: [ 26.579147  28.531448 173.03717   87.6856   136.5368   171.44763\n",
      "  73.67821   14.621739  36.374687  57.37822 ] | loss: 32.420738220214844\n",
      "step: 22 | gd_count: [ 35.  44.  63.  55.  30.  13.  77.  42.  31. 217.] | prediction: [ 29.951893  51.757843  74.30142   77.67438   27.044159  20.146154\n",
      "  78.212814  35.222294  25.885439 184.5903  ] | loss: 24.946836471557617\n",
      "step: 23 | gd_count: [  0. 227. 151. 222.  53.  84.  53.  20.  22.] | prediction: [  4.1408167 203.45444    80.20617   154.40054    28.864964   47.88955\n",
      "  24.932386   21.5648     18.305206 ] | loss: 36.494903564453125\n",
      "Epoch 19 Val, MSE: 308.47 MAE: 200.54, Cost 6.8 sec\n",
      "save best mse 308.47 mae 200.54 model epoch 19\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('tensorboard_test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-80-39d7cdd08480>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/writer.py\u001b[0m in \u001b[0;36madd_graph\u001b[0;34m(self, model, input_to_model, verbose)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'forward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m             \u001b[0;31m# A valid PyTorch model should have a 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_to_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m             \u001b[0;31m# Caffe2 models do not have the 'forward' method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/utils/tensorboard/_pytorch_graph.py\u001b[0m in \u001b[0;36mgraph\u001b[0;34m(model, args, verbose)\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# TODO: move outside of torch.onnx?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m             \u001b[0mtrace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m             \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_pass_inline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace\u001b[0;34m(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m    880\u001b[0m         return trace_module(func, {'forward': example_inputs}, None,\n\u001b[1;32m    881\u001b[0m                             \u001b[0mcheck_trace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrap_check_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheck_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m                             check_tolerance, _force_outplace, _module_class)\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     if (hasattr(func, '__self__') and isinstance(func.__self__, torch.nn.Module) and\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mtrace_module\u001b[0;34m(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, _force_outplace, _module_class, _compilation_unit)\u001b[0m\n\u001b[1;32m   1031\u001b[0m             \u001b[0;31m# this is needed since Module.__call__ sets up some extra tracing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmethod_name\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"forward\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1033\u001b[0;31m             \u001b[0mexample_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1034\u001b[0m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_method_from_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_lookup_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_force_outplace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1035\u001b[0m             \u001b[0mcheck_trace_method\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/torch/jit/__init__.py\u001b[0m in \u001b[0;36mmake_tuple\u001b[0;34m(example_inputs)\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0;31m# done primarily so that weird iterables fail here and not pybind11 code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 706\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    707\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mexample_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "writer.add_graph(model)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(dataloaders['val']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "perm = np.random.permutation(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ATTENTION - NE PAS TOUCHER\n",
    "\n",
    "for i in range(300):\n",
    "    if i < 60:\n",
    "        path_img = os.path.join(\"SHHA/train\", f'IMG_{perm[i]}.jpg')\n",
    "        path_npy = os.path.join(\"SHHA/train\", f'IMG_{perm[i]}.npy')\n",
    "        # os.remove(path_img)\n",
    "        # os.remove(path_npy)\n",
    "    else:\n",
    "        if i > 91:\n",
    "            path_img = os.path.join(\"SHHA/val\", f'IMG_{perm[i]}.jpg')\n",
    "            path_npy = os.path.join(\"SHHA/val\", f'IMG_{perm[i]}.npy')\n",
    "            ## os.remove(path_img)\n",
    "            ## os.remove(path_npy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "91\n"
     ]
    }
   ],
   "source": [
    "for i in range(300):\n",
    "    if perm[i] == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5, 229,  86, 246, 238,  22, 167, 277, 212,   6,  93, 197, 267,\n",
       "       228,  45,  37, 111,  80, 241, 260,  30,  48, 262,  71, 179, 160,\n",
       "       181, 146, 163, 161, 172, 278, 109, 104, 201, 155, 183, 296,  41,\n",
       "       108,  14,  78, 251, 185, 194, 199, 139, 195,  98, 255, 131, 122,\n",
       "        11,  21, 214,  58, 219,  65, 119, 145, 275,  82, 126,  92, 188,\n",
       "        38, 112, 149,   4, 253, 143,  47,  75, 206,  73,  64,  56, 268,\n",
       "       159, 274, 235, 297, 171,  25,   2,  29,  44, 285,  90, 137,  77,\n",
       "         0, 207, 107, 117,  52, 168,   8, 138, 269, 299, 169,  66,  91,\n",
       "       115,  42, 209, 225, 240, 153, 125, 105,  39,  63, 298, 173, 102,\n",
       "       100, 261, 103, 247,  61, 249, 129, 202, 252, 120,  35,  43, 170,\n",
       "       230, 133, 273, 237, 263, 259, 142, 132, 182, 198,  74,  54, 292,\n",
       "        17, 114, 118, 166,  55,  59, 191, 121, 144, 205, 254,  26, 294,\n",
       "       215, 281, 151,  60,  46,  15, 176,   9, 211,  16,   1, 124, 110,\n",
       "       289, 165,  84, 203,  79, 236, 128, 147, 113,  28,  88,  20,  50,\n",
       "       288, 162,  97,  10,  13, 158, 178,  87, 266, 291, 106, 141,  94,\n",
       "       127, 218, 286, 186,  57, 293, 233,  27, 116, 157, 223, 284, 271,\n",
       "        34, 180,  62, 258,  89, 154,  95,  96,  67,  81,  70, 184, 257,\n",
       "       134, 265, 177, 192, 220, 217,  23,  18, 152, 280,  72, 208, 174,\n",
       "       221, 245, 200, 226, 187, 242, 232, 279,  99,  85,  40,  19, 283,\n",
       "       213, 216, 243, 130,  53, 101, 175, 295,  49, 287, 224, 190, 250,\n",
       "        51, 264, 150, 222, 193, 135, 156, 148, 256, 204, 140,   3,  76,\n",
       "        36,  69, 272,  83, 276,   7, 210, 239, 231,  32, 244,  68, 248,\n",
       "        12, 196,  33, 136,  24,  31, 282, 290, 234, 227, 189, 123, 164,\n",
       "       270])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
