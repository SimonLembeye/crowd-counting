{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models,transforms,datasets\n",
    "import time\n",
    "from torch.utils import data\n",
    "%matplotlib inline\n",
    "import torchvision.transforms as standard_transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from torch import optim\n",
    "from torch.autograd import Variable\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from PIL import Image, ImageOps, ImageFilter\n",
    "import numbers\n",
    "import pdb\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using gpu: False \n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Using gpu: %s ' % torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open ShanghaiTech_Crowd_Counting_Dataset.zip, ShanghaiTech_Crowd_Counting_Dataset.zip.zip or ShanghaiTech_Crowd_Counting_Dataset.zip.ZIP.\r\n"
     ]
    }
   ],
   "source": [
    "!unzip ShanghaiTech_Crowd_Counting_Dataset.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHHA(data.Dataset):\n",
    "    def __init__(self, data_path, mode, main_transform=None, img_transform=None, gt_transform=None):\n",
    "        self.img_path = data_path + '/img'\n",
    "        self.gt_path = data_path + '/den'\n",
    "        self.data_files = [filename for filename in os.listdir(self.img_path) \\\n",
    "                           if os.path.isfile(os.path.join(self.img_path,filename))]\n",
    "        self.num_samples = len(self.data_files) \n",
    "        self.main_transform=main_transform  \n",
    "        self.img_transform = img_transform\n",
    "        self.gt_transform = gt_transform     \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        fname = self.data_files[index]\n",
    "        img, den = self.read_image_and_gt(fname)      \n",
    "        if self.main_transform is not None:\n",
    "            img, den = self.main_transform(img,den) \n",
    "        if self.img_transform is not None:\n",
    "            img = self.img_transform(img)         \n",
    "        if self.gt_transform is not None:\n",
    "            den = self.gt_transform(den)               \n",
    "        return img, den\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_samples\n",
    "\n",
    "    def read_image_and_gt(self,fname):\n",
    "        img = Image.open(os.path.join(self.img_path,fname))\n",
    "        if img.mode == 'L':\n",
    "            img = img.convert('RGB')\n",
    "\n",
    "        # den = sio.loadmat(os.path.join(self.gt_path,os.path.splitext(fname)[0] + '.mat'))\n",
    "        # den = den['map']\n",
    "        den = pd.read_csv(os.path.join(self.gt_path,os.path.splitext(fname)[0] + '.csv'), sep=',',header=None).values\n",
    "        \n",
    "        den = den.astype(np.float32, copy=False)    \n",
    "        den = Image.fromarray(den)  \n",
    "        return img, den    \n",
    "\n",
    "    def get_num_samples(self):\n",
    "        return self.num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(models):\n",
    "    for model in models:\n",
    "        real_init_weights(model)\n",
    "\n",
    "\n",
    "def real_init_weights(m):\n",
    "\n",
    "    if isinstance(m, list):\n",
    "        for mini_m in m:\n",
    "            real_init_weights(mini_m)\n",
    "    else:\n",
    "        if isinstance(m, nn.Conv2d):    \n",
    "            nn.init.normal_(m.weight, std=0.01)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.Linear):\n",
    "            m.weight.data.normal_(0.0, std=0.01)\n",
    "        elif isinstance(m, nn.BatchNorm2d):\n",
    "            nn.init.constant_(m.weight, 1)\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m,nn.Module):\n",
    "            for mini_m in m.children():\n",
    "                real_init_weights(mini_m)\n",
    "        else:\n",
    "            print( m )\n",
    "\n",
    "def weights_normal_init(*models):\n",
    "    for model in models:\n",
    "        dev=0.01\n",
    "        if isinstance(model, list):\n",
    "            for m in model:\n",
    "                weights_normal_init(m, dev)\n",
    "        else:\n",
    "            for m in model.modules():            \n",
    "                if isinstance(m, nn.Conv2d):        \n",
    "                    m.weight.data.normal_(0.0, dev)\n",
    "                    if m.bias is not None:\n",
    "                        m.bias.data.fill_(0.0)\n",
    "                elif isinstance(m, nn.Linear):\n",
    "                    m.weight.data.normal_(0.0, dev)\n",
    "\n",
    "\n",
    "def logger(exp_path, exp_name, work_dir, exception, resume=False):\n",
    "\n",
    "    from tensorboardX import SummaryWriter\n",
    "    \n",
    "    if not os.path.exists(exp_path):\n",
    "        os.mkdir(exp_path)\n",
    "    writer = SummaryWriter(exp_path+ '/' + exp_name)\n",
    "    log_file = exp_path + '/' + exp_name + '/' + exp_name + '.txt'\n",
    "    \n",
    "    cfg_file = open('./config.py',\"r\")  \n",
    "    cfg_lines = cfg_file.readlines()\n",
    "    \n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(''.join(cfg_lines) + '\\n\\n\\n\\n')\n",
    "\n",
    "    if not resume:\n",
    "        copy_cur_env(work_dir, exp_path+ '/' + exp_name + '/code', exception)\n",
    "\n",
    "\n",
    "    return writer, log_file\n",
    "\n",
    "\n",
    "\n",
    "def logger_for_CMTL(exp_path, exp_name, work_dir, exception, resume=False):\n",
    "    \n",
    "    if not os.path.exists(exp_path):\n",
    "        os.mkdir(exp_path)\n",
    "\n",
    "    if not os.path.exists(exp_path+ '/' + exp_name):\n",
    "        os.mkdir(exp_path+ '/' + exp_name)\n",
    "    log_file = exp_path + '/' + exp_name + '/' + exp_name + '.txt'\n",
    "    \n",
    "    cfg_file = open('./config.py',\"r\")  \n",
    "    cfg_lines = cfg_file.readlines()\n",
    "    \n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write(''.join(cfg_lines) + '\\n\\n\\n\\n')\n",
    "\n",
    "    if not resume:\n",
    "        copy_cur_env(work_dir, exp_path+ '/' + exp_name + '/code', exception)\n",
    "\n",
    "\n",
    "    return log_file\n",
    "\n",
    "def logger_txt(log_file,epoch,scores):\n",
    "\n",
    "    mae, mse, loss = scores\n",
    "\n",
    "    snapshot_name = 'all_ep_%d_mae_%.1f_mse_%.1f' % (epoch + 1, mae, mse)\n",
    "\n",
    "    # pdb.set_trace()\n",
    "\n",
    "    with open(log_file, 'a') as f:\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')\n",
    "        f.write(snapshot_name + '\\n')\n",
    "        f.write('    [mae %.2f mse %.2f], [val loss %.4f]\\n' % (mae, mse, loss))\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def vis_results(exp_name, epoch, writer, restore, img, pred_map, gt_map):\n",
    "\n",
    "    pil_to_tensor = standard_transforms.ToTensor()\n",
    "\n",
    "    x = []\n",
    "    \n",
    "    for idx, tensor in enumerate(zip(img.cpu().data, pred_map, gt_map)):\n",
    "        if idx>1:# show only one group\n",
    "            break\n",
    "        pil_input = restore(tensor[0])\n",
    "        pil_output = torch.from_numpy(tensor[1]/(tensor[2].max()+1e-10)).repeat(3,1,1)\n",
    "        pil_label = torch.from_numpy(tensor[2]/(tensor[2].max()+1e-10)).repeat(3,1,1)\n",
    "        x.extend([pil_to_tensor(pil_input.convert('RGB')), pil_label, pil_output])\n",
    "    x = torch.stack(x, 0)\n",
    "    x = vutils.make_grid(x, nrow=3, padding=5)\n",
    "    x = (x.numpy()*255).astype(np.uint8)\n",
    "\n",
    "    writer.add_image(exp_name + '_epoch_' + str(epoch+1), x)\n",
    "\n",
    "\n",
    "\n",
    "def print_summary(exp_name,scores,train_record):\n",
    "    mae, mse, loss = scores\n",
    "    print( '='*50 )\n",
    "    print( exp_name )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '    [mae %.2f mse %.2f], [val loss %.4f]' % (mae, mse, loss) )        \n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '[best] [model: %s] , [mae %.2f], [mse %.2f]' % (train_record['best_model_name'],\\\n",
    "                                                        train_record['best_mae'],\\\n",
    "                                                        train_record['best_mse']) )\n",
    "    print( '='*50)\n",
    "\n",
    "def print_WE_summary(log_txt,epoch,scores,train_record,c_maes):\n",
    "    mae, mse, loss = scores\n",
    "    # pdb.set_trace()\n",
    "    with open(log_txt, 'a') as f:\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n')\n",
    "        f.write(str(epoch) + '\\n\\n')\n",
    "        f.write('  [mae %.4f], [val loss %.4f]\\n\\n' % (mae, loss))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes.avg)) + '\\n')\n",
    "\n",
    "\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')\n",
    "\n",
    "    print( '='*50 )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '    [mae %.2f mse %.2f], [val loss %.4f]' % (mae, mse, loss) )        \n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '[best] [model: %s] , [mae %.2f], [mse %.2f]' % (train_record['best_model_name'],\\\n",
    "                                                        train_record['best_mae'],\\\n",
    "                                                        train_record['best_mse']) )\n",
    "    print( '='*50 )\n",
    "\n",
    "\n",
    "def print_GCC_summary(log_txt,epoch, scores,train_record,c_maes,c_mses):\n",
    "    mae, mse, loss = scores\n",
    "    c_mses['level'] = np.sqrt(c_mses['level'].avg)\n",
    "    c_mses['time'] = np.sqrt(c_mses['time'].avg)\n",
    "    c_mses['weather'] = np.sqrt(c_mses['weather'].avg)\n",
    "    with open(log_txt, 'a') as f:\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n')\n",
    "        f.write(str(epoch) + '\\n\\n')\n",
    "        f.write('  [mae %.4f mse %.4f], [val loss %.4f]\\n\\n' % (mae, mse, loss))\n",
    "        f.write('  [level: mae %.4f mse %.4f]\\n' % (np.average(c_maes['level'].avg), np.average(c_mses['level'])))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes['level'].avg)) + '\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_mses['level'])) + '\\n\\n')\n",
    "\n",
    "        f.write('  [time: mae %.4f mse %.4f]\\n' % (np.average(c_maes['time'].avg), np.average(c_mses['time'])))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes['time'].avg)) + '\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_mses['time'])) + '\\n\\n')\n",
    "\n",
    "        f.write('  [weather: mae %.4f mse %.4f]\\n' % (np.average(c_maes['weather'].avg), np.average(c_mses['weather'])))\n",
    "        f.write('    list: ' + str(np.transpose(c_maes['weather'].avg)) + '\\n')\n",
    "        f.write('    list: ' + str(np.transpose(c_mses['weather']))+ '\\n\\n')\n",
    "\n",
    "        f.write('='*15 + '+'*15 + '='*15 + '\\n\\n')\n",
    "\n",
    "    print( '='*50 )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '    [mae %.2f mse %.2f], [val loss %.4f]' % (mae, mse, loss) )\n",
    "    print( '    '+ '-'*20 )\n",
    "    print( '[best] [model: %s] , [mae %.2f], [mse %.2f]' % (train_record['best_model_name'],\\\n",
    "                                                        train_record['best_mae'],\\\n",
    "                                                        train_record['best_mse']) )\n",
    "    print( '='*50 )   \n",
    "\n",
    "\n",
    "def update_model(net,optimizer,scheduler,epoch,i_tb,exp_path,exp_name,scores,train_record,log_file=None):\n",
    "\n",
    "    mae, mse, loss = scores\n",
    "\n",
    "    snapshot_name = 'all_ep_%d_mae_%.1f_mse_%.1f' % (epoch + 1, mae, mse)\n",
    "\n",
    "    if mae < train_record['best_mae'] or mse < train_record['best_mse']:   \n",
    "        train_record['best_model_name'] = snapshot_name\n",
    "        if log_file is not None:\n",
    "            logger_txt(log_file,epoch,scores)\n",
    "        to_saved_weight = net.state_dict()\n",
    "        torch.save(to_saved_weight, os.path.join(exp_path, exp_name, snapshot_name + '.pth'))\n",
    "\n",
    "    if mae < train_record['best_mae']:           \n",
    "        train_record['best_mae'] = mae\n",
    "    if mse < train_record['best_mse']:\n",
    "        train_record['best_mse'] = mse \n",
    "\n",
    "    latest_state = {'train_record':train_record, 'net':net.state_dict(), 'optimizer':optimizer.state_dict(),\\\n",
    "                    'scheduler':scheduler.state_dict(), 'epoch': epoch, 'i_tb':i_tb, 'exp_path':exp_path, \\\n",
    "                    'exp_name':exp_name}\n",
    "\n",
    "    torch.save(latest_state,os.path.join(exp_path, exp_name, 'latest_state.pth'))\n",
    "\n",
    "    return train_record\n",
    "\n",
    "\n",
    "def copy_cur_env(work_dir, dst_dir, exception):\n",
    "\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.mkdir(dst_dir)\n",
    "\n",
    "    for filename in os.listdir(work_dir):\n",
    "\n",
    "        file = os.path.join(work_dir,filename)\n",
    "        dst_file = os.path.join(dst_dir,filename)\n",
    "\n",
    "\n",
    "        if os.path.isdir(file) and exception not in filename:\n",
    "            shutil.copytree(file, dst_file)\n",
    "        elif os.path.isfile(file):\n",
    "            shutil.copyfile(file,dst_file)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, cur_val):\n",
    "        self.cur_val = cur_val\n",
    "        self.sum += cur_val\n",
    "        self.count += 1\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "class AverageCategoryMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self,num_class):        \n",
    "        self.num_class = num_class\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.cur_val = np.zeros(self.num_class)\n",
    "        self.avg = np.zeros(self.num_class)\n",
    "        self.sum = np.zeros(self.num_class)\n",
    "        self.count = np.zeros(self.num_class)\n",
    "\n",
    "    def update(self, cur_val, class_id):\n",
    "        self.cur_val[class_id] = cur_val\n",
    "        self.sum[class_id] += cur_val\n",
    "        self.count[class_id] += 1\n",
    "        self.avg[class_id] = self.sum[class_id] / self.count[class_id]\n",
    "\n",
    "\n",
    "class Timer(object):\n",
    "    \"\"\"A simple timer.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.total_time = 0.\n",
    "        self.calls = 0\n",
    "        self.start_time = 0.\n",
    "        self.diff = 0.\n",
    "        self.average_time = 0.\n",
    "\n",
    "    def tic(self):\n",
    "        # using time.time instead of time.clock because time time.clock\n",
    "        # does not normalize for multithreading\n",
    "        self.start_time = time.time()\n",
    "\n",
    "    def toc(self, average=True):\n",
    "        self.diff = time.time() - self.start_time\n",
    "        self.total_time += self.diff\n",
    "        self.calls += 1\n",
    "        self.average_time = self.total_time / self.calls\n",
    "        if average:\n",
    "            return self.average_time\n",
    "        else:\n",
    "            return self.diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================img tranforms============================\n",
    "\n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img, mask, bbx=None):\n",
    "        if bbx is None:\n",
    "            for t in self.transforms:\n",
    "                img, mask = t(img, mask)\n",
    "            return img, mask\n",
    "        for t in self.transforms:\n",
    "            img, mask, bbx = t(img, mask, bbx)\n",
    "        return img, mask, bbx\n",
    "\n",
    "class RandomHorizontallyFlip(object):\n",
    "    def __call__(self, img, mask, bbx=None):\n",
    "        if random.random() < 0.5:\n",
    "            if bbx is None:\n",
    "                return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "            w, h = img.size\n",
    "            xmin = w - bbx[:,3]\n",
    "            xmax = w - bbx[:,1]\n",
    "            bbx[:,1] = xmin\n",
    "            bbx[:,3] = xmax\n",
    "            return img.transpose(Image.FLIP_LEFT_RIGHT), mask.transpose(Image.FLIP_LEFT_RIGHT), bbx\n",
    "        if bbx is None:\n",
    "            return img, mask\n",
    "        return img, mask, bbx\n",
    "\n",
    "class RandomCrop(object):\n",
    "    def __init__(self, size, padding=0):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "        self.padding = padding\n",
    "\n",
    "    def __call__(self, img, mask, dst_size=None):\n",
    "        if self.padding > 0:\n",
    "            img = ImageOps.expand(img, border=self.padding, fill=0)\n",
    "            mask = ImageOps.expand(mask, border=self.padding, fill=0)\n",
    "\n",
    "        assert img.size == mask.size\n",
    "        w, h = img.size\n",
    "        if dst_size is None:\n",
    "            th, tw = self.size\n",
    "        else:\n",
    "            th, tw = dst_size\n",
    "        if w == tw and h == th:\n",
    "            return img, mask\n",
    "        if w < tw or h < th:\n",
    "            return img.resize((tw, th), Image.BILINEAR), mask.resize((tw, th), Image.NEAREST)\n",
    "\n",
    "        x1 = random.randint(0, w - tw)\n",
    "        y1 = random.randint(0, h - th)\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "\n",
    "class CenterCrop(object):\n",
    "    def __init__(self, size):\n",
    "        if isinstance(size, numbers.Number):\n",
    "            self.size = (int(size), int(size))\n",
    "        else:\n",
    "            self.size = size\n",
    "\n",
    "    def __call__(self, img, mask):\n",
    "        w, h = img.size\n",
    "        th, tw = self.size\n",
    "        x1 = int(round((w - tw) / 2.))\n",
    "        y1 = int(round((h - th) / 2.))\n",
    "        return img.crop((x1, y1, x1 + tw, y1 + th)), mask.crop((x1, y1, x1 + tw, y1 + th))\n",
    "\n",
    "\n",
    "\n",
    "class FreeScale(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size  # (h, w)\n",
    "\n",
    "    def __call__(self, img, mask):\n",
    "        return img.resize((self.size[1], self.size[0]), Image.BILINEAR), mask.resize((self.size[1], self.size[0]), Image.NEAREST)\n",
    "\n",
    "\n",
    "class ScaleDown(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size  # (h, w)\n",
    "\n",
    "    def __call__(self, mask):\n",
    "        return  mask.resize((self.size[1]/cfg.TRAIN.DOWNRATE, self.size[0]/cfg.TRAIN.DOWNRATE), Image.NEAREST)\n",
    "\n",
    "\n",
    "class Scale(object):\n",
    "    def __init__(self, size):\n",
    "        self.size = size\n",
    "\n",
    "    def __call__(self, img, mask):\n",
    "        if img.size != mask.size:\n",
    "            print( img.size )\n",
    "            print( mask.size )          \n",
    "        assert img.size == mask.size\n",
    "        w, h = img.size\n",
    "        if (w <= h and w == self.size) or (h <= w and h == self.size):\n",
    "            return img, mask\n",
    "        if w < h:\n",
    "            ow = self.size\n",
    "            oh = int(self.size * h / w)\n",
    "            return img.resize((ow, oh), Image.BILINEAR), mask.resize((ow, oh), Image.NEAREST)\n",
    "        else:\n",
    "            oh = self.size\n",
    "            ow = int(self.size * w / h)\n",
    "            return img.resize((ow, oh), Image.BILINEAR), mask.resize((ow, oh), Image.NEAREST)\n",
    "\n",
    "\n",
    "# ===============================label tranforms============================\n",
    "\n",
    "class DeNormalize(object):\n",
    "    def __init__(self, mean, std):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        for t, m, s in zip(tensor, self.mean, self.std):\n",
    "            t.mul_(s).add_(m)\n",
    "        return tensor\n",
    "\n",
    "\n",
    "class MaskToTensor(object):\n",
    "    def __call__(self, img):\n",
    "        return torch.from_numpy(np.array(img, dtype=np.int32)).long()\n",
    "\n",
    "\n",
    "class LabelNormalize(object):\n",
    "    def __init__(self, para):\n",
    "        self.para = para\n",
    "\n",
    "    def __call__(self, tensor):\n",
    "        # tensor = 1./(tensor+self.para).log()\n",
    "        tensor = torch.from_numpy(np.array(tensor))\n",
    "        tensor = tensor*self.para\n",
    "        return tensor\n",
    "\n",
    "class GTScaleDown(object):\n",
    "    def __init__(self, factor=8):\n",
    "        self.factor = factor\n",
    "\n",
    "    def __call__(self, img):\n",
    "        w, h = img.size\n",
    "        if self.factor==1:\n",
    "            return img\n",
    "        tmp = np.array(img.resize((w//self.factor, h//self.factor), Image.BICUBIC))*self.factor*self.factor\n",
    "        img = Image.fromarray(tmp)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = (576,768)\n",
    "LABEL_FACTOR = 1\n",
    "TRAIN_BATCH_SIZE = 1\n",
    "NUM_WORKERS = 0\n",
    "\n",
    "def get_min_size(batch):\n",
    "\n",
    "    min_ht = TRAIN_SIZE[0]\n",
    "    min_wd = TRAIN_SIZE[1]\n",
    "\n",
    "    for i_sample in batch:\n",
    "        \n",
    "        _,ht,wd = i_sample.shape\n",
    "        if ht<min_ht:\n",
    "            min_ht = ht\n",
    "        if wd<min_wd:\n",
    "            min_wd = wd\n",
    "    return min_ht,min_wd\n",
    "\n",
    "def random_crop(img,den,dst_size):\n",
    "    # dst_size: ht, wd\n",
    "\n",
    "    _,ts_hd,ts_wd = img.shape\n",
    "\n",
    "    x1 = random.randint(0, ts_wd - dst_size[1])//LABEL_FACTOR*LABEL_FACTOR\n",
    "    y1 = random.randint(0, ts_hd - dst_size[0])//LABEL_FACTOR*LABEL_FACTOR\n",
    "    x2 = x1 + dst_size[1]\n",
    "    y2 = y1 + dst_size[0]\n",
    "\n",
    "    label_x1 = x1//LABEL_FACTOR\n",
    "    label_y1 = y1//LABEL_FACTOR\n",
    "    label_x2 = x2//LABEL_FACTOR\n",
    "    label_y2 = y2//LABEL_FACTOR\n",
    "\n",
    "    return img[:,y1:y2,x1:x2], den[label_y1:label_y2,label_x1:label_x2]\n",
    "\n",
    "def share_memory(batch):\n",
    "    out = None\n",
    "    if False:\n",
    "        # If we're in a background process, concatenate directly into a\n",
    "        # shared memory tensor to avoid an extra copy\n",
    "        numel = sum([x.numel() for x in batch])\n",
    "        storage = batch[0].storage()._new_shared(numel)\n",
    "        out = batch[0].new(storage)\n",
    "    return out\n",
    "\n",
    "def SHHA_collate(batch):\n",
    "    # @GJY \n",
    "    r\"\"\"Puts each data field into a tensor with outer dimension batch size\"\"\"\n",
    "\n",
    "    transposed = list(zip(*batch)) # imgs and dens\n",
    "    imgs, dens = [transposed[0],transposed[1]]\n",
    "\n",
    "\n",
    "    error_msg = \"batch must contain tensors; found {}\"\n",
    "    if isinstance(imgs[0], torch.Tensor) and isinstance(dens[0], torch.Tensor):\n",
    "        \n",
    "        min_ht, min_wd = get_min_size(imgs)\n",
    "\n",
    "        # print min_ht, min_wd\n",
    "\n",
    "        # pdb.set_trace()\n",
    "        \n",
    "        cropped_imgs = []\n",
    "        cropped_dens = []\n",
    "        for i_sample in range(len(batch)):\n",
    "            _img, _den = random_crop(imgs[i_sample],dens[i_sample],[min_ht,min_wd])\n",
    "            cropped_imgs.append(_img)\n",
    "            cropped_dens.append(_den)\n",
    "\n",
    "\n",
    "        cropped_imgs = torch.stack(cropped_imgs, 0, out=share_memory(cropped_imgs))\n",
    "        cropped_dens = torch.stack(cropped_dens, 0, out=share_memory(cropped_dens))\n",
    "\n",
    "        return [cropped_imgs,cropped_dens]\n",
    "\n",
    "    raise TypeError((error_msg.format(type(batch[0]))))\n",
    "\n",
    "\n",
    "def loading_data():\n",
    "    mean_std = ([0.410824894905, 0.370634973049, 0.359682112932], [0.278580576181, 0.26925137639, 0.27156367898])\n",
    "    log_para = 100.\n",
    "    factor = 1\n",
    "    TRAIN_BATCH_SIZE = 1\n",
    "    DATA_PATH = \"ProcessedData/shanghaitech_part_A\"\n",
    "    VAL_BATCH_SIZE = 3\n",
    "    \n",
    "    \n",
    "    train_main_transform = Compose([\n",
    "        RandomHorizontallyFlip()\n",
    "    ])\n",
    "    img_transform = standard_transforms.Compose([\n",
    "        standard_transforms.ToTensor(),\n",
    "        standard_transforms.Normalize(*mean_std)\n",
    "    ])\n",
    "    gt_transform = standard_transforms.Compose([\n",
    "        GTScaleDown(factor),\n",
    "        LabelNormalize(log_para)\n",
    "    ])\n",
    "    restore_transform = standard_transforms.Compose([\n",
    "        DeNormalize(*mean_std),\n",
    "        standard_transforms.ToPILImage()\n",
    "    ])\n",
    "\n",
    "    train_set = SHHA(DATA_PATH+'/train', 'train',main_transform=train_main_transform, img_transform=img_transform, gt_transform=gt_transform)\n",
    "    train_loader =None\n",
    "    if TRAIN_BATCH_SIZE==1:\n",
    "        train_loader = DataLoader(train_set, batch_size=1, shuffle=True, drop_last=True)\n",
    "    elif TRAIN_BATCH_SIZE>1:\n",
    "        train_loader = DataLoader(train_set, batch_size=TRAIN_BATCH_SIZE, num_workers=NUM_WORKERS, collate_fn=SHHA_collate, shuffle=True, drop_last=True)\n",
    "    \n",
    "    \n",
    "\n",
    "    val_set = SHHA(DATA_PATH+'/test', 'test', main_transform=None, img_transform=img_transform, gt_transform=gt_transform)\n",
    "    val_loader = DataLoader(val_set, batch_size=VAL_BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True, drop_last=False)\n",
    "\n",
    "    return train_loader, val_loader, restore_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, val_loader, restore_transform = loading_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CSRNet(nn.Module):\n",
    "    def __init__(self, load_weights=False):\n",
    "        super(CSRNet, self).__init__()\n",
    "        self.seen = 0\n",
    "        self.frontend_feat = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512]\n",
    "        self.backend_feat  = [512, 512, 512,256,128,64]\n",
    "        self.frontend = make_layers(self.frontend_feat)\n",
    "        self.backend = make_layers(self.backend_feat,in_channels = 512,dilation = True)\n",
    "        self.output_layer = nn.Conv2d(64, 1, kernel_size=1)\n",
    "        if not load_weights:\n",
    "            mod = models.vgg16(pretrained = True)\n",
    "            self._initialize_weights()\n",
    "            self.frontend.load_state_dict(mod.features[0:23].state_dict())\n",
    "            \n",
    "    def forward(self,x):\n",
    "        size = x.size()\n",
    "        x = self.frontend(x)\n",
    "        x = self.backend(x)\n",
    "        x = self.output_layer(x)\n",
    "        x = F.upsample(x, size = size[2:])\n",
    "        return x\n",
    "    \n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.normal_(m.weight, std=0.01)\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            \n",
    "                \n",
    "def make_layers(cfg, in_channels = 3,batch_norm=False,dilation = False):\n",
    "    if dilation:\n",
    "        d_rate = 2\n",
    "    else:\n",
    "        d_rate = 1\n",
    "    layers = []\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=d_rate,dilation = d_rate)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CrowdCounter(nn.Module):\n",
    "    def __init__(self,gpus,model_name):\n",
    "        super(CrowdCounter, self).__init__()        \n",
    "\n",
    "        self.CCN = CSRNet()\n",
    "        self.CCN.to(device)\n",
    "        self.loss_mse_fn = nn.MSELoss().to(device)\n",
    "        \"\"\"\n",
    "        if len(gpus)>1:\n",
    "            self.CCN = torch.nn.DataParallel(self.CCN, device_ids=gpus).cuda()\n",
    "        else:\n",
    "            self.CCN=self.CCN.cuda()\n",
    "        self.loss_mse_fn = nn.MSELoss().cuda()\n",
    "        \"\"\"\n",
    "        \n",
    "    @property\n",
    "    def loss(self):\n",
    "        return self.loss_mse\n",
    "    \n",
    "    def forward(self, img, gt_map): \n",
    "        density_map = self.CCN(img) \n",
    "        \n",
    "        self.loss_mse= self.build_loss(density_map.squeeze(), gt_map.squeeze())               \n",
    "        return density_map\n",
    "    \n",
    "    def build_loss(self, density_map, gt_data):\n",
    "        loss_mse = self.loss_mse_fn(density_map, gt_data)  \n",
    "        return loss_mse\n",
    "\n",
    "    def test_forward(self, img):                               \n",
    "        density_map = self.CCN(img)                    \n",
    "        return density_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "GPU_ID = [0]\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.strftime(\"%m-%d_%H-%M\", time.localtime())\n",
    "EXP_NAME = now + '_' + \"SHHA\" + \"_\" + \"CSRNet\"\n",
    "EXP_PATH = './exp'\n",
    "net = 'CSRNet'\n",
    "LR = 1e-5 # learning rate\n",
    "LR_DECAY = 0.995 # decay rate\n",
    "LR_DECAY_START = -1 # when training epoch is more than it, the learning rate will be begin to decay\n",
    "NUM_EPOCH_LR_DECAY = 1 # decay frequency\n",
    "MAX_EPOCH = 200\n",
    "RESUME = False\n",
    "PRINT_FREQ = 1\n",
    "LOG_PARA = 100.\n",
    "\n",
    "\n",
    "class Trainer():\n",
    "    def __init__(self, dataloader, pwd):\n",
    "\n",
    "        self.data_mode = 'SHHA'\n",
    "        self.exp_name = EXP_NAME\n",
    "        self.exp_path = EXP_PATH\n",
    "        self.pwd = pwd\n",
    "        self.LOG_PARA = LOG_PARA\n",
    "\n",
    "        self.net_name = net\n",
    "        self.net = CrowdCounter(GPU_ID,self.net_name).to(device)\n",
    "        self.optimizer = optim.Adam(self.net.CCN.parameters(), lr=LR, weight_decay=1e-4)\n",
    "        # self.optimizer = optim.SGD(self.net.parameters(), cfg.LR, momentum=0.95,weight_decay=5e-4)\n",
    "        self.scheduler = StepLR(self.optimizer, step_size=NUM_EPOCH_LR_DECAY, gamma=LR_DECAY)          \n",
    "\n",
    "        self.train_record = {'best_mae': 1e20, 'best_mse':1e20, 'best_model_name': ''}\n",
    "        self.timer = {'iter time' : Timer(),'train time' : Timer(),'val time' : Timer()} \n",
    "\n",
    "        self.epoch = 0\n",
    "        self.i_tb = 0\n",
    "        \n",
    "        \"\"\"\n",
    "        if cfg.PRE_GCC:\n",
    "            self.net.load_state_dict(torch.load(cfg.PRE_GCC_MODEL))\n",
    "        \"\"\"\n",
    "        \n",
    "        self.train_loader, self.val_loader, self.restore_transform = dataloader()\n",
    "\n",
    "        if RESUME:\n",
    "            latest_state = torch.load(RESUME_PATH)\n",
    "            self.net.load_state_dict(latest_state['net'])\n",
    "            self.optimizer.load_state_dict(latest_state['optimizer'])\n",
    "            self.scheduler.load_state_dict(latest_state['scheduler'])\n",
    "            self.epoch = latest_state['epoch'] + 1\n",
    "            self.i_tb = latest_state['i_tb']\n",
    "            self.train_record = latest_state['train_record']\n",
    "            self.exp_path = latest_state['exp_path']\n",
    "            self.exp_name = latest_state['exp_name']\n",
    "\n",
    "        # self.writer, self.log_txt = logger(self.exp_path, self.exp_name, self.pwd, 'exp', resume=RESUME)\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "\n",
    "        # self.validate_V3()\n",
    "        for epoch in range(self.epoch, MAX_EPOCH):\n",
    "            self.epoch = epoch\n",
    "            if epoch > LR_DECAY_START:\n",
    "                self.scheduler.step()\n",
    "                \n",
    "            # training    \n",
    "            self.timer['train time'].tic()\n",
    "            self.train()\n",
    "            self.timer['train time'].toc(average=False)\n",
    "\n",
    "            print( 'train time: {:.2f}s'.format(self.timer['train time'].diff) )\n",
    "            print( '='*20 )\n",
    "\n",
    "            # validation\n",
    "            if epoch%VAL_FREQ==0 or epoch>VAL_DENSE_START:\n",
    "                self.timer['val time'].tic()\n",
    "                self.validate_V1()\n",
    "                self.timer['val time'].toc(average=False)\n",
    "                print( 'val time: {:.2f}s'.format(self.timer['val time'].diff) )\n",
    "                \n",
    "                torch.save(self.net.state_dict(), \"my_model_weigths.pth\")\n",
    "\n",
    "\n",
    "    def train(self): # training for all datasets\n",
    "        self.net.train()\n",
    "        \n",
    "        for i, data in enumerate(self.train_loader, 0):\n",
    "            self.timer['iter time'].tic()\n",
    "            img, gt_map = data\n",
    "            img = Variable(img).to(device)\n",
    "            gt_map = Variable(gt_map).to(device)\n",
    "\n",
    "            self.optimizer.zero_grad()\n",
    "            pred_map = self.net(img, gt_map)\n",
    "            loss = self.net.loss\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "\n",
    "            if (i + 1) % PRINT_FREQ == 0:\n",
    "                self.i_tb += 1\n",
    "                # self.writer.add_scalar('train_loss', loss.item(), self.i_tb)\n",
    "                self.timer['iter time'].toc(average=False)\n",
    "                print( '[ep %d][it %d][loss %.4f][lr %.4f][%.2fs]' % \\\n",
    "                        (self.epoch + 1, i + 1, loss.item(), self.optimizer.param_groups[0]['lr']*10000, self.timer['iter time'].diff) )\n",
    "                print( '        [cnt: gt: %.1f pred: %.2f]' % (gt_map[0].sum().data/self.LOG_PARA, pred_map[0].sum().data/self.LOG_PARA) )   \n",
    "\n",
    "\n",
    "    def validate_V1(self):# validate_V1 for SHHA, SHHB, UCF-QNRF, UCF50\n",
    "\n",
    "        self.net.eval()\n",
    "        \n",
    "        losses = AverageMeter()\n",
    "        maes = AverageMeter()\n",
    "        mses = AverageMeter()\n",
    "\n",
    "        for vi, data in enumerate(self.val_loader, 0):\n",
    "            img, gt_map = data\n",
    "\n",
    "            with torch.no_grad():\n",
    "                img = Variable(img).to(device)\n",
    "                gt_map = Variable(gt_map).to(device)\n",
    "\n",
    "                pred_map = self.net.forward(img,gt_map)\n",
    "\n",
    "                pred_map = pred_map.data.cpu().numpy()\n",
    "                gt_map = gt_map.data.cpu().numpy()\n",
    "\n",
    "                for i_img in range(pred_map.shape[0]):\n",
    "                \n",
    "                    pred_cnt = np.sum(pred_map[i_img])/self.LOG_PARA\n",
    "                    gt_count = np.sum(gt_map[i_img])/self.LOG_PARA\n",
    "\n",
    "                    \n",
    "                    losses.update(self.net.loss.item())\n",
    "                    maes.update(abs(gt_count-pred_cnt))\n",
    "                    mses.update((gt_count-pred_cnt)*(gt_count-pred_cnt))\n",
    "                if vi==0:\n",
    "                    vis_results(self.exp_name, self.epoch, self.writer, self.restore_transform, img, pred_map, gt_map)\n",
    "            \n",
    "        mae = maes.avg\n",
    "        mse = np.sqrt(mses.avg)\n",
    "        loss = losses.avg\n",
    "\n",
    "        self.writer.add_scalar('val_loss', loss, self.epoch + 1)\n",
    "        self.writer.add_scalar('mae', mae, self.epoch + 1)\n",
    "        self.writer.add_scalar('mse', mse, self.epoch + 1)\n",
    "\n",
    "        self.train_record = update_model(self.net,self.optimizer,self.scheduler,self.epoch,self.i_tb,self.exp_path,self.exp_name, \\\n",
    "            [mae, mse, loss],self.train_record,self.log_txt)\n",
    "        print_summary(self.exp_name,[mae, mse, loss],self.train_record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/lib/python3.7/site-packages/torch/optim/lr_scheduler.py:100: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule.See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/simon/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py:2404: UserWarning: nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\n",
      "  warnings.warn(\"nn.functional.upsample is deprecated. Use nn.functional.interpolate instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ep 1][it 1][loss 0.1478][lr 0.0995][15.98s]\n",
      "        [cnt: gt: 1426.8 pred: 2.83]\n",
      "TRAIN\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "if seed is not None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    \n",
    "gpus = GPU_ID\n",
    "if len(gpus)==1:\n",
    "    torch.cuda.set_device(gpus[0])\n",
    "\"\"\"\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "#------------Start Training------------\n",
    "# pwd = os.path.split(os.path.realpath(__file__))[0]\n",
    "cc_trainer = Trainer(loading_data,\"\")\n",
    "cc_trainer.forward()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
